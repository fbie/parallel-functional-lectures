@inproceedings{Steele2006Parallel,
    abstract = {{The Programming Language Research Group at Sun Microsystems Laboratories seeks to apply lessons learned from the Java (TM) Programming Language to the next generation of programming languages. The Java language supports platform-independent parallel programming with explicit multithreading and explicit locks. As part of the DARPA program for High Productivity Computing Systems, we are developing Fortress, a language intended to support large-scale scientific computation. One of the design principles is that parallelism be encouraged everywhere (for example, it is intentionally just a little bit harder to write a sequential loop than a parallel loop). Another is to have rich mechanisms for encapsulation and abstraction; the idea is to have a fairly complicated language for library writers that enables them to write libraries that present a relatively simple set of interfaces to the application programmer. We will discuss ideas for using a rich polymorphic type system to organize multithreading and data distribution on large parallel machines. The net result is similar in some ways to data distribution facilities in other languages such as HPF and Chapel, but more open-ended, because in Fortress the facilities are defined by user-replaceable libraries rather than wired into the compiler.}},
    address = {Berlin, Heidelberg},
    author = {Steele, Guy L.},
    booktitle = {Proceedings of the 8th International Conference on Functional and Logic Programming},
    citeulike-article-id = {14068361},
    citeulike-linkout-0 = {http://www.brics.dk/pilambda/old/docs/Aarhus-Fortress-Parallelism-2006public.pdf},
    citeulike-linkout-1 = {http://portal.acm.org/citation.cfm?id=2100073},
    citeulike-linkout-2 = {http://dx.doi.org/10.1007/11737414_1},
    doi = {10.1007/11737414_1},
    isbn = {3-540-33438-6, 978-3-540-33438-5},
    keywords = {fortress, parallel-programming, programming-language},
    location = {Fuji-Susono, Japan},
    pages = {1},
    posted-at = {2016-06-14 06:22:45},
    priority = {0},
    publisher = {Springer-Verlag},
    series = {FLOPS'06},
    title = {{Parallel Programming and Parallel Abstractions in Fortress}},
    url = {http://www.brics.dk/pilambda/old/docs/Aarhus-Fortress-Parallelism-2006public.pdf},
    year = {2006}
}

@inproceedings{Dou2016VEnron,
    abstract = {{Like most conventional software, spreadsheets are subject to software evolution. However, spreadsheet evolution is rarely assisted by version management tools. As a result, the version information across evolved spreadsheets is often missing or highly fragmented. This makes it difficult for users to notice the evolution issues arising from their spreadsheets. In this paper, we propose a semi-automated approach that leverages spreadsheets' contexts (e.g., attached emails) and contents to identify evolved spreadsheets and recover the embedded version information. We apply it to the released email archive of the Enron Corporation and build an industrial-scale, versioned spreadsheet corpus VEnron. Our approach first clusters spreadsheets that likely evolved from one to another into evolution groups based on various fragmented information, such as spreadsheet filenames, spreadsheet contents, and spreadsheet-attached emails. Then, it recovers the version information of the spreadsheets in each evolution group. VEnron enables us to identify interesting issues that can arise from spreadsheet evolution. For example, the versioned spreadsheets popularly exist in the Enron email archive; changes in formulas are common; and some groups (16.9\%) can introduce new errors during evolution. According to our knowledge, VEnron is the first spreadsheet corpus with version information. It provides a valuable resource to understand issues arising from spreadsheet evolution.}},
    address = {New York, NY, USA},
    author = {Dou, Wensheng and Xu, Liang and Cheung, Shing C. and Gao, Chushu and Wei, Jun and Huang, Tao},
    booktitle = {Proceedings of the 38th International Conference on Software Engineering Companion},
    citeulike-article-id = {14068350},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2889238},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2889160.2889238},
    doi = {10.1145/2889160.2889238},
    isbn = {978-1-4503-4205-6},
    keywords = {analysis, spreadsheets, versioning},
    location = {Austin, Texas},
    pages = {162--171},
    posted-at = {2016-06-14 05:14:33},
    priority = {3},
    publisher = {ACM},
    series = {ICSE '16},
    title = {{VEnron: A Versioned Spreadsheet Corpus and Related Evolution Analysis}},
    url = {http://dx.doi.org/10.1145/2889160.2889238},
    year = {2016}
}

@inproceedings{Dou2014Spreadsheet,
    abstract = {{Spreadsheets are widely used by end users for numerical computation in their business. Spreadsheet cells whose computation is subject to the same semantics are often clustered in a row or column. When a spreadsheet evolves, these cell clusters can degenerate due to ad hoc modifications or undisciplined copy-and-pastes. Such degenerated clusters no longer keep cells prescribing the same computational semantics, and are said to exhibit ambiguous computation smells. Our empirical study finds that such smells are common and likely harmful. We propose AmCheck, a novel technique that automatically detects and repairs ambiguous computation smells by recovering their intended computational semantics. A case study using AmCheck suggests that it is useful for discovering and repairing real spreadsheet problems.}},
    address = {New York, NY, USA},
    author = {Dou, Wensheng and Cheung, Shing C. and Wei, Jun},
    booktitle = {Proceedings of the 36th International Conference on Software Engineering},
    citeulike-article-id = {14068349},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2568316},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2568225.2568316},
    doi = {10.1145/2568225.2568316},
    isbn = {978-1-4503-2756-5},
    keywords = {analysis, array-programming, spreadsheets},
    location = {Hyderabad, India},
    pages = {848--858},
    posted-at = {2016-06-14 05:13:45},
    priority = {3},
    publisher = {ACM},
    series = {ICSE 2014},
    title = {{Is Spreadsheet Ambiguity Harmful? Detecting and Repairing Spreadsheet Smells Due to Ambiguous Computation}},
    url = {http://dx.doi.org/10.1145/2568225.2568316},
    year = {2014}
}

@book{Sestoft2016Java,
    author = {Sestoft, Peter},
    citeulike-article-id = {14054711},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20&amp;path=ASIN/0262529076},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21&amp;path=ASIN/0262529076},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21&amp;path=ASIN/0262529076},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0262529076},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0262529076/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20&path=ASIN/0262529076},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0262529076},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0262529076},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0262529076&index=books&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0262529076},
    day = {18},
    edition = {third edition},
    howpublished = {Paperback},
    isbn = {0262529076},
    keywords = {book, java},
    month = mar,
    posted-at = {2016-06-01 04:37:37},
    priority = {0},
    publisher = {The MIT Press},
    title = {{Java Precisely (MIT Press)}},
    url = {http://www.worldcat.org/isbn/0262529076},
    year = {2016}
}

@inproceedings{Swaine2012Seeing,
    abstract = {{This paper presents the latest chapter in our adventures coping with a large, sequentially-tuned, legacy runtime system in today's parallel world. Specifically, this paper introduces our new graphical visualizer that helps programmers understand how to program in parallel with Racket's futures and, to some extent, what performs well in sequential Racket. Overall, our experience with parallelism in Racket is that we can achieve reasonable parallel performance in Racket without sacrificing the most important property of functional programming language implementations, namely safety. That is, Racket programmers are guaranteed that every Racket primitive (and thus all functions built using Racket primitives) will either behave properly, or it will signal an error explaining what went wrong. That said, however, it is challenging to understand how to best use futures to achieve interesting speedups, and the visualizer is our attempt to more widely disseminate key performance details of the runtime system in order to help Racket programmers maximize performance.}},
    address = {New York, NY, USA},
    author = {Swaine, James and Fetscher, Burke and St Amour, Vincent and Findler, Robert B. and Flatt, Matthew},
    booktitle = {Proceedings of the 1st ACM SIGPLAN Workshop on Functional High-performance Computing},
    citeulike-article-id = {14041573},
    citeulike-linkout-0 = {http://users.eecs.northwestern.edu/~stamourv/papers/seeing-the-futures.pdf},
    citeulike-linkout-1 = {http://portal.acm.org/citation.cfm?id=2364485},
    citeulike-linkout-2 = {http://dx.doi.org/10.1145/2364474.2364485},
    doi = {10.1145/2364474.2364485},
    isbn = {978-1-4503-1577-7},
    keywords = {functional-programming, parallel-programming},
    location = {Copenhagen, Denmark},
    pages = {73--82},
    posted-at = {2016-05-25 10:05:06},
    priority = {3},
    publisher = {ACM},
    series = {FHPC '12},
    title = {{Seeing the Futures: Profiling Shared-memory Parallel Racket}},
    url = {http://users.eecs.northwestern.edu/~stamourv/papers/seeing-the-futures.pdf},
    year = {2012}
}

@article{Morita2007Automatic,
    abstract = {{Divide-and-conquer algorithms are suitable for modern parallel machines, tending to have large amounts of inherent parallelism and working well with caches and deep memory hierarchies. Among others, list homomorphisms are a class of recursive functions on lists, which match very well with the divide-and-conquer paradigm. However, direct programming with list homomorphisms is a challenge for many programmers. In this paper, we propose and implement a novel systemthat can automatically derive cost-optimal list homomorphisms from a pair of sequential programs, based on the third homomorphism theorem. Our idea is to reduce extraction of list homomorphisms to derivation of weak right inverses. We show that a weak right inverse always exists and can be automatically generated from a wide class of sequential programs. We demonstrate our system with several nontrivial examples, including the maximum prefix sum problem, the prefix sum computation, the maximum segment sum problem, and the line-of-sight problem. The experimental results show practical efficiency of our automatic parallelization algorithm and good speedups of the generated parallel programs.}},
    address = {New York, NY, USA},
    author = {Morita, Kazutaka and Morihata, Akimasa and Matsuzaki, Kiminori and Hu, Zhenjiang and Takeichi, Masato},
    citeulike-article-id = {14025919},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1250752},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1273442.1250752},
    doi = {10.1145/1273442.1250752},
    issn = {0362-1340},
    journal = {SIGPLAN Not.},
    keywords = {algebra, homomorphism, parallel-programming},
    month = jun,
    number = {6},
    pages = {146--155},
    posted-at = {2016-05-02 13:43:32},
    priority = {3},
    publisher = {ACM},
    title = {{Automatic Inversion Generates Divide-and-conquer Parallel Programs}},
    url = {http://dx.doi.org/10.1145/1273442.1250752},
    volume = {42},
    year = {2007}
}

@inproceedings{Brown2014General,
    abstract = {{We describe a general technique for obtaining provably correct, non-blocking implementations of a large class of tree data structures where pointers are directed from parents to children. Updates are permitted to modify any contiguous portion of the tree atomically. Our non-blocking algorithms make use of the LLX, SCX and VLX primitives, which are multi-word generalizations of the standard LL, SC and VL primitives and have been implemented from single-word CAS. To illustrate our technique, we describe how it can be used in a fairly straightforward way to obtain a non-blocking implementation of a chromatic tree, which is a relaxed variant of a red-black tree. The height of the tree at any time is O(c + log n), where n is the number of keys and c is the number of updates in progress. We provide an experimental performance analysis which demonstrates that our Java implementation of a chromatic tree rivals, and often significantly outperforms, other leading concurrent dictionaries.}},
    address = {New York, NY, USA},
    author = {Brown, Trevor and Ellen, Faith and Ruppert, Eric},
    booktitle = {Proceedings of the 19th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming},
    citeulike-article-id = {14025817},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2555267},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2555243.2555267},
    doi = {10.1145/2555243.2555267},
    isbn = {978-1-4503-2656-8},
    keywords = {concurrency, data-structures, trees},
    location = {Orlando, Florida, USA},
    pages = {329--342},
    posted-at = {2016-05-02 10:41:00},
    priority = {2},
    publisher = {ACM},
    series = {PPoPP '14},
    title = {{A General Technique for Non-blocking Trees}},
    url = {http://dx.doi.org/10.1145/2555243.2555267},
    year = {2014}
}

@article{Lenharth2016Parallel,
    abstract = {{Data-centric abstractions and execution strategies are needed to exploit parallelism in large-scale graph analytics.}},
    address = {New York, NY, USA},
    author = {Lenharth, Andrew and Nguyen, Donald and Pingali, Keshav},
    citeulike-article-id = {14023960},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2930840.2901919},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2901919},
    doi = {10.1145/2901919},
    issn = {0001-0782},
    journal = {Commun. ACM},
    keywords = {graphs, parallel-programming},
    month = apr,
    number = {5},
    pages = {78--87},
    posted-at = {2016-04-29 07:31:38},
    priority = {4},
    publisher = {ACM},
    title = {{Parallel Graph Analytics}},
    url = {http://dx.doi.org/10.1145/2901919},
    volume = {59},
    year = {2016}
}

@misc{Erdmann2016Parallelism,
    address = {5000 Forbes Avenue, Pittsburgh, PA 15213-3891},
    author = {Erdmann, Michael},
    citeulike-article-id = {14023950},
    citeulike-linkout-0 = {http://www.cs.cmu.edu/~15150/resources/lectures/19/Parallelism.pdf},
    howpublished = {Lecture Notes},
    institution = {Carnegie Mellon University},
    keywords = {functional-programming, graphs, parallel-programming},
    posted-at = {2016-04-29 06:52:16},
    priority = {4},
    school = {Carnegie Mellon University},
    title = {{P}arallelism, {C}ost {G}raphs, and {S}equences},
    url = {http://www.cs.cmu.edu/~15150/resources/lectures/19/Parallelism.pdf},
    year = {2016}
}

@article{Steele2009Organizing,
    abstract = {{Alan Perlis, inverting OscarWilde's famous quip about cynics, once suggested, decades ago, that a Lisp programmer is one who knows the value of everything and the cost of nothing. Now that the conference on Lisp and Functional Programming has become ICFP, some may think that OCaml and Haskell programmers have inherited this (now undeserved) epigram. I do believe that as multicore processors are becoming prominent, and soon ubiquitous, it behooves all programmers to rethink their programming style, strategies, and tactics, so that their code may have excellent performance. For the last six years I have been part of a team working on a programming language, Fortress, that has borrowed ideas not only from Fortran, not only from Java, not only from Algol and Alphard and CLU, not only from MADCAP and MODCAP and MIRFAC and the Klerer-May system-but also from Haskell, and I would like to repay the favor. In this talk I will discuss three ideas (none original with me) that I have found to be especially powerful in organizing Fortress programs so that they may be executed equally effectively either sequentially or in parallel: user-defined associative operators (and, more generally, user-defined monoids); conjugate transforms of data; and monoid-caching trees (as described, for example, by Hinze and Paterson). I will exhibit pleasant little code examples (some original with me) that make use of these ideas.}},
    address = {New York, NY, USA},
    author = {Steele, Guy L.},
    citeulike-article-id = {14003790},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1596551},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1631687.1596551},
    doi = {10.1145/1631687.1596551},
    issn = {0362-1340},
    journal = {SIGPLAN Not.},
    keywords = {functional, parallel-programming},
    month = aug,
    number = {9},
    pages = {1--2},
    posted-at = {2016-04-06 11:55:35},
    priority = {0},
    publisher = {ACM},
    title = {{Organizing Functional Code for Parallel Execution or, Foldl and Foldr Considered Slightly Harmful}},
    url = {http://dx.doi.org/10.1145/1631687.1596551},
    volume = {44},
    year = {2009}
}

@inproceedings{Hansen2016Wristworn,
    abstract = {{This paper addresses gaze interaction for smart home control, conducted from a wrist-worn unit. First we asked ten people to enact the gaze movements they would propose for e.g. opening a door or adjusting the room temperature. On basis of their suggestions we built and tested different versions of a prototype applying off-screen stroke input. Command prompts were given to twenty participants by text or arrow displays. The success rate achieved by the end of their first encounter with the system was 46\% in average; it took them 1.28 seconds to connect with the system and 1.29 seconds to make a correct selection. Their subjective evaluations were positive with regard to the speed of the interaction. We conclude that gaze gesture input seems feasible for fast and brief remote control of smart home technology provided that robustness of tracking is improved.}},
    address = {New York, NY, USA},
    author = {Hansen, John P. and Lund, Haakon and Biermann, Florian and M{\o}llenbach, Emillie and Sztuk, Sebastian and San Agustin, Javier},
    booktitle = {Proceedings of the Ninth Biennial ACM Symposium on Eye Tracking Research \& Applications},
    citeulike-article-id = {13991392},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2857514},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2857491.2857514},
    doi = {10.1145/2857491.2857514},
    isbn = {978-1-4503-4125-7},
    keywords = {gaze-tracking},
    location = {Charleston, South Carolina},
    pages = {57--64},
    posted-at = {2016-03-31 06:56:16},
    priority = {0},
    publisher = {ACM},
    series = {ETRA '16},
    title = {{Wrist-worn Pervasive Gaze Interaction}},
    url = {http://dx.doi.org/10.1145/2857491.2857514},
    year = {2016}
}

@incollection{Sexton2008Virtual,
    author = {Sexton, AlanP and Swinbank, Richard},
    booktitle = {Sharing Data, Information and Knowledge},
    citeulike-article-id = {13985643},
    citeulike-linkout-0 = {http://www.cs.bham.ac.uk/~aps/research/papers/pdf/SeSw-BNCOD08-VFS-Demotion-BV.pdf},
    citeulike-linkout-1 = {http://dx.doi.org/10.1007/978-3-540-70504-8_13},
    citeulike-linkout-2 = {http://link.springer.com/chapter/10.1007/978-3-540-70504-8_13},
    doi = {10.1007/978-3-540-70504-8_13},
    editor = {Gray, Alex and Jeffery, Keith and Shao, Jianhua},
    keywords = {data-structures, k-d-tree, trees},
    pages = {139--152},
    posted-at = {2016-03-22 10:33:58},
    priority = {0},
    publisher = {Springer Berlin Heidelberg},
    series = {Lecture Notes in Computer Science},
    title = {{Virtual Forced Splitting, Demotion and the BV-Tree}},
    url = {http://www.cs.bham.ac.uk/~aps/research/papers/pdf/SeSw-BNCOD08-VFS-Demotion-BV.pdf},
    volume = {5071},
    year = {2008}
}

@inproceedings{Freeston1995General,
    abstract = {{We present a generic solution to a problem which lies at the heart of the unpredictable worst-case performance characteristics of a wide class of multi-dimensional index designs: those which employ a recursive partitioning of the data space. We then show how this solution can produce modified designs with fully predictable and controllable worst-case characteristics. In particular, we show how the recursive partitioning of an n-dimensional dataspace can be represented in such a way that the characteristics of the one-dimensional B-tree are preserved in n dimensions, as far as is topologically possible i.e. a representation guaranteeing logarithmic access and update time, while also guaranteeing a one-third minimum occupancy of both data and index nodes.}},
    address = {New York, NY, USA},
    author = {Freeston, Michael},
    booktitle = {Proceedings of the 1995 ACM SIGMOD International Conference on Management of Data},
    citeulike-article-id = {1246488},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=223796},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/223784.223796},
    doi = {10.1145/223784.223796},
    isbn = {0-89791-731-6},
    keywords = {data-structures, k-d-tree, trees},
    location = {San Jose, California, USA},
    pages = {80--91},
    posted-at = {2016-03-22 07:23:03},
    priority = {0},
    publisher = {ACM},
    series = {SIGMOD '95},
    title = {{A General Solution of the N-dimensional B-tree Problem}},
    url = {http://dx.doi.org/10.1145/223784.223796},
    year = {1995}
}

@inproceedings{Robinson1981KDBtree,
    abstract = {{The problem of retrieving multikey records via range queries from a large, dynamic index is considered. By large it is meant that most of the index must be stored on secondary memory. By dynamic it is meant that insertions and deletions are intermixed with queries, so that the index cannot be built beforehand. A new data structure, the K-D-B-tree, is presented as a solution to this problem. K-D-B-trees combine properties of K-D-trees and B-trees. It is expected that the multidimensional search effieciency of balanced K-D-trees and the I/O efficiency of B-trees should both be approximated in the K-D-B-tree. Preliminary experimental results that tend to support this are reported.}},
    address = {New York, NY, USA},
    author = {Robinson, John T.},
    booktitle = {Proceedings of the 1981 ACM SIGMOD International Conference on Management of Data},
    citeulike-article-id = {4813463},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=582321},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/582318.582321},
    doi = {10.1145/582318.582321},
    isbn = {0-89791-040-0},
    keywords = {data-structures, k-d-tree, trees},
    location = {Ann Arbor, Michigan},
    pages = {10--18},
    posted-at = {2016-03-21 09:35:47},
    priority = {0},
    publisher = {ACM},
    series = {SIGMOD '81},
    title = {{The K-D-B-tree: A Search Structure for Large Multidimensional Dynamic Indexes}},
    url = {http://dx.doi.org/10.1145/582318.582321},
    year = {1981}
}

@article{Bentley1975Multidimensional,
    abstract = {{This paper develops the multidimensional binary search tree (or k-d tree, where k is the dimensionality of the search space) as a data structure for storage of information to be retrieved by associative searches. The k-d tree is defined and examples are given. It is shown to be quite efficient in its storage requirements. A significant advantage of this structure is that a single data structure can handle many types of queries very efficiently. Various utility algorithms are developed; their proven average running times in an n record file are: insertion, O(log n); deletion of the root, O(n(k-1)/k); deletion of a random node, O(log n); and optimization (guarantees logarithmic performance of searches), O(n log n). Search algorithms are given for partial match queries with t keys specified [proven maximum running time of O(n(k-t)/k)] and for nearest neighbor queries [empirically observed average running time of O(log n).] These performances far surpass the best currently known algorithms for these tasks. An algorithm is presented to handle any general intersection query. The main focus of this paper is theoretical. It is felt, however, that k-d trees could be quite useful in many applications, and examples of potential uses are given.}},
    address = {New York, NY, USA},
    author = {Bentley, Jon L.},
    citeulike-article-id = {1044110},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=361007},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/361002.361007},
    doi = {10.1145/361002.361007},
    issn = {0001-0782},
    journal = {Commun. ACM},
    keywords = {data-structures, k-d-tree},
    month = sep,
    number = {9},
    pages = {509--517},
    posted-at = {2016-03-19 13:45:26},
    priority = {0},
    publisher = {ACM},
    title = {{Multidimensional Binary Search Trees Used for Associative Searching}},
    url = {http://dx.doi.org/10.1145/361002.361007},
    volume = {18},
    year = {1975}
}

@inproceedings{Kaplan1995Persistent,
    abstract = {{An abstract is not available.}},
    address = {New York, NY, USA},
    author = {Kaplan, Haim and Tarjan, Robert E.},
    booktitle = {Proceedings of the Twenty-seventh Annual ACM Symposium on Theory of Computing},
    citeulike-article-id = {13948822},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=225090},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/225058.225090},
    doi = {10.1145/225058.225090},
    isbn = {0-89791-718-9},
    keywords = {data-structures, functional},
    location = {Las Vegas, Nevada, USA},
    pages = {93--102},
    posted-at = {2016-03-02 15:55:30},
    priority = {5},
    publisher = {ACM},
    series = {STOC '95},
    title = {{Persistent Lists with Catenation via Recursive Slow-down}},
    url = {http://dx.doi.org/10.1145/225058.225090},
    year = {1995}
}

@book{Okasaki1999Purely,
    abstract = {{Most books on data structures assume an imperative language such as C or C++.
However, data structures for these languages do not always translate well to
functional languages such as Standard ML, Haskell, or Scheme. This book
describes data structures from the point of view of functional languages, with
examples, and presents design techniques that allow programmers to develop
their own functional data structures. The author includes both classical data
structures, such as red-black trees and binomial queues, and a host of new
data structures developed exclusively for functional languages. All source
code is given in Standard ML and Haskell, and most of the programs are easily
adaptable to other functional languages. This handy reference for professional
programmers working with functional languages can also be used as a tutorial
or for self-study.}},
    author = {Okasaki, Chris},
    citeulike-article-id = {2983293},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20&amp;path=ASIN/0521663504},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21&amp;path=ASIN/0521663504},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21&amp;path=ASIN/0521663504},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0521663504},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0521663504/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20&path=ASIN/0521663504},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0521663504},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0521663504},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0521663504&index=books&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0521663504},
    day = {13},
    howpublished = {Paperback},
    isbn = {0521663504},
    keywords = {algorithms, data-structures, functional},
    month = jun,
    posted-at = {2016-03-02 15:40:58},
    priority = {0},
    publisher = {Cambridge University Press},
    title = {{Purely Functional Data Structures}},
    url = {http://www.worldcat.org/isbn/0521663504},
    year = {1999}
}

@article{Finkel1974Quad,
    abstract = {{The quad tree is a data structure appropriate for storing information to be retrieved on composite keys. We discuss the specific case of two-dimensional retrieval, although the structure is easily generalised to arbitrary dimensions. Algorithms are given both for staightforward insertion and for a type of balanced insertion into quad trees. Empirical analyses show that the average time for insertion is logarithmic with the tree size. An algorithm for retrieval within regions is presented along with data from empirical studies which imply that searching is reasonably efficient. We define an optimized tree and present an algorithm to accomplish optimization in n log n time. Searching is guaranteed to be fast in optimized trees. Remaining problems include those of deletion from quad trees and merging of quad trees, which seem to be inherently difficult operations.}},
    author = {Finkel, R. A. and Bentley, J. L.},
    booktitle = {Acta Informatica},
    citeulike-article-id = {2583154},
    citeulike-linkout-0 = {https://www.researchgate.net/profile/Raphael_Finkel/publication/220197855_Quad_Trees_A_Data_Structure_for_Retrieval_on_Composite_Keys/links/0c9605273bba2ece7b000000.pdf},
    citeulike-linkout-1 = {http://dx.doi.org/10.1007/bf00288933},
    citeulike-linkout-2 = {http://www.springerlink.com/content/x7147683u3241843},
    citeulike-linkout-3 = {http://link.springer.com/article/10.1007/BF00288933},
    day = {1},
    doi = {10.1007/bf00288933},
    issn = {0001-5903},
    journal = {Acta Informatica},
    keywords = {data-structures, quad-tree},
    month = mar,
    number = {1},
    pages = {1--9},
    posted-at = {2016-03-01 15:13:20},
    priority = {0},
    publisher = {Springer-Verlag},
    title = {{Quad Trees A Data Structure for Retrieval on Composite Keys}},
    url = {https://www.researchgate.net/profile/Raphael_Finkel/publication/220197855_Quad_Trees_A_Data_Structure_for_Retrieval_on_Composite_Keys/links/0c9605273bba2ece7b000000.pdf},
    volume = {4},
    year = {1974}
}

@article{Boehm1995Ropes,
    abstract = {{this paper.  APPENDIX  All measurements in Figures 4, 5, and 6 are in user mode CPU microseconds on a SPARCstation 2 running running SunOS 4.1.2. We used version 4.1 of the package in Reference 1. The machine had enough memory (64 MB) that paging was not an issue. All programs were compiled with gcc and statically linked. Garbage collection times are included. The tests were run for enough iterations in the same heap to force several collections}},
    author = {Boehm, Hans-J and Atkinson, Russ and Plass, Michael},
    citeulike-article-id = {13947552},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.14.9450},
    keywords = {data-structures, ropes},
    posted-at = {2016-03-01 10:21:18},
    priority = {0},
    title = {{R}opes: an {A}lternative to {S}trings},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.14.9450},
    year = {1995}
}

@mastersthesis{Lorange2014Improving,
    author = {L'orange, Jean N.},
    citeulike-article-id = {13944393},
    citeulike-linkout-0 = {http://hypirion.com/thesis.pdf},
    keywords = {data-structures, relaxed-radix-balanced},
    month = jun,
    posted-at = {2016-02-29 16:40:40},
    priority = {0},
    school = {Norwegian University of Science and Technology},
    title = {{I}mproving {RRB-T}ree {P}erformance through {T}ransience},
    url = {http://hypirion.com/thesis.pdf},
    year = {2014}
}

@article{Tzannes2010Lazy,
    abstract = {{We present Lazy Binary Splitting (LBS), a user-level scheduler of nested parallelism for shared-memory multiprocessors that builds on existing Eager Binary Splitting work-stealing (EBS) implemented in Intel's Threading Building Blocks (TBB), but improves performance and ease-of-programming. In its simplest form (SP), EBS requires manual tuning by repeatedly running the application under carefully controlled conditions to determine a stop-splitting-threshold (sst)for every do-all loop in the code. This threshold limits the parallelism and prevents excessive overheads for fine-grain parallelism. Besides being tedious, this tuning also over-fits the code to some particular dataset, platform and calling context of the do-all loop, resulting in poor performance portability for the code. LBS overcomes both the performance portability and ease-of-programming pitfalls of a manually fixed threshold by adapting dynamically to run-time conditions without requiring tuning. We compare LBS to Auto-Partitioner (AP), the latest default scheduler of TBB, which does not require manual tuning either but lacks context portability, and outperform it by 38.9\% using TBB's default AP configuration, and by 16.2\% after we tuned AP to our experimental platform. We also compare LBS to SP by manually finding SP's sst using a training dataset and then running both on a different execution dataset. LBS outperforms SP by 19.5\% on average. while allowing for improved performance portability without requiring tedious manual tuning. LBS also outperforms SP with sst=1, its default value when undefined, by 56.7\%, and serializing work-stealing (SWS), another work-stealer by 54.7\%. Finally, compared to serializing inner parallelism (SI) which has been used by OpenMP, LBS is 54.2\% faster.}},
    address = {New York, NY, USA},
    author = {Tzannes, Alexandros and Caragea, George C. and Barua, Rajeev and Vishkin, Uzi},
    citeulike-article-id = {13938634},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1693479},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1837853.1693479},
    doi = {10.1145/1837853.1693479},
    issn = {0362-1340},
    journal = {SIGPLAN Not.},
    keywords = {parallel-programming, scheduling},
    month = jan,
    number = {5},
    pages = {179--190},
    posted-at = {2016-02-23 09:22:23},
    priority = {4},
    publisher = {ACM},
    title = {{Lazy Binary-splitting: A Run-time Adaptive Work-stealing Scheduler}},
    url = {http://dx.doi.org/10.1145/1837853.1693479},
    volume = {45},
    year = {2010}
}

@article{Hinze2006Finger,
    abstract = {{We introduce 2-3 finger trees, a functional representation of persistent sequences supporting access to the ends in amortized constant time, and concatenation and splitting in time logarithmic in the size of the smaller piece. Representations achieving these bounds have appeared previously, but 2-3 finger trees are much simpler, as are the operations on them. Further, by defining the split operation in a general form, we obtain a general purpose data structure that can serve as a sequence, priority queue, search tree, priority search queue and more.}},
    address = {New York, NY, USA},
    author = {Hinze, Ralf and Paterson, Ross},
    citeulike-article-id = {2399086},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1114674},
    citeulike-linkout-1 = {http://journals.cambridge.org/action/displayAbstract?fromPage=online&aid=398492},
    citeulike-linkout-2 = {http://dx.doi.org/10.1017/s0956796805005769},
    day = {16},
    doi = {10.1017/s0956796805005769},
    issn = {1469-7653},
    journal = {Journal of Functional Programming},
    keywords = {data-structures, functional-pearl, functional-programming},
    month = feb,
    number = {2},
    pages = {197--217},
    posted-at = {2016-02-19 10:51:58},
    priority = {0},
    publisher = {Cambridge University Press},
    title = {{Finger trees: a simple general-purpose data structure}},
    url = {http://dx.doi.org/10.1017/s0956796805005769},
    volume = {16},
    year = {2006}
}

@techreport{Bagwell2012RRBTrees,
    author = {Bagwell, Philip and Rompf, Tiark},
    citeulike-article-id = {13935778},
    citeulike-linkout-0 = {http://infoscience.epfl.ch/record/169879/files/RMTrees.pdf},
    day = {11},
    institution = {\'{E}cole polytechnique f\'{e}d\'{e}rale de Lausanne},
    keywords = {functional-programming, relaxed-radix-balanced, vectors},
    month = nov,
    posted-at = {2016-02-18 14:37:40},
    priority = {0},
    title = {{RRB-Trees: Efficient Immutable Vectors}},
    url = {http://infoscience.epfl.ch/record/169879/files/RMTrees.pdf},
    year = {2012}
}

@inproceedings{Stucki2015RRB,
    abstract = {{State-of-the-art immutable collections have wildly differing performance characteristics across their operations, often forcing programmers to choose different collection implementations for each task. Thus, changes to the program can invalidate the choice of collections, making code evolution costly. It would be desirable to have a collection that performs well for a broad range of operations. To this end, we present the RRB-Vector, an immutable sequence collection that offers good performance across a large number of sequential and parallel operations. The underlying innovations are: (1) the Relaxed-Radix-Balanced (RRB) tree structure, which allows efficient structural reorganization, and (2) an optimization that exploits spatio-temporal locality on the RRB data structure in order to offset the cost of traversing the tree. In our benchmarks, the RRB-Vector speedup for parallel operations is lower bounded by 7x when executing on 4 CPUs of 8 cores each. The performance for discrete operations, such as appending on either end, or updating and removing elements, is consistently good and compares favorably to the most important immutable sequence collections in the literature and in use today. The memory footprint of RRB-Vector is on par with arrays and an order of magnitude less than competing collections.}},
    address = {New York, NY, USA},
    author = {Stucki, Nicolas and Rompf, Tiark and Ureche, Vlad and Bagwell, Phil},
    booktitle = {Proceedings of the 20th ACM SIGPLAN International Conference on Functional Programming},
    citeulike-article-id = {13912198},
    citeulike-linkout-0 = {http://doi.acm.org/10.1145/2784731.2784739},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2784731.2784739},
    doi = {10.1145/2784731.2784739},
    keywords = {arrays, data, immutable, literature-review-2016-jan, radix-balanced, relaxed-radix-balanced, sequences, structures, trees, vectors},
    location = {Vancouver, BC, Canada},
    pages = {342--354},
    posted-at = {2016-02-17 13:45:53},
    priority = {0},
    publisher = {ACM},
    series = {ICFP 2015},
    title = {{RRB Vector: A Practical General Purpose Immutable Sequence}},
    url = {http://doi.acm.org/10.1145/2784731.2784739},
    year = {2015}
}

@inproceedings{Bergstrom2010Lazy,
    abstract = {{Nested data-parallelism (NDP) is a declarative style for programming irregular parallel applications. NDP languages provide language features favoring the NDP style, efficient compilation of NDP programs, and various common NDP operations like parallel maps, filters, and sum-like reductions. In this paper, we describe the implementation of NDP in Parallel ML (PML), part of the Manticore project. Managing the parallel decomposition of work is one of the main challenges of implementing NDP. If the decomposition creates too many small chunks of work, performance will be eroded by too much parallel overhead. If, on the other hand, there are too few large chunks of work, there will be too much sequential processing and processors will sit idle. Recently the technique of Lazy Binary Splitting was proposed for dynamic parallel decomposition of work on flat arrays, with promising results. We adapt Lazy Binary Splitting to parallel processing of binary trees, which we use to represent parallel arrays in PML. We call our technique Lazy Tree Splitting (LTS). One of its main advantages is its performance robustness: per-program tuning is not required to achieve good performance across varying platforms. We describe LTS-based implementations of standard NDP operations, and we present experimental data demonstrating the scalability of LTS across a range of benchmarks.}},
    address = {New York, NY, USA},
    author = {Bergstrom, Lars and Rainey, Mike and Reppy, John and Shaw, Adam and Fluet, Matthew},
    booktitle = {Proceedings of the 15th ACM SIGPLAN International Conference on Functional Programming},
    citeulike-article-id = {13912211},
    citeulike-linkout-0 = {http://doi.acm.org/10.1145/1863543.1863558},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1863543.1863558},
    doi = {10.1145/1863543.1863558},
    keywords = {compilers, languages, nested-data-parallel, run-time, scheduling, systems},
    location = {Baltimore, Maryland, USA},
    pages = {93--104},
    posted-at = {2016-02-17 13:45:21},
    priority = {0},
    publisher = {ACM},
    series = {ICFP '10},
    title = {{Lazy Tree Splitting}},
    url = {http://doi.acm.org/10.1145/1863543.1863558},
    year = {2010}
}

@article{Tzannes2014Lazy,
    abstract = {{Lazy scheduling is a runtime scheduler for task-parallel codes that effectively coarsens parallelism on load conditions in order to significantly reduce its overheads compared to existing approaches, thus enabling the efficient execution of more fine-grained tasks. Unlike other adaptive dynamic schedulers, lazy scheduling does not maintain any additional state to infer system load and does not make irrevocable serialization decisions. These two features allow it to scale well and to provide excellent load balancing in practice but at a much lower overhead cost compared to work stealing, the golden standard of dynamic schedulers. We evaluate three variants of lazy scheduling on a set of benchmarks on three different platforms and find it to substantially outperform popular work stealing implementations on fine-grained codes. Furthermore, we show that the vast performance gap between manually coarsened and fully parallel code is greatly reduced by lazy scheduling, and that, with minimal static coarsening, lazy scheduling delivers performance very close to that of fully tuned code. The tedious manual coarsening required by the best existing work stealing schedulers and its damaging effect on performance portability have kept novice and general-purpose programmers from parallelizing their codes. Lazy scheduling offers the foundation for a declarative parallel programming methodology that should attract those programmers by minimizing the need for manual coarsening and by greatly enhancing the performance portability of parallel code.}},
    address = {New York, NY, USA},
    author = {Tzannes, Alexandros and Caragea, George C. and Vishkin, Uzi and Barua, Rajeev},
    citeulike-article-id = {13934462},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2629643},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2629643},
    doi = {10.1145/2629643},
    issn = {0164-0925},
    journal = {ACM Trans. Program. Lang. Syst.},
    keywords = {parallel-programming, scheduling},
    month = sep,
    number = {3},
    posted-at = {2016-02-17 13:42:53},
    priority = {4},
    publisher = {ACM},
    title = {{Lazy Scheduling: A Runtime Adaptive Scheduler for Declarative Parallelism}},
    url = {http://dx.doi.org/10.1145/2629643},
    volume = {36},
    year = {2014}
}

@inproceedings{Weiser1981Program,
    abstract = {{Program slicing is a method used by experienced computer programmers for abstracting from programs. Starting from a subset of a program's behavior, slicing reduces that program to a minimal form which still produces that behavior. The reduced program, called a  ” slice”, is an independent program guaranteed to faithfully represent the original program within the domain of the specified subset of behavior.Finding a slice is in general unsolvable. A dataflow algorithm is presented for approximating slices when the behavior subset is specified as the values of a set of variables at a statement. Experimental evidence is presented that these slices are used by programmers during debugging. Experience with two automatic slicing tools is summarized. New measures of program complexity are suggested based on the organization of a program's slices.}},
    address = {Piscataway, NJ, USA},
    author = {Weiser, Mark},
    booktitle = {Proceedings of the 5th International Conference on Software Engineering},
    citeulike-article-id = {522778},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=802557},
    isbn = {0-89791-146-6},
    keywords = {data-flow, program-analysis},
    location = {San Diego, California, USA},
    pages = {439--449},
    posted-at = {2016-02-17 09:46:29},
    priority = {3},
    publisher = {IEEE Press},
    series = {ICSE '81},
    title = {{Program Slicing}},
    url = {http://portal.acm.org/citation.cfm?id=802557},
    year = {1981}
}

@techreport{Sestoft2006Spreadsheet,
    author = {Sestoft, Peter},
    citeulike-article-id = {13933607},
    citeulike-linkout-0 = {http://www.itu.dk/people/sestoft/funcalc/ITU-TR-2006-91.pdf},
    day = {28},
    institution = {IT University of Copenhagen},
    keywords = {spreadsheets},
    month = sep,
    posted-at = {2016-02-16 10:08:33},
    priority = {0},
    title = {{A Spreadsheet Core Implementation in C\#}},
    url = {http://www.itu.dk/people/sestoft/funcalc/ITU-TR-2006-91.pdf},
    year = {2006}
}

@article{Huet1997Zipper,
    abstract = {{Almost every programmer has faced the problem of representing a tree together with a subtree that is the focus of attention, where that focus may move left, right, up or down the tree. The Zipper is Huet's nifty name for a nifty data structure which fulfills this need. I wish I had known of it when I faced this task, because the solution I came up with was not quite so efficient or elegant as the Zipper.}},
    address = {New York, NY, USA},
    author = {Huet, G\'{e}rard},
    citeulike-article-id = {201777},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=969867.969872},
    citeulike-linkout-1 = {http://journals.cambridge.org/action/displayAbstract?fromPage=online&aid=44121},
    citeulike-linkout-2 = {http://dx.doi.org/10.1017/s0956796897002864},
    doi = {10.1017/s0956796897002864},
    issn = {1469-7653},
    journal = {Journal of Functional Programming},
    keywords = {functional-pearl, functional-programming, zippers},
    month = sep,
    number = {05},
    pages = {549--554},
    posted-at = {2016-02-11 12:11:55},
    priority = {0},
    publisher = {Cambridge University Press},
    title = {{The Zipper}},
    url = {http://dx.doi.org/10.1017/s0956796897002864},
    volume = {7},
    year = {1997}
}

@article{Hinze2001Weaving,
    abstract = {{Suppose, you want to implement a structured editor for some term type, so that the user can navigate through a given term and perform edit actions on subterms. In this case you are immediately faced with the problem of how to keep track of the cursor movements and the user\&apos;s edits in a reasonably efficient manner. In a previous pearl, Huet (1997) introduced a simple data structure, the Zipper, that addresses this problem – we will explain the Zipper briefly in section 2. A drawback of the Zipper is that the type of cursor locations depends on the structure of the term type, i.e. each term type gives rise to a different type of location (unless you are working in an untyped environment). In this pearl, we present an alternative data structure, the web, that serves the same purpose, but that is parametric in the underlying term type. Sections 3–6 are devoted to the new data structure. Before we unravel the Zipper and explore the web, let us first give a taste of their use.}},
    address = {New York, NY, USA},
    author = {Hinze, Ralf and Jeuring, Johan},
    citeulike-article-id = {2291159},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=968433},
    citeulike-linkout-1 = {http://journals.cambridge.org/action/displayAbstract?fromPage=online&aid=90859},
    citeulike-linkout-2 = {http://dx.doi.org/10.1017/s0956796801004129},
    doi = {10.1017/s0956796801004129},
    issn = {1469-7653},
    journal = {Journal of Functional Programming},
    keywords = {functional-programming, zippers},
    month = nov,
    number = {06},
    pages = {681--689},
    posted-at = {2016-02-11 12:10:52},
    priority = {2},
    publisher = {Cambridge University Press},
    title = {{Weaving a web}},
    url = {http://dx.doi.org/10.1017/s0956796801004129},
    volume = {11},
    year = {2001}
}

@inproceedings{Nanz2015Comparative,
    archivePrefix = {arXiv},
    author = {Nanz, Sebastian and Furia, Carlo A.},
    booktitle = {Software Engineering (ICSE), 2015 IEEE/ACM 37th IEEE International Conference on},
    citeulike-article-id = {13921810},
    citeulike-linkout-0 = {http://arxiv.org/abs/1409.0252},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/icse.2015.90},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7194625},
    doi = {10.1109/icse.2015.90},
    eprint = {1409.0252},
    institution = {Dept. of Comput. Sci., ETH Zurich, Zurich, Switzerland},
    keywords = {programming-language},
    month = may,
    pages = {778--788},
    posted-at = {2016-01-29 12:42:55},
    priority = {1},
    publisher = {IEEE},
    title = {{A Comparative Study of Programming Languages in Rosetta Code}},
    url = {http://arxiv.org/abs/1409.0252},
    volume = {1},
    year = {2015}
}

@inproceedings{petersen2008systematic,
    author = {Petersen, Kai and Feldt, Robert and Mujtaba, Shahid and Mattsson, Michael},
    booktitle = {12th International Conference on Evaluation and Assessment in Software Engineering},
    citeulike-article-id = {13883401},
    citeulike-linkout-0 = {http://www.rbsv.eu/courses/rmtw/mtrl/SM.pdf},
    keywords = {mapping-study, review, software-engineering, systematic},
    number = {1},
    organization = {sn},
    posted-at = {2015-12-14 13:28:39},
    priority = {1},
    title = {{Systematic mapping studies in software engineering}},
    url = {http://www.rbsv.eu/courses/rmtw/mtrl/SM.pdf},
    volume = {17},
    year = {2008}
}

@incollection{keele2007guidelines,
    author = {Kitchenham, Barbara and Charters, Stuart},
    booktitle = {Technical report, Ver. 2.3 EBSE Technical Report. EBSE},
    citeulike-article-id = {13883399},
    citeulike-linkout-0 = {http://www.cse.chalmers.se/~feldt/advice/kitchenham_2007_systematic_reviews_report_updated.pdf},
    keywords = {review, software-engineering, systematic},
    posted-at = {2015-12-14 13:24:27},
    priority = {0},
    title = {{Guidelines for performing systematic literature reviews in software engineering}},
    url = {http://www.cse.chalmers.se/~feldt/advice/kitchenham_2007_systematic_reviews_report_updated.pdf},
    year = {2007}
}

@inproceedings{Hermans2015Enrons,
    author = {Hermans, Felienne and Murphy-Hill, Emerson},
    booktitle = {Proceedings of the International Conference on Software Engineering, Software Engineering in Practice Track},
    citeulike-article-id = {13501892},
    citeulike-linkout-0 = {http://people.engr.ncsu.edu/ermurph3/papers/icse-seip-15.pdf},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/ICSE.2015.129},
    doi = {10.1109/ICSE.2015.129},
    keywords = {review, spreadsheets},
    posted-at = {2015-12-03 16:05:38},
    priority = {2},
    title = {{Enron's Spreadsheets and Related Emails: A Dataset and Analysis}},
    url = {http://people.engr.ncsu.edu/ermurph3/papers/icse-seip-15.pdf},
    year = {2015}
}

@phdthesis{Cheng2015Thesis,
    address = {45 rue d'Ulm, 75005 Paris, France},
    author = {Cheng, Tie},
    citeulike-article-id = {13851247},
    day = {23},
    institution = {INRIA},
    keywords = {spreadsheets, static-analysis, types},
    month = sep,
    posted-at = {2015-12-01 09:30:52},
    priority = {0},
    school = {\'{E}cole normale sup\'{e}rieure},
    title = {{Static Analysis of Spreadsheet Applications}},
    year = {2015}
}

@incollection{Nielson1999Type,
    author = {Nielson, Flemming and Nielson, HanneRiis and Hankin, Chris},
    booktitle = {Principles of Program Analysis},
    citeulike-article-id = {13849964},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-662-03811-6_5},
    citeulike-linkout-1 = {http://link.springer.com/chapter/10.1007/978-3-662-03811-6_5},
    doi = {10.1007/978-3-662-03811-6_5},
    keywords = {program-analysis, types},
    pages = {283--363},
    posted-at = {2015-11-30 09:39:23},
    priority = {2},
    publisher = {Springer Berlin Heidelberg},
    title = {{Type and Effect Systems}},
    url = {http://dx.doi.org/10.1007/978-3-662-03811-6_5},
    year = {1999}
}

@inproceedings{Hochstadt2010Logical,
    abstract = {{Programmers reason about their programs using a wide variety of formal and informal methods. Programmers in untyped languages such as Scheme or Erlang are able to use any such method to reason about the type behavior of their programs. Our type system for Scheme accommodates common reasoning methods by assigning variable occurrences a subtype of their declared type based on the predicates prior to the occurrence, a discipline dubbed occurrence typing. It thus enables programmers to enrich existing Scheme code with types, while requiring few changes to the code itself. Three years of practical experience has revealed serious shortcomings of our type system. In particular, it relied on a system of ad-hoc rules to relate combinations of predicates, it could not reason about subcomponents of data structures, and it could not follow sophisticated reasoning about the relationship among predicate tests, all of which are used in existing code. In this paper, we reformulate occurrence typing to eliminate these shortcomings. The new formulation derives propositional logic formulas that hold when an expression evaluates to true or false, respectively. A simple proof system is then used to determine types of variable occurrences from these propositions. Our implementation of this revised occurrence type system thus copes with many more untyped programming idioms than the original system.}},
    address = {New York, NY, USA},
    author = {Hochstadt, Sam T. and Felleisen, Matthias},
    booktitle = {Proceedings of the 15th ACM SIGPLAN International Conference on Functional Programming},
    citeulike-article-id = {9096570},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1863561},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1932681.1863561},
    doi = {10.1145/1932681.1863561},
    isbn = {978-1-60558-794-3},
    issn = {0362-1340},
    journal = {SIGPLAN Not.},
    keywords = {occurrence-typing, scheme, types},
    location = {Baltimore, Maryland, USA},
    month = sep,
    pages = {117--128},
    posted-at = {2015-11-27 10:20:18},
    priority = {3},
    publisher = {ACM},
    series = {ICFP '10},
    title = {{Logical Types for Untyped Languages}},
    url = {http://dx.doi.org/10.1145/1932681.1863561},
    volume = {45},
    year = {2010}
}

@inproceedings{Hochstadt2008Design,
    abstract = {{When scripts in untyped languages grow into large programs, maintaining them becomes difficult. A lack of types in typical scripting languages means that programmers must (re)discover critical pieces of design information every time they wish to change a program. This analysis step both slows down the maintenance process and may even introduce mistakes due to the violation of undiscovered invariants. This paper presents Typed Scheme, an explicitly typed extension of an untyped scripting language. Its type system is based on the novel notion of occurrence typing, which we formalize and mechanically prove sound. The implementation of Typed Scheme additionally borrows elements from a range of approaches, including recursive types, true unions and subtyping, plus polymorphism combined with a modicum of local inference. Initial experiments with the implementation suggest that Typed Scheme naturally accommodates the programming style of the underlying scripting language, at least for the first few thousand lines of ported code.}},
    address = {New York, NY, USA},
    author = {Hochstadt, Sam T. and Felleisen, Matthias},
    booktitle = {Proceedings of the 35th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages},
    citeulike-article-id = {2898847},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1328438.1328486},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1328438.1328486},
    doi = {10.1145/1328438.1328486},
    isbn = {978-1-59593-689-9},
    keywords = {occurrence-typing, scheme, types},
    location = {San Francisco, California, USA},
    pages = {395--406},
    posted-at = {2015-11-27 09:50:00},
    priority = {3},
    publisher = {ACM},
    series = {POPL '08},
    title = {{The Design and Implementation of Typed Scheme}},
    url = {http://dx.doi.org/10.1145/1328438.1328486},
    year = {2008}
}

@inproceedings{Damas1982Principal,
    abstract = {{An abstract is not available.}},
    address = {New York, NY, USA},
    author = {Damas, Luis and Milner, Robin},
    booktitle = {Proceedings of the 9th ACM SIGPLAN-SIGACT symposium on Principles of programming languages},
    citeulike-article-id = {370442},
    citeulike-linkout-0 = {http://web.cs.wpi.edu/~cs4536/c12/milner-damas_principal_types.pdf},
    citeulike-linkout-1 = {http://portal.acm.org/citation.cfm?id=582176},
    citeulike-linkout-2 = {http://dx.doi.org/10.1145/582153.582176},
    doi = {10.1145/582153.582176},
    isbn = {0-89791-065-6},
    keywords = {functional-programming, inference, types},
    location = {Albuquerque, New Mexico},
    pages = {207--212},
    posted-at = {2015-11-05 15:32:24},
    priority = {2},
    publisher = {ACM},
    series = {POPL '82},
    title = {{Principal type-schemes for functional programs}},
    url = {http://web.cs.wpi.edu/~cs4536/c12/milner-damas_principal_types.pdf},
    year = {1982}
}

@inproceedings{Cousot1979Systematic,
    abstract = {{Semantic analysis of programs is essential in optimizing
compilers and program verification systems. It encompasses data
flow analysis, data type determination, generation of approximate
invariant assertions, etc.

Several recent papers (among others Cousot \& Cousot[77a],
Graham \& Wegman[76], Kam \& Ullman[76], Kildall[73],
Rosen[78], Tarjan[76], Wegbreit[75]) have introduced abstract
approaches to program analysis which are tantamount to the use of a
program analysis framework (A,t,\~{a}) where A is a
lattice of (approximate) assertions, t is an (approximate)
predicate transformer and \~{a} is an often implicit function
specifying the meaning of the elements of A. This paper is devoted
to the systematic and correct design of program analysis frameworks
with respect to a formal semantics.

Preliminary definitions are given in Section 2 concerning the
merge over all paths and (least) fixpoint program-wide analysis
methods. In Section 3 we briefly define the (forward and backward)
deductive semantics of programs which is later used as a formal
basis in order to prove the correctness of the approximate program
analysis frameworks. Section 4 very shortly recall the main
elements of the lattice theoretic approach to approximate semantic
analysis of programs.

The design of a space of approximate assertions A is studied in
Section 5. We first justify the very reasonable assumption that A
must be chosen such that the exact invariant assertions of any
program must have an upper approximation in A and that the
approximate analysis of any program must be performed using a
deterministic process. These assumptions are shown to imply that A
is a Moore family, that the approximation operator (wich defines
the least upper approximation of any assertion) is an upper closure
operator and that A is necessarily a complete lattice. We next show
that the connection between a space of approximate assertions and a
computer representation is naturally made using a pair of isotone
adjoined functions. This type of connection between two complete
lattices is related to Galois connections thus making available
classical mathematical results. Additional results are proved, they
hold when no two approximate assertions have the same meaning.

In Section 6 we study and examplify various methods which can be
used in order to define a space of approximate assertions or
equivalently an approximation function. They include the
characterization of the least Moore family containing an arbitrary
set of assertions, the construction of the least closure operator
greater than or equal to an arbitrary approximation function, the
definition of closure operators by composition, the definition of a
space of approximate assertions by means of a complete join
congruence relation or by means of a family of principal
ideals.

Section 7 is dedicated to the design of the approximate
predicate transformer induced by a space of approximate assertions.
First we look for a reasonable definition of the correctness of
approximate predicate transformers and show that a local
correctness condition can be given which has to be verified for
every type of elementary statement. This local correctness
condition ensures that the (merge over all paths or fixpoint)
global analysis of any program is correct. Since isotony is not
required for approximate predicate transformers to be correct it is
shown that non-isotone program analysis frameworks are manageable
although it is later argued that the isotony hypothesis is natural.
We next show that among all possible approximate predicate
transformers which can be used with a given space of approximate
assertions there exists a best one which provides the maximum
information relative to a program-wide analysis method. The best
approximate predicate transformer induced by a space of approximate
assertions turns out to be isotone. Some interesting consequences
of the existence of a best predicate transformer are examined. One
is that we have in hand a formal specification of the programs
which have to be written in order to implement a program analysis
framework once a representation of the space of approximate
assertions has been chosen. Examples are given, including ones
where the semantics of programs is formalized using Hoare[78]'s
sets of traces.

In Section 8 we show that a hierarchy of approximate analyses
can be defined according to the fineness of the approximations
specified by a program analysis framework. Some elements of the
hierarchy are shortly exhibited and related to the relevant
literature.

In Section 9 we consider global program analysis methods. The
distinction between "distributive" and "non-distributive" program
analysis frameworks is studied. It is shown that when the best
approximate predicate transformer is considered the coincidence or
not of the merge over all paths and least fixpoint global analyses
of programs is a consequence of the choice of the space of
approximate assertions. It is shown that the space of approximate
assertions can always be refined so that the merge over all paths
analysis of a program can be defined by means of a least fixpoint
of isotone equations.

Section 10 is devoted to the combination of program analysis
frameworks. We study and examplify how to perform the "sum",
"product" and "power" of program analysis frameworks. It is shown
that combined analyses lead to more accurate information than the
conjunction of the corresponding separate analyses but this can
only be achieved by a new design of the approximate predicate
transformer induced by the combined program analysis
frameworks.}},
    address = {New York, NY, USA},
    author = {Cousot, Patrick and Cousot, Radhia},
    booktitle = {Proceedings of the 6th ACM SIGACT-SIGPLAN Symposium on Principles of Programming Languages},
    citeulike-article-id = {225306},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=567778},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/567752.567778},
    doi = {10.1145/567752.567778},
    keywords = {abstract-interpretation, data-flow},
    location = {San Antonio, Texas},
    pages = {269--282},
    posted-at = {2015-11-05 15:24:53},
    priority = {1},
    publisher = {ACM},
    series = {POPL '79},
    title = {{Systematic Design of Program Analysis Frameworks}},
    url = {http://dx.doi.org/10.1145/567752.567778},
    year = {1979}
}

@incollection{Cheng2012Abstract,
    author = {Cheng, Tie and Rival, Xavier},
    booktitle = {Static Analysis},
    citeulike-article-id = {13828903},
    citeulike-linkout-0 = {http://www.di.ens.fr/~chengtie/pubs/paper_48.pdf},
    citeulike-linkout-1 = {http://dx.doi.org/10.1007/978-3-642-33125-1_9},
    citeulike-linkout-2 = {http://link.springer.com/chapter/10.1007/978-3-642-33125-1_9},
    doi = {10.1007/978-3-642-33125-1_9},
    editor = {Min\'{e}, Antoine and Schmidt, David},
    keywords = {abstract-interpretation, spreadsheets, types, zones},
    pages = {94--110},
    posted-at = {2015-11-05 13:20:25},
    priority = {3},
    publisher = {Springer Berlin Heidelberg},
    series = {Lecture Notes in Computer Science},
    title = {{An Abstract Domain to Infer Types over Zones in Spreadsheets}},
    url = {http://www.di.ens.fr/~chengtie/pubs/paper_48.pdf},
    volume = {7460},
    year = {2012}
}

@inproceedings{Cousot1977Abstract,
    abstract = {A program denotes computations in some universe of objects. Abstract interpretation of programs consists in using that denotation to describe computations in another universe of abstract objects, so that the results of abstract execution give some information on the actual computations. An intuitive example (which we borrow from Sintzoff [72]) is the rule of signs. The text -1515 * 17 may be understood to denote computations on the abstract universe {(+), (-), (±)} where the semantics of arithmetic operators is defined by the rule of signs. The abstract execution -1515 * 17 → -(+) * (+) → (-) * (+) → (-), proves that -1515 * 17 is a negative number. Abstract interpretation is concerned by a particular underlying structure of the usual universe of computations (the sign, in our example). It gives a summary of some facets of the actual executions of a program. In general this summary is simple to obtain but inaccurate (e.g. -1515 + 17 → -(+) + (+) → (-) + (+) → (±)). Despite its fundamentally incomplete results abstract interpretation allows the programmer or the compiler to answer questions which do not need full knowledge of program executions or which tolerate an imprecise answer, (e.g. partial correctness proofs of programs ignoring the termination problems, type checking, program optimizations which are not carried in the absence of certainty about their feasibility, …).},
    address = {New York, NY, USA},
    author = {Cousot, Patrick and Cousot, Radhia},
    booktitle = {Proceedings of the 4th ACM SIGACT-SIGPLAN Symposium on Principles of Programming Languages},
    citeulike-article-id = {120466},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=512973},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/512950.512973},
    doi = {10.1145/512950.512973},
    keywords = {abstract-interpretation, data-flow},
    location = {Los Angeles, California},
    pages = {238--252},
    posted-at = {2015-11-02 10:40:10},
    priority = {3},
    publisher = {ACM},
    series = {POPL '77},
    title = {{Abstract Interpretation: A Unified Lattice Model for Static Analysis of Programs by Construction or Approximation of Fixpoints}},
    url = {http://dx.doi.org/10.1145/512950.512973},
    year = {1977}
}

@incollection{Cheng2015Static,
    author = {Cheng, Tie and Rival, Xavier},
    booktitle = {Programming Languages and Systems},
    citeulike-article-id = {13822912},
    citeulike-linkout-0 = {http://www.di.ens.fr/~chengtie/pubs/esop.pdf},
    citeulike-linkout-1 = {http://dx.doi.org/10.1007/978-3-662-46669-8_2},
    citeulike-linkout-2 = {http://link.springer.com/chapter/10.1007/978-3-662-46669-8_2},
    doi = {10.1007/978-3-662-46669-8_2},
    editor = {Vitek, Jan},
    keywords = {abstract-interpretation, data-flow, spreadsheets, types, zones},
    pages = {26--52},
    posted-at = {2015-11-02 09:47:01},
    priority = {3},
    publisher = {Springer Berlin Heidelberg},
    series = {Lecture Notes in Computer Science},
    title = {{Static Analysis of Spreadsheet Applications for Type-Unsafe Operations Detection}},
    url = {http://www.di.ens.fr/~chengtie/pubs/esop.pdf},
    volume = {9032},
    year = {2015}
}

@misc{Wack1991Proposal,
    abstract = {{In this paper we have extolled the virtues of a data driven program, in some instances it may be desirable for a program to be both demand and data driven. A very simple common example is the telephone system. When someone calls you, the phone rings and alerts you that someone wishes to talk to you. In this case, the phone system is acting in a data driven mode. If it were demand driven, you would have to constantly pick up the phone and check to see if anybody wanted to talk to you. However, when you wish to place a call, you pick up the phone and dial the number of the party with which you wish to speak. In this case, you are placing a demand to the telephone company computers to contact a specific phone. This is much simpler than any data driven system we could create. So, it seems apparent that while being data-driven is a good thing in many instances, there may be times when it is desirable to be demand driven. For instance, the demand driven strategy, amounting to lazy evaluation, can be beneficial in circumstances when a cell contains a large amount of information (computationally) that you would only like viewed on user request. Thus, this brings us to the "new and improved" definition of a spreadsheet:}},
    author = {Wack, Andrew P.},
    citeulike-article-id = {13815527},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.52.3620},
    posted-at = {2015-10-28 10:43:27},
    priority = {2},
    title = {{A Proposal for a Powerful, Efficient, Algebraic Reduction, Parallel Spreadsheet}},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.52.3620},
    year = {1991}
}

@article{wack1991proposal,
    author = {Wack, Andrew P.},
    citeulike-article-id = {13815525},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.52.3620&#38;rep=rep1&#38;type=pdf},
    keywords = {parallel-programming, spreadsheets},
    posted-at = {2015-10-28 10:41:02},
    priority = {2},
    publisher = {Citeseer},
    title = {{A Proposal for a Powerful, Efficient, Algebraic Reduction, Parallel Spreadsheet}},
    url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.52.3620&#38;rep=rep1&#38;type=pdf},
    year = {1991}
}

@incollection{Gibbons1994Third,
    abstract = {{The Third Homomorphism Theorem is a folk theorem of the constructive algorithmics
community. It states that a function on lists that can be computed both from left to right
and from right to left is necessarily a list homomorphism---it can be computed according
to any parenthesization of the list.
We formalize and prove the theorem, and use it to improve an O(n

2

) sorting algorithm
to O(n log n).
1 Introduction

List homomorphisms are those functions on finite lists that promote through
...}},
    author = {Gibbons, Jeremy},
    booktitle = {Proceedings Computing, the Australian Theory Seminar, CATS'94, Sydney, Australia, 17--19 Dec 1994},
    citeulike-article-id = {928790},
    citeulike-linkout-0 = {https://researchspace.auckland.ac.nz/bitstream/handle/2292/3514/005thirdht.pdf?sequence=1},
    citeulike-linkout-1 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.45.2247},
    editor = {Jay, C. B.},
    keywords = {functional-programming, parallel-programming},
    posted-at = {2015-10-23 06:16:24},
    priority = {2},
    publisher = {Univ.\ of Techn., Sidney},
    title = {{The Third Homomorphism Theorem}},
    url = {https://researchspace.auckland.ac.nz/bitstream/handle/2292/3514/005thirdht.pdf?sequence=1},
    year = {1994}
}

@article{Hu2015How,
    abstract = {{In 1989 when functional programming was still considered a niche topic, Hughes wrote a visionary paper arguing convincingly 'why functional programming matters'. More than two decades have passed. Has functional programming really mattered? Our answer is a resounding 'Yes!'. Functional programming is now at the forefront of a new generation of programming technologies, and enjoying increasing popularity and influence. In this paper, we review the impact of functional programming, focusing on how it has changed the way we may construct programs, the way we may verify programs, and fundamentally the way we may think about programs.}},
    author = {Hu, Zhenjiang and Hughes, John and Wang, Meng},
    citeulike-article-id = {13768895},
    citeulike-linkout-0 = {http://dx.doi.org/10.1093/nsr/nwv042},
    citeulike-linkout-1 = {http://nsr.oxfordjournals.org/content/2/3/349.abstract},
    citeulike-linkout-2 = {http://nsr.oxfordjournals.org/content/2/3/349.full.pdf},
    day = {01},
    doi = {10.1093/nsr/nwv042},
    issn = {2053-714X},
    journal = {National Science Review},
    keywords = {functional-programming, review},
    month = sep,
    number = {3},
    pages = {349--370},
    posted-at = {2015-10-23 05:57:06},
    priority = {3},
    publisher = {Oxford University Press},
    title = {{How functional programming mattered}},
    url = {http://dx.doi.org/10.1093/nsr/nwv042},
    volume = {2},
    year = {2015}
}

@article{Abraham2007UCheck,
    abstract = {{Spreadsheets are widely used, and studies have shown that most end-user spreadsheets contain non-trivial errors. Most of the currently available tools that try to mitigate this problem require varying levels of user intervention. This paper presents a system, called UCheck, that detects errors in spreadsheets automatically. UCheck carries out automatic header and unit inference, and reports unit errors to the users. UCheck is based on two static analyses phases that infer header and unit information for all cells in a spreadsheet. We have tested UCheck on a wide variety of spreadsheets and found that it works accurately and reliably. The system was also used in a continuing education course for high school teachers, conducted through Oregon State University, aimed at making the participants aware of the need for quality control in the creation of spreadsheets.}},
    author = {Abraham, Robin and Erwig, Martin},
    citeulike-article-id = {13805425},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.jvlc.2006.06.001},
    doi = {10.1016/j.jvlc.2006.06.001},
    issn = {1045926X},
    journal = {Journal of Visual Languages \& Computing},
    keywords = {spreadsheets, types},
    month = feb,
    number = {1},
    pages = {71--95},
    posted-at = {2015-10-19 06:07:14},
    priority = {2},
    title = {{UCheck: A spreadsheet type checker for end users}},
    url = {http://dx.doi.org/10.1016/j.jvlc.2006.06.001},
    volume = {18},
    year = {2007}
}

@inproceedings{Ahmad2003Type,
    author = {Ahmad, Yanif and Antoniu, Tudor and Goldwater, Sharon and Krishnamurthi, Shriram},
    booktitle = {Automated Software Engineering, 2003. Proceedings. 18th IEEE International Conference on},
    citeulike-article-id = {13805424},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/ase.2003.1240305},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1240305},
    doi = {10.1109/ase.2003.1240305},
    institution = {Dept. of Comput. Sci., Brown Univ., Providence, RI, USA},
    isbn = {0-7695-2035-9},
    issn = {1938-4300},
    keywords = {spreadsheets, types},
    month = oct,
    pages = {174--183},
    posted-at = {2015-10-19 06:03:52},
    priority = {3},
    publisher = {IEEE},
    title = {{A type system for statically detecting spreadsheet errors}},
    url = {http://dx.doi.org/10.1109/ase.2003.1240305},
    year = {2003}
}

@misc{Oppenheimer2009More,
    author = {Oppenheimer, Diego},
    citeulike-article-id = {13805394},
    citeulike-linkout-0 = {https://blogs.office.com/2009/09/08/more-on-performance-improvements-in-excel-2010/},
    day = {8},
    howpublished = {Blog post},
    keywords = {multithreading, spreadsheets, website},
    month = sep,
    note = {Retrieved on 19.10.2015},
    posted-at = {2015-10-19 04:54:22},
    priority = {0},
    title = {{More on Performance Improvements in Excel 2010}},
    url = {https://blogs.office.com/2009/09/08/more-on-performance-improvements-in-excel-2010/},
    year = {2009}
}

@misc{Oppenheimer2005Multithreaded,
    author = {Oppenheimer, Diego},
    citeulike-article-id = {13805383},
    citeulike-linkout-0 = {https://blogs.office.com/2005/11/03/multi-threaded-calculation-in-excel-or-how-calculation-can-become-much-faster-in-excel-12/},
    day = {3},
    howpublished = {Blog post},
    keywords = {multithreading, spreadsheets, website},
    month = nov,
    note = {Retrieved on 19.10.2015},
    posted-at = {2015-10-19 04:43:29},
    priority = {0},
    title = {{Multi-threaded calculation in Excel, or  ” how calculation can become much faster in Excel 12”}},
    url = {https://blogs.office.com/2005/11/03/multi-threaded-calculation-in-excel-or-how-calculation-can-become-much-faster-in-excel-12/},
    year = {2005}
}

@misc{Abramson2001Parallel,
    author = {Abramson, D. and Roe, P.},
    citeulike-article-id = {13805379},
    citeulike-linkout-0 = {https://www.google.com/patents/US20010056440},
    keywords = {multithreading, patent, spreadsheets},
    month = dec,
    note = {US Patent App. 09/891,951},
    posted-at = {2015-10-19 04:25:15},
    priority = {2},
    publisher = {Google Patents},
    title = {{Parallel execution mechanism for spreadsheets}},
    url = {https://www.google.com/patents/US20010056440},
    year = {2001}
}

@misc{Adler2000System,
    author = {Adler, D. and Salama, R.},
    citeulike-article-id = {13805378},
    citeulike-linkout-0 = {https://www.google.com/patents/US6138130},
    keywords = {patent, spreadsheets, types},
    month = oct,
    note = {US Patent 6,138,130},
    posted-at = {2015-10-19 04:25:15},
    priority = {2},
    publisher = {Google Patents},
    title = {{System and method for processing data in an electronic spreadsheet in accordance with a data type}},
    url = {https://www.google.com/patents/US6138130},
    year = {2000}
}

@misc{Duzak2011Multithread,
    author = {Duzak, J. J. and Becker, A. and Androski, M. J. and Campbell, D.},
    citeulike-article-id = {13805377},
    citeulike-linkout-0 = {https://www.google.com/patents/US8032821},
    keywords = {multithreading, patent, spreadsheets},
    month = oct,
    note = {US Patent 8,032,821},
    posted-at = {2015-10-19 04:25:15},
    priority = {0},
    publisher = {Google Patents},
    title = {{Multi-thread spreadsheet processing with dependency levels}},
    url = {https://www.google.com/patents/US8032821},
    year = {2011}
}

@inproceedings{Chamberlain1999Regions,
    abstract = {{Most array languages, including Fortran 90, Matlab, and APL, provide support for referencing arrays by extending the traditional array subscripting construct found in scalar languages. We present an alternative to subscripting that exploits the concept of regions---an index set representation that can be named, manipulated with high-level operators, and syntactically separated from array references. This paper develops the concept of region-based programming and describes its benefits in the context of an idealized array language called RL. We show that regions simplify programming, reduce the likelihood of errors, and enable code reuse. Furthermore, we describe how regions accentuate the locality of array expressions and how this locality is important when targeting parallel computers. We also show how the concepts of region-based programming have been used in ZPL, a fully-implemented practical parallel programming language in use by scientists and engineers. In addition, we contrast region-based programming with the array reference constructs of other array languages.}},
    address = {New York, NY, USA},
    author = {Chamberlain, Bradford L. and Lewis, E. Christopher and Lin, Calvin and Snyder, Lawrence},
    booktitle = {Proceedings of the Conference on APL '99 : On Track to the 21st Century: On Track to the 21st Century},
    citeulike-article-id = {13803789},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=312627.312713},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/312627.312713},
    doi = {10.1145/312627.312713},
    isbn = {1-58113-126-7},
    keywords = {array-programming, zpl},
    location = {Scranton, Pennsylvania, USA},
    pages = {41--49},
    posted-at = {2015-10-16 10:27:56},
    priority = {0},
    publisher = {ACM},
    series = {APL '99},
    title = {{Regions: An Abstraction for Expressing Array Computation}},
    url = {http://dx.doi.org/10.1145/312627.312713},
    year = {1999}
}

@inproceedings{Chamberlain1998ZPLs,
    abstract = {{An abstract is not available.}},
    address = {Washington, DC, USA},
    author = {Chamberlain, B. and Choi, S. and Lewis, E. and Lin, C. and Snyder, L. and Weathersby, W.},
    booktitle = {Proceedings of the High-Level Parallel Programming Models and Supportive Environments},
    citeulike-article-id = {13803619},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=822265},
    isbn = {0-8186-8412-7},
    keywords = {array-programming, parallel-programming, performance, zpl},
    posted-at = {2015-10-16 05:07:57},
    priority = {2},
    publisher = {IEEE Computer Society},
    series = {HIPS '98},
    title = {{ZPL's WYSIWYG Performance Model}},
    url = {http://portal.acm.org/citation.cfm?id=822265},
    year = {1998}
}

@inproceedings{Lippmeier2013Data,
    abstract = {{Existing approaches to array fusion can deal with straight-line producer consumer pipelines, but cannot fuse branching data flows where a generated array is consumed by several different consumers. Branching data flows are common and natural to write, but a lack of fusion leads to the creation of an intermediate array at every branch point. We present a new array fusion system that handles branches, based on Waters's series expression framework, but extended to work in a functional setting. Our system also solves a related problem in stream fusion, namely the introduction of duplicate loop counters. We demonstrate speedup over existing fusion systems for several key examples.}},
    address = {New York, NY, USA},
    author = {Lippmeier, Ben and Chakravarty, Manuel M. T. and Keller, Gabriele and Robinson, Amos},
    booktitle = {Proceedings of the 2013 ACM SIGPLAN Symposium on Haskell},
    citeulike-article-id = {13803607},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2503782},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2503778.2503782},
    doi = {10.1145/2503778.2503782},
    isbn = {978-1-4503-2383-3},
    keywords = {fusion, haskell, repa, streams},
    location = {Boston, Massachusetts, USA},
    pages = {93--104},
    posted-at = {2015-10-16 04:27:26},
    priority = {2},
    publisher = {ACM},
    series = {Haskell '13},
    title = {{Data Flow Fusion with Series Expressions in Haskell}},
    url = {http://dx.doi.org/10.1145/2503778.2503782},
    year = {2013}
}

@inproceedings{Hansen2015GazeWatch,
    abstract = {{We demonstrate potentials of adding a gaze tracking unit to a smartwatch, allowing hands-free interaction with the watch itself and control of the environment. Users give commands via gaze gestures, i.e. looking away and back to the GazeWatch. Rapid presentation of single words on the watch display provides a rich and effective textual interface. Finally, we exemplify how the GazeWatch can be used as a ubiquitous pointer on large displays.}},
    address = {New York, NY, USA},
    author = {Hansen, John P. and Biermann, Florian and M{\o}llenbach, Emilie and Lund, Haakon and San Agustin, Javier and Sztuk, Sebastian},
    booktitle = {Proceedings of the 17th International Conference on Human-Computer Interaction with Mobile Devices and Services Adjunct},
    citeulike-article-id = {13801108},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2786567.2792899},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2786567.2792899},
    doi = {10.1145/2786567.2792899},
    isbn = {978-1-4503-3653-6},
    keywords = {gaze-tracking},
    location = {Copenhagen, Denmark},
    pages = {615--621},
    posted-at = {2015-10-13 08:39:04},
    priority = {0},
    publisher = {ACM},
    series = {MobileHCI '15},
    title = {{A GazeWatch Prototype}},
    url = {http://dx.doi.org/10.1145/2786567.2792899},
    year = {2015}
}

@inproceedings{Hansen2015Gaze,
    abstract = {{Mobile gaze interaction is challenged by inherent motor noise. We examined the gaze tracking accuracy and precision of twelve subjects wearing a gaze tracker on their wrist while standing and walking. Results suggest that it will be possible to detect whether people are glancing the watch, but not where on the screen they are looking. To counter the motor noise we present a word-by-word textual UI that shows temporary command options to be executed by gaze-strokes. Twenty-seven participants conducted a simulated smartwatch task and were able to reliably perform commands that would adjust the speed of word presentation or make regressions. We discuss future design and usage options for a textual smartwatch gaze interface.}},
    address = {New York, NY, USA},
    author = {Hansen, John P. and Biermann, Florian and Madsen, Janus A. and Jonassen, Morten and Lund, Haakon and San Agustin, Javier and Sztuk, Sebastian},
    booktitle = {Proceedings of the 2015 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2015 ACM International Symposium on Wearable Computers},
    citeulike-article-id = {13801102},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2800835.2804332},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2800835.2804332},
    doi = {10.1145/2800835.2804332},
    isbn = {978-1-4503-3575-1},
    keywords = {gaze-tracking},
    location = {Osaka, Japan},
    pages = {839--847},
    posted-at = {2015-10-13 08:38:32},
    priority = {0},
    publisher = {ACM},
    series = {UbiComp '15},
    title = {{A Gaze Interactive Textual Smartwatch Interface}},
    url = {http://dx.doi.org/10.1145/2800835.2804332},
    year = {2015}
}

@inproceedings{Chakravarty2007Data,
    abstract = {{We describe the design and current status of our effort to implement the programming model of nested data parallelism into the Glasgow Haskell Compiler. We extended the original programming model and its implementation, both of which were first popularised by the NESL language, in terms of expressiveness as well as efficiency. Our current aim is to provide a convenient programming environment for SMP parallelism, and especially multicore architectures. Preliminary benchmarks show that we are, at least for some programs, able to achieve good absolute performance and excellent speedups.}},
    address = {New York, NY, USA},
    author = {Chakravarty, Manuel M. T. and Leshchinskiy, Roman and Jones, Simon P. and Keller, Gabriele and Marlow, Simon},
    booktitle = {Proceedings of the 2007 Workshop on Declarative Aspects of Multicore Programming},
    citeulike-article-id = {1652960},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1248652},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1248648.1248652},
    doi = {10.1145/1248648.1248652},
    isbn = {978-1-59593-690-5},
    keywords = {array-programming, dph, nested-parallelism, parallel-programming},
    location = {Nice, France},
    pages = {10--18},
    posted-at = {2015-10-06 12:52:17},
    priority = {1},
    publisher = {ACM},
    series = {DAMP '07},
    title = {{Data Parallel Haskell: A Status Report}},
    url = {http://dx.doi.org/10.1145/1248648.1248652},
    year = {2007}
}

@book{Blelloch1990Vector,
    author = {Blelloch, Guy E.},
    citeulike-article-id = {13795990},
    citeulike-linkout-0 = {https://www.cs.cmu.edu/afs/cs.cmu.edu/Web/People/blelloch/papers/Ble90.pdf},
    keywords = {flattening, nesl, parallel-programming},
    posted-at = {2015-10-06 10:33:40},
    priority = {3},
    title = {{Vector models for data-parallel computing}},
    url = {https://www.cs.cmu.edu/afs/cs.cmu.edu/Web/People/blelloch/papers/Ble90.pdf},
    volume = {356},
    year = {1990}
}

@inproceedings{Blelloch1996Provable,
    abstract = {{In this paper we prove time and space bounds for the implementation of the programming language NESL on various parallel machine models. NESL is a sugared typed \&amp;lambda;-calculus with a set of array primitives and an explicit parallel map over arrays. Our results extend previous work on provable implementation bounds for functional languages by considering space and by including arrays. For modeling the cost of NESL we augment a standard call-by-value operational semantics to return two cost measures: a DAG representing the sequential dependence in the computation, and a measure of the space taken by a sequential implementation. We show that a NESL program with  w  work (nodes in the DAG),  d  depth (levels in the DAG), and  s  sequential space can be implemented on a  p  processor butterfly network, hypercube, or CRCW PRAM using  O ( w/p  +  d  log  p ) time and  O ( s  +  dp  log  p ) reachable space. 1  For programs with sufficient parallelism these bounds are optimal in that they give linear speedup and use space within a constant factor of the sequential space.}},
    address = {New York, NY, USA},
    author = {Blelloch, Guy E. and Greiner, John},
    booktitle = {ICFP '96: Proceedings of the first ACM SIGPLAN international conference on Functional programming},
    citeulike-article-id = {5309362},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=232650},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/232627.232650},
    doi = {10.1145/232627.232650},
    isbn = {0-89791-770-7},
    keywords = {cost-function, nesl, parallel-programming},
    location = {Philadelphia, Pennsylvania, United States},
    pages = {213--225},
    posted-at = {2015-10-01 14:19:09},
    priority = {3},
    publisher = {ACM},
    title = {{A provable time and space efficient implementation of NESL}},
    url = {http://dx.doi.org/10.1145/232627.232650},
    year = {1996}
}

@techreport{Blelloch1993NESL,
    address = {Pittsburgh, PA, USA},
    author = {Blelloch, Guy E.},
    citeulike-article-id = {1659234},
    citeulike-linkout-0 = {http://www.cs.cmu.edu/afs/cs.cmu.edu/project/scandal/public/papers/CMU-CS-95-170.html},
    citeulike-linkout-1 = {http://portal.acm.org/citation.cfm?id=865114},
    keywords = {array-programming, nesl, parallel-programming},
    posted-at = {2015-10-01 14:18:20},
    priority = {1},
    publisher = {Carnegie Mellon University},
    title = {{NESL: A Nested Data-Parallel Language (Version 2.6)}},
    url = {http://www.cs.cmu.edu/afs/cs.cmu.edu/project/scandal/public/papers/CMU-CS-95-170.html},
    year = {1993}
}

@electronic{Jones2008Harnessing,
    abstract = {{ABSTRACT. If you want to program a parallel computer, a purely functional language like Haskell is a promising starting point. Since the language is pure, it is by-default safe for parallel evaluation, whereas imperative languages are by-default unsafe. But that doesn't make it easy! Indeed it has proved quite difficult to get robust, scalable performance increases through parallel functional programming, especially as the number of processors increases. A particularly promising and well-studied approach to employing large numbers of processors is data parallelism. Blelloch's pioneering work on NESL showed that it was possible to combine a rather flexible programming model (nested data parallelism) with a fast, scalable execution model (flat data parallelism). In this paper we describe Data Parallel Haskell, which embodies nested data parallelism in a modern, general-purpose language, implemented in a state-of-the-art compiler, GHC. We focus particularly on the vectorisation transformation, which transforms nested to flat data parallelism. 1}},
    author = {Jones, Simon P. and Leshchinskiy, Roman and Keller, Gabriele and Chakravarty, Manuel M. T.},
    citeulike-article-id = {7678717},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.141.1748},
    keywords = {array-programming, functional-programming, haskell, parallel-programming, streams},
    posted-at = {2015-10-01 13:09:24},
    priority = {3},
    title = {{Harnessing the Multicores: Nested Data Parallelism in Haskell}},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.141.1748},
    year = {2008}
}

@misc{R-Packages2015,
    citeulike-article-id = {13779959},
    citeulike-linkout-0 = {https://cran.r-project.org/web/packages/},
    keywords = {rlang, website},
    note = {Retrieved on 01.10.2015},
    posted-at = {2015-10-01 09:10:01},
    priority = {0},
    title = {{Available CRAN Packages By Name}},
    url = {https://cran.r-project.org/web/packages/}
}

@misc{Eddelbuettel2015CRAN,
    author = {Eddelbuettel, Dirk},
    citeulike-article-id = {13778895},
    citeulike-linkout-0 = {https://cran.r-project.org/web/views/HighPerformanceComputing.html},
    day = {31},
    keywords = {parallel-programming, rlang},
    month = jul,
    note = {Retrieved on 29.09.2015},
    posted-at = {2015-09-30 13:18:43},
    priority = {0},
    title = {{CRAN Task View: High-Performance and Parallel Computing with R}},
    url = {https://cran.r-project.org/web/views/HighPerformanceComputing.html},
    year = {2015}
}

@misc{Weston2014Getting,
    author = {Weston, Steve},
    citeulike-article-id = {13778011},
    citeulike-linkout-0 = {https://cran.r-project.org/web/packages/doMC/vignettes/gettingstartedMC.pdf},
    day = {26},
    keywords = {array-programming, parallel-programming, review},
    month = feb,
    note = {Retrieved on 28.09.2015},
    posted-at = {2015-09-29 16:06:29},
    priority = {0},
    title = {{Getting Started with doMC and foreach}},
    url = {https://cran.r-project.org/web/packages/doMC/vignettes/gettingstartedMC.pdf},
    year = {2014}
}

@manual{RInternals2015,
    author = {R Core Team},
    citeulike-article-id = {13777074},
    citeulike-linkout-0 = {https://cran.r-project.org/doc/manuals/r-release/R-ints.pdf},
    day = {14},
    edition = {3.3.2},
    howpublished = {https://cran.r-project.org/doc/manuals/r-release/R-ints.pdf},
    keywords = {array-programming, rlang},
    month = aug,
    note = {Retrieved on 28.09.2015},
    posted-at = {2015-09-28 14:59:22},
    priority = {1},
    publisher = {Available from CRAN website},
    title = {{R Internals}},
    url = {https://cran.r-project.org/doc/manuals/r-release/R-ints.pdf},
    year = {2015}
}

@manual{RLangDef2015,
    author = {R Core Team},
    citeulike-article-id = {13777065},
    citeulike-linkout-0 = {https://cran.r-project.org/doc/manuals/r-release/R-lang.pdf},
    day = {14},
    edition = {3.3.2},
    howpublished = {https://cran.r-project.org/doc/manuals/r-release/R-lang.pdf},
    month = aug,
    note = {Retrieved on 28.09.2015},
    posted-at = {2015-09-28 14:53:05},
    priority = {1},
    publisher = {Available from CRAN website},
    title = {{R Language Definition (draft)}},
    url = {https://cran.r-project.org/doc/manuals/r-release/R-lang.pdf},
    year = {2015}
}

@book{Adler2010R,
    abstract = {{Presents a guide to the R computer language, covering such topics as the user interface, packages, syntax, objects, functions, object-oriented programming, data sets, lattice graphics, regression models, and bioconductor.}},
    author = {Adler, Joseph},
    citeulike-article-id = {10346845},
    citeulike-linkout-0 = {http://www.worldcat.org/isbn/9780596801700},
    citeulike-linkout-1 = {http://books.google.com/books?vid=ISBN9780596801700},
    citeulike-linkout-2 = {http://www.amazon.com/gp/search?keywords=9780596801700&index=books&linkCode=qs},
    citeulike-linkout-3 = {http://www.librarything.com/isbn/9780596801700},
    citeulike-linkout-4 = {http://www.worldcat.org/oclc/432987461},
    isbn = {9780596801700},
    keywords = {array-programming, book, rlang},
    posted-at = {2015-09-28 14:44:56},
    priority = {0},
    publisher = {O'Reilly},
    title = {{R in a nutshell}},
    url = {http://www.worldcat.org/isbn/9780596801700},
    year = {2010}
}

@article{Leijen2009Design,
    abstract = {{The Task Parallel Library (TPL) is a library for .NET that makes it easy to take advantage of potential parallelism in a program. The library relies heavily on generics and delegate expressions to provide custom control structures expressing structured parallelism such as map-reduce in user programs. The library implementation is built around the notion of a task as a finite CPU-bound computation. To capture the ubiquitous apply-to-all pattern the library also introduces the novel concept of a replicable task. Tasks and replicable tasks are assigned to threads using work stealing techniques, but unlike traditional implementations based on the THE protocol, the library uses a novel data structure called a 'duplicating queue'. A surprising feature of duplicating queues is that they have sequentially inconsistent behavior on architectures with weak memory models, but capture this non-determinism in a benign way by sometimes duplicating elements. TPL ships as part of the Microsoft Parallel Extensions for the .NET framework 4.0, and forms the foundation of Parallel LINQ queries (however, note that the productized TPL library may differ in significant ways from the basic design described in this article).}},
    address = {New York, NY, USA},
    author = {Leijen, Daan and Schulte, Wolfram and Burckhardt, Sebastian},
    citeulike-article-id = {6017606},
    citeulike-linkout-0 = {http://research.microsoft.com/en-us/um/people/daan/download/papers/tpl-oopsla-2009.pdf},
    citeulike-linkout-1 = {http://portal.acm.org/citation.cfm?id=1639949.1640106},
    citeulike-linkout-2 = {http://dx.doi.org/10.1145/1639949.1640106},
    doi = {10.1145/1639949.1640106},
    issn = {0362-1340},
    journal = {SIGPLAN Not.},
    keywords = {library, parallel-programming},
    number = {10},
    pages = {227--242},
    posted-at = {2015-09-15 07:42:48},
    priority = {2},
    publisher = {ACM},
    title = {{The design of a task parallel library}},
    url = {http://research.microsoft.com/en-us/um/people/daan/download/papers/tpl-oopsla-2009.pdf},
    volume = {44},
    year = {2009}
}

@inproceedings{Coutts2007Stream,
    abstract = {{This paper presents an automatic deforestation system, stream fusion, based on equational transformations, that fuses a wider range of functions than existing short-cut fusion systems. In particular, stream fusion is able to fuse zips, left folds and functions over nested lists, including list comprehensions. A distinguishing feature of the framework is its simplicity: by transforming list functions to expose their structure, intermediate values are eliminated by general purpose compiler optimisations. We have reimplemented the Haskell standard List library on top of our framework, providing stream fusion for Haskell lists. By allowing a wider range of functions to fuse, we see an increase in the number of occurrences of fusion in typical Haskell programs. We present benchmarks documenting time and space improvements.}},
    address = {New York, NY, USA},
    author = {Coutts, Duncan and Leshchinskiy, Roman and Stewart, Don},
    booktitle = {Proceedings of the 12th ACM SIGPLAN International Conference on Functional Programming},
    citeulike-article-id = {2326693},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1291151.1291199},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1291151.1291199},
    doi = {10.1145/1291151.1291199},
    isbn = {978-1-59593-815-2},
    issn = {0362-1340},
    journal = {SIGPLAN Not.},
    keywords = {functional-programming, streams},
    location = {Freiburg, Germany},
    month = oct,
    pages = {315--326},
    posted-at = {2015-08-10 13:04:12},
    priority = {3},
    publisher = {ACM},
    series = {ICFP '07},
    title = {{Stream Fusion: From Lists to Streams to Nothing at All}},
    url = {http://dx.doi.org/10.1145/1291151.1291199},
    volume = {42},
    year = {2007}
}

@article{Budimlic2010Concurrent,
    abstract = {{We introduce the Concurrent Collections (CnC) programming model. CnC supports flexible combinations of task and data parallelism while retaining determinism. CnC is implicitly parallel, with the user providing high-level operations along with semantic ordering constraints that together form a CnC graph. We formally describe the execution semantics of CnC and prove that the model guarantees deterministic computation. We evaluate the performance of CnC implementations on several applications and show that CnC offers performance and scalability equivalent to or better than that offered by lower-level parallel programming models.}},
    address = {Amsterdam, The Netherlands, The Netherlands},
    author = {Budimli\'{c}, Zoran and Burke, Michael and Cav{\'{e}}, Vincent and Knobe, Kathleen and Lowney, Geoff and Newton, Ryan and Palsberg, Jens and Peixotto, David and Sarkar, Vivek and Schlimbach, Frank and Ta\c{s}irlar, Sa\u{g}nak},
    citeulike-article-id = {13699049},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1938482.1938486},
    citeulike-linkout-1 = {http://dx.doi.org/10.1155/2010/521797},
    doi = {10.1155/2010/521797},
    issn = {1058-9244},
    journal = {Sci. Program.},
    keywords = {concurrency, data-structures},
    month = aug,
    number = {3-4},
    pages = {203--217},
    posted-at = {2015-08-10 12:14:42},
    priority = {1},
    publisher = {IOS Press},
    title = {{Concurrent Collections}},
    url = {http://dx.doi.org/10.1155/2010/521797},
    volume = {18},
    year = {2010}
}

@inproceedings{Fisher2005EUSES,
    abstract = {{In recent years several tools and methodologies have been developed to improve the dependability of spreadsheets. However, there has been little evaluation of these dependability devices on spreadsheets in actual use by end users. To assist in the process of evaluating these methodologies, we have assembled a corpus of spreadsheets from a variety of sources. We have ensured that these spreadsheets are suitable for evaluating dependability devices in Microsoft Excel (the most commonly used commercial spreadsheet environment) and have measured a variety of feature of these spreadsheets to aid researchers in selecting subsets of the corpus appropriate to their needs.}},
    address = {New York, NY, USA},
    author = {Fisher, Marc and Rothermel, Gregg},
    booktitle = {Proceedings of the First Workshop on End-user Software Engineering},
    citeulike-article-id = {13695670},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1083242},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1082983.1083242},
    doi = {10.1145/1082983.1083242},
    isbn = {1-59593-131-7},
    keywords = {review, spreadsheets},
    location = {St. Louis, Missouri},
    pages = {1--5},
    posted-at = {2015-08-05 14:53:34},
    priority = {2},
    publisher = {ACM},
    series = {WEUSE I},
    title = {{The EUSES Spreadsheet Corpus: A Shared Resource for Supporting Experimentation with Spreadsheet Dependability Mechanisms}},
    url = {http://dx.doi.org/10.1145/1082983.1083242},
    year = {2005}
}

@mastersthesis{Patapavicius2011Efficient,
    author = {Patapavicius, Linas},
    citeulike-article-id = {13693268},
    keywords = {blas, masters-thesis, parallel-programming, spreadsheets},
    month = feb,
    posted-at = {2015-08-03 09:41:01},
    priority = {2},
    school = {IT University of Copenhagen},
    title = {{Efficient Linear Algebra Operations in Spreadsheets}},
    year = {2011}
}

@mastersthesis{Hamann2010Parallelization,
    author = {Hamann, Jens H.},
    citeulike-article-id = {13693258},
    citeulike-linkout-0 = {http://www.itu.dk/people/jhh/thesis/thesis/},
    keywords = {masters-thesis, parallel-programming, spreadsheets},
    month = may,
    posted-at = {2015-08-03 09:36:23},
    priority = {3},
    school = {IT University of Copenhagen},
    title = {{Parallelization of Spreadsheet Computations}},
    url = {http://www.itu.dk/people/jhh/thesis/thesis/},
    year = {2010}
}

@mastersthesis{Rask2014Integration,
    author = {Rask, Jonas D. and Timmerman, Simon E.},
    citeulike-article-id = {13693233},
    keywords = {masters-thesis, spreadsheets},
    month = jun,
    posted-at = {2015-08-03 08:55:16},
    priority = {0},
    school = {IT University of Copenhagen},
    title = {{Integration of Sheet-Defined Functions in Excel Using C\#}},
    year = {2014}
}

@misc{Trudeau2015Collaboration,
    author = {Trudeau, Jim},
    citeulike-article-id = {13691969},
    citeulike-linkout-0 = {http://developer.amd.com/community/blog/2015/07/15/collaboration-and-open-source-at-amd-libreoffice/},
    day = {15},
    keywords = {gpu-programming, spreadsheets, website},
    month = jul,
    note = {Accessed on 31.07.2015},
    posted-at = {2015-07-31 16:01:38},
    priority = {0},
    title = {{Collaboration and Open Source at AMD: LibreOffice}},
    url = {http://developer.amd.com/community/blog/2015/07/15/collaboration-and-open-source-at-amd-libreoffice/},
    year = {2015}
}

@techreport{Gosling2015Java,
    author = {Gosling, James and Joy, Bill and Steele, Guy and Bracha, Gilad and Buckley, Alex},
    citeulike-article-id = {13691920},
    citeulike-linkout-0 = {https://docs.oracle.com/javase/specs/},
    edition = {Version 8},
    keywords = {book, java},
    month = mar,
    note = {Accessed on 31.07.2015},
    posted-at = {2015-07-31 14:58:32},
    priority = {0},
    title = {{The Java Language Specification}},
    url = {https://docs.oracle.com/javase/specs/},
    year = {2015}
}

@phdthesis{Wack1996Partitioning,
    abstract = {{An abstract is not available.}},
    address = {Newark, DE, USA},
    author = {Wack, Andrew P.},
    citeulike-article-id = {13691898},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=269551},
    keywords = {graphs, message-passing, parallel-programming, spreadsheets},
    posted-at = {2015-07-31 14:28:34},
    priority = {1},
    publisher = {University of Delaware},
    title = {{Partitioning Dependency Graphs for Concurrent Execution: A Parallel Spreadsheet on a Realistically Modeled Message Passing Environment}},
    url = {http://portal.acm.org/citation.cfm?id=269551},
    year = {1996}
}

@proceedings{ARRAY14,
    abstract = {{The first ACM SIGPLAN International Workshop on Libraries, Languages and Compilers for Array Programming was held in Edinburgh on June 12th and 13th 2014, immediately following and associated with PLDI 2014. This volume contains the accepted papers. Slides of the presentations are available at http://www.sable.mcgill.ca/array/.}},
    address = {New York, NY, USA},
    citeulike-article-id = {13691893},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2627373},
    isbn = {978-1-4503-2937-8},
    keywords = {array-programming, proceedings},
    location = {Edinburgh, United Kingdom},
    posted-at = {2015-07-31 14:19:05},
    priority = {0},
    publisher = {ACM},
    title = {{ARRAY'14: Proceedings of ACM SIGPLAN International Workshop on Libraries, Languages, and Compilers for Array Programming}},
    url = {http://portal.acm.org/citation.cfm?id=2627373},
    year = {2014}
}

@proceedings{ARRAY15,
    abstract = {{An abstract is not available.}},
    address = {New York, NY, USA},
    citeulike-article-id = {13691890},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2774959},
    isbn = {978-1-4503-3584-3},
    keywords = {array-programming, proceedings},
    location = {Portland, OR, USA},
    posted-at = {2015-07-31 14:18:22},
    priority = {0},
    publisher = {ACM},
    title = {{ARRAY 2015: Proceedings of the 2Nd ACM SIGPLAN International Workshop on Libraries, Languages, and Compilers for Array Programming}},
    url = {http://portal.acm.org/citation.cfm?id=2774959},
    year = {2015}
}

@inproceedings{Snyder2007Design,
    abstract = {{ZPL is an implicitly parallel programming language, which means all instructions to implement and manage the parallelism are inserted by the compiler. It is the first implicitly parallel language to achieve performance portability, that is, consistent high performance across all (MIMD) parallel platforms. ZPL has been designed from first principles, and is founded on the CTA abstract parallel machine. A key enabler of ZPL's performance portability is its What You See Is What You Get (WYSIWYG) performance model. The paper describes the antecedent research on which ZPL was founded, the design principles used to build it incrementally, and the technical basis for its performance portability. Comparisons with other parallel programming approaches are included.}},
    address = {New York, NY, USA},
    author = {Snyder, Lawrence},
    booktitle = {Proceedings of the Third ACM SIGPLAN Conference on History of Programming Languages},
    citeulike-article-id = {2244403},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1238852},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1238844.1238852},
    doi = {10.1145/1238844.1238852},
    isbn = {978-1-59593-766-7},
    keywords = {parallel-programming, performance, programming-language, zpl},
    location = {San Diego, California},
    posted-at = {2015-07-30 08:21:21},
    priority = {0},
    publisher = {ACM},
    series = {HOPL III},
    title = {{The Design and Development of ZPL}},
    url = {http://dx.doi.org/10.1145/1238844.1238852},
    year = {2007}
}

@inproceedings{Imam2014Exploiting,
    abstract = {{We have built an interpreter for the array programming language J. The interpreter exploits implicit data parallelism in the language to achieve good parallel speedups on a variety of benchmark applications. Many array programming languages operate on entire arrays without the need to write loops. Writing without loops simplifies the programs. Array programs without loops allow an interpreter to parallelize the execution of the code without complex analysis or input from the programmer. The J programming language includes the usual idioms of operations on arrays of the same size and shape, where the operations can often be performed in parallel for each individual item of the operands. Another opportunity comes from Js reduction operations, where suitable operations can be performed in parallel for all the items of an operand. J has a notion of verb rank, which allows programmers to simplify programs by declaring how operations are applied to operands. The verb rank mechanism allows us to extract further parallelism. Our implementation of an implicitly parallelizing interpreter for J is written entirely in Java. We have written the interpreter in a framework that produces native code for the interpreter, giving good scalar performance. The interpreter itself is responsible for exploiting the parallelism available in the applications. Our results show we attain good parallel speed-up on a variety of benchmarks, including near perfect linear speed-up on inherently parallel benchmarks. We believe that the lessons learned from our approach to exploiting data parallelism in an interpreter can be applied to other interpreted languages as well.}},
    address = {New York, NY, USA},
    author = {Imam, Shams and Sarkar, Vivek and Leibs, David and Kessler, Peter B.},
    booktitle = {Proceedings of ACM SIGPLAN International Workshop on Libraries, Languages, and Compilers for Array Programming},
    citeulike-article-id = {13686961},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2627374},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2627373.2627374},
    doi = {10.1145/2627373.2627374},
    isbn = {978-1-4503-2937-8},
    keywords = {array-programming, java, parallel-programming, programming-language},
    location = {Edinburgh, United Kingdom},
    posted-at = {2015-07-27 14:53:36},
    priority = {3},
    publisher = {ACM},
    series = {ARRAY'14},
    title = {{Exploiting Implicit Parallelism in Dynamic Array Programming Languages}},
    url = {http://dx.doi.org/10.1145/2627373.2627374},
    year = {2014}
}

@article{Tarditi2006Accelerator,
    abstract = {{GPUs are difficult to program for general-purpose uses. Programmers can either learn graphics APIs and convert their applications to use graphics pipeline operations or they can use stream programming abstractions of GPUs. We describe Accelerator, a system that uses data parallelism to program GPUs for general-purpose uses instead. Programmers use a conventional imperative programming language and a library that provides only high-level data-parallel operations. No aspects of GPUs are exposed to programmers. The library implementation compiles the data-parallel operations on the fly to optimized GPU pixel shader code and API calls.We describe the compilation techniques used to do this. We evaluate the effectiveness of using data parallelism to program GPUs by providing results for a set of compute-intensive benchmarks. We compare the performance of Accelerator versions of the benchmarks against hand-written pixel shaders. The speeds of the Accelerator versions are typically within 50\% of the speeds of hand-written pixel shader code. Some benchmarks significantly outperform C versions on a CPU: they are up to 18 times faster than C code running on a CPU.}},
    address = {New York, NY, USA},
    author = {Tarditi, David and Puri, Sidd and Oglesby, Jose},
    booktitle = {ASPLOS-XII: Proceedings of the 12th international conference on Architectural support for programming languages and operating systems},
    citeulike-article-id = {2881839},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1168857.1168898},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1168857.1168898},
    doi = {10.1145/1168857.1168898},
    isbn = {1595934510},
    issn = {0163-5980},
    journal = {SIGOPS Oper. Syst. Rev.},
    keywords = {array-programming, gpu-programming, parallel-programming},
    month = oct,
    number = {5},
    pages = {325--335},
    posted-at = {2015-07-25 12:00:31},
    priority = {1},
    publisher = {ACM},
    title = {{Accelerator: Using Data Parallelism to Program GPUs for General-purpose Uses}},
    url = {http://dx.doi.org/10.1145/1168857.1168898},
    volume = {40},
    year = {2006}
}

@article{Lawson1979Basic,
    abstract = {{An abstract is not available.}},
    address = {New York, NY, USA},
    author = {Lawson, C. L. and Hanson, R. J. and Kincaid, D. R. and Krogh, F. T.},
    citeulike-article-id = {2834740},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=355841.355847},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/355841.355847},
    doi = {10.1145/355841.355847},
    issn = {0098-3500},
    journal = {ACM Trans. Math. Softw.},
    keywords = {blas, numeric},
    month = sep,
    number = {3},
    pages = {308--323},
    posted-at = {2015-07-24 12:48:14},
    priority = {1},
    publisher = {ACM},
    title = {{Basic Linear Algebra Subprograms for Fortran Usage}},
    url = {http://dx.doi.org/10.1145/355841.355847},
    volume = {5},
    year = {1979}
}

@article{Goldberg1991What,
    abstract = {{Floating-point arithmetic is considered as esoteric subject by many people. This is rather surprising, because floating-point is ubiquitous in computer systems: Almost every language has a floating-point datatype; computers from PCs to supercomputers have floating-point accelerators; most compilers will be called upon to compile floating-point algorithms from time to time; and virtually every operating system must respond to floating-point exceptions such as overflow. This paper presents a tutorial on the aspects of floating-point that have a direct impact on designers of computer systems. It begins with background on floating-point representation and rounding error, continues with a discussion of the IEEE floating point standard, and concludes with examples of how computer system  builders can better support floating point.}},
    address = {New York, NY, USA},
    author = {Goldberg, David},
    citeulike-article-id = {620342},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=103163},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/103162.103163},
    doi = {10.1145/103162.103163},
    issn = {0360-0300},
    journal = {ACM Comput. Surv.},
    keywords = {arithmetic, ieee-float, review},
    month = mar,
    number = {1},
    pages = {5--48},
    posted-at = {2015-07-20 12:54:05},
    priority = {3},
    publisher = {ACM},
    title = {{What Every Computer Scientist Should Know About Floating-point Arithmetic}},
    url = {http://dx.doi.org/10.1145/103162.103163},
    volume = {23},
    year = {1991}
}

@article{Lin1999Finding,
    abstract = {{Because the prefix computation has broad applications, many combinational circuits for solving the prefix problem, called prefix circuits, have been designed. The size s and the depth d of an n-input prefix circuit satisfy the inequality d+s≥2n−2; thus, a prefix circuit is depth-size optimal if d+s=2n−2. We present a constant-time algorithm for finding depth-size optimal parallel prefix circuits with fan-out 2 and depths t either in the range n−1<t<2⌊lgn⌋−1 or in the range n−1<t<2⌊lgn⌋, depending on the value of n.}},
    author = {Lin, Yen-Chun and Liu, Chun-Keng},
    citeulike-article-id = {13669322},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/s0020-0190(99)00058-7},
    doi = {10.1016/s0020-0190(99)00058-7},
    issn = {00200190},
    journal = {Information Processing Letters},
    keywords = {parallel-prefix-networks},
    month = may,
    number = {4},
    pages = {191--195},
    posted-at = {2015-07-10 16:25:24},
    priority = {2},
    title = {{Finding optimal parallel prefix circuits with fan-out 2 in constant time}},
    url = {http://dx.doi.org/10.1016/s0020-0190(99)00058-7},
    volume = {70},
    year = {1999}
}

@article{Snir1986Depthsize,
    abstract = {{A prefix circuit has n inputs x1,…,xn, and computes the n outputs x1 \^{a} … \^{a} xi, i = 1, …, n, where \^{a} is an associative operation. It is shown that the depth t and the size s of parallel prefix circuits are related by the inequality t + s ≥ 2n −2. This is true even if arbitrary binary operations can be performed at each node. For 2 lg n − 2 < t < n − 1 optimal circuits with t + s = 2n − 2 are built. The depth and size of carry-lookahead circuits with n outputs are related by the inequality t + s ≥ 4n. The depth of parallel prefix circuits of width w is shown to be .}},
    author = {Snir, Marc},
    citeulike-article-id = {13669315},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/0196-6774(86)90003-9},
    doi = {10.1016/0196-6774(86)90003-9},
    issn = {01966774},
    journal = {Journal of Algorithms},
    keywords = {parallel-prefix-networks},
    month = jun,
    number = {2},
    pages = {185--201},
    posted-at = {2015-07-10 16:14:43},
    priority = {2},
    title = {{Depth-size trade-offs for parallel prefix computation}},
    url = {http://dx.doi.org/10.1016/0196-6774(86)90003-9},
    volume = {7},
    year = {1986}
}

@article{Voigtlander2008Much,
    abstract = {{This pearl develops a statement about parallel prefix computation in the spirit of Knuth's 0-1-Principle for oblivious sorting algorithms. It turns out that 0-1 is not quite enough here. The perfect hammer for the nails we are going to drive in is relational parametricity.}},
    address = {New York, NY, USA},
    author = {Voigtl\"{a}nder, Janis},
    citeulike-article-id = {13668203},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1328445},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1328897.1328445},
    doi = {10.1145/1328897.1328445},
    issn = {0362-1340},
    journal = {SIGPLAN Not.},
    keywords = {correctness, functional-pearl, parallel-prefix-networks},
    month = jan,
    number = {1},
    pages = {29--35},
    posted-at = {2015-07-09 10:21:02},
    priority = {4},
    publisher = {ACM},
    title = {{Much Ado About Two (Pearl): A Pearl on Parallel Prefix Computation}},
    url = {http://dx.doi.org/10.1145/1328897.1328445},
    volume = {43},
    year = {2008}
}

@phdthesis{Hermans2013Analyzing,
    address = {Postbus 5, 2600 AA Delft, The Netherlands},
    author = {Hermans, F\'{e}lienne F.},
    citeulike-article-id = {13643960},
    citeulike-linkout-0 = {http://files.figshare.com/996353/dissertation.pdf},
    citeulike-linkout-1 = {http://www.worldcat.org/isbn/9789088915680},
    citeulike-linkout-2 = {http://books.google.com/books?vid=ISBN9789088915680},
    citeulike-linkout-3 = {http://www.amazon.com/gp/search?keywords=9789088915680&index=books&linkCode=qs},
    citeulike-linkout-4 = {http://www.librarything.com/isbn/9789088915680},
    citeulike-linkout-5 = {http://www.worldcat.org/oclc/905869356},
    day = {23},
    isbn = {9789088915680},
    keywords = {spreadsheets},
    month = jan,
    posted-at = {2015-06-11 19:04:42},
    priority = {2},
    publisher = {[s.n.]},
    school = {Delft University of Technology},
    title = {{Analyzing and visualizing spreadsheets.}},
    url = {http://files.figshare.com/996353/dissertation.pdf},
    year = {2013}
}

@incollection{Hinze2004Algebra,
    abstract = {{A parallel prefix circuit takes n inputs x 1, x 2, ..., x n  and produces the n outputs x 1, x 1 ∘ x 2, ..., x 1 ∘ x 2 ∘ ⋯ ∘ x n , where'∘' is an arbitrary associative binary operation. Parallel prefix circuits and their counterparts in software, parallel prefix computations or scans, have numerous applications ranging from fast integer addition over parallel sorting to convex hull problems. A parallel prefix circuit can be implemented in a variety of ways taking into account constraints on size, depth, or fan-out. Traditionally, implementations are either defined graphically or by enumerating the underlying graph. Both approaches have their pros and cons. A figure if well drawn conveys the possibly recursive structure of the scan but it is not amenable to formal manipulation. A description in form of a graph while rigorous obscures the structure of a scan and is equally hard to manipulate. In this paper we show that parallel prefix circuits enjoy a very pleasant algebra. Using only two basic building blocks and four combinators all standard designs can be described succinctly and rigorously. The rules of the algebra allow us to prove the circuits correct and to derive circuit designs in a systematic manner.}},
    author = {Hinze, Ralf},
    booktitle = {Mathematics of Program Construction},
    citeulike-article-id = {13622635},
    citeulike-linkout-0 = {http://www.cs.ox.ac.uk/ralf.hinze/publications/MPC04.pdf},
    citeulike-linkout-1 = {http://dx.doi.org/10.1007/978-3-540-27764-4_11},
    citeulike-linkout-2 = {http://link.springer.com/chapter/10.1007/978-3-540-27764-4_11},
    doi = {10.1007/978-3-540-27764-4_11},
    editor = {Kozen, Dexter},
    keywords = {algebra, functional-programming, parallel-prefix-networks, parallel-programming, scan},
    pages = {186--210},
    posted-at = {2015-05-22 09:03:21},
    priority = {3},
    publisher = {Springer Berlin Heidelberg},
    series = {Lecture Notes in Computer Science},
    title = {{An Algebra of Scans}},
    url = {http://www.cs.ox.ac.uk/ralf.hinze/publications/MPC04.pdf},
    volume = {3125},
    year = {2004}
}

@article{Shavit2011Data,
    abstract = {{The advent of multicore processors as the standard computing platform will force major changes in software design.}},
    address = {New York, NY, USA},
    author = {Shavit, Nir},
    citeulike-article-id = {8900088},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1897873},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1897852.1897873},
    doi = {10.1145/1897852.1897873},
    issn = {0001-0782},
    journal = {Commun. ACM},
    keywords = {concurrency, data-structures, multi-core, multithreading, review},
    month = mar,
    number = {3},
    pages = {76--84},
    posted-at = {2015-05-08 09:11:04},
    priority = {3},
    publisher = {ACM},
    title = {{Data Structures in the Multicore Age}},
    url = {http://dx.doi.org/10.1145/1897852.1897873},
    volume = {54},
    year = {2011}
}

@article{Bacon2007Realtime,
    abstract = {{Traditional computer science deals with the computation of correct results. Realtime systems interact with the physical world, so they have a second correctness criterion: they have to compute the correct result within a bounded amount of time. Simply building functionally correct software is hard enough. When timing is added to the requirements, the cost and complexity of building the software increase enormously.}},
    address = {New York, NY, USA},
    author = {Bacon, David F.},
    citeulike-article-id = {13605056},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1217256.1217268},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1217256.1217268},
    doi = {10.1145/1217256.1217268},
    issn = {1542-7730},
    journal = {Queue},
    keywords = {gc, java, performance},
    month = feb,
    number = {1},
    pages = {40--49},
    posted-at = {2015-05-07 13:23:18},
    priority = {1},
    publisher = {ACM},
    title = {{Realtime Garbage Collection}},
    url = {http://dx.doi.org/10.1145/1217256.1217268},
    volume = {5},
    year = {2007}
}

@book{Iverson1962Programming,
    author = {Iverson, Kenneth E.},
    citeulike-article-id = {1557387},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20&amp;path=ASIN/0471430145},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21&amp;path=ASIN/0471430145},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21&amp;path=ASIN/0471430145},
    citeulike-linkout-3 = {http://www.amazon.co.uk/exec/obidos/ASIN/0471430145/citeulike00-21},
    citeulike-linkout-4 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20&path=ASIN/0471430145},
    citeulike-linkout-5 = {http://www.worldcat.org/isbn/0471430145},
    citeulike-linkout-6 = {http://books.google.com/books?vid=ISBN0471430145},
    citeulike-linkout-7 = {http://www.amazon.com/gp/search?keywords=0471430145&index=books&linkCode=qs},
    citeulike-linkout-8 = {http://www.librarything.com/isbn/0471430145},
    howpublished = {Textbook Binding},
    isbn = {0471430145},
    keywords = {array-programming, book, programming-language},
    posted-at = {2015-04-27 10:24:01},
    priority = {2},
    publisher = {John Wiley \& Sons},
    title = {{A Programming Language}},
    url = {http://www.worldcat.org/isbn/0471430145},
    year = {1962}
}

@article{Vinoski2007Concurrency,
    author = {Vinoski, Steve},
    citeulike-article-id = {13593063},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/mic.2007.104},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4305575},
    doi = {10.1109/mic.2007.104},
    institution = {Verivue},
    issn = {1089-7801},
    journal = {Internet Computing, IEEE},
    keywords = {actors, concurrency, parallel-programming, programming-language},
    number = {5},
    pages = {90--93},
    posted-at = {2015-04-27 10:11:15},
    priority = {1},
    publisher = {IEEE},
    title = {{Concurrency with Erlang}},
    url = {http://dx.doi.org/10.1109/mic.2007.104},
    volume = {11},
    year = {2007}
}

@inproceedings{Kyrola2012GraphChi,
    abstract = {{Current systems for graph computation require a distributed computing cluster to handle very large real-world problems, such as analysis on social networks or the web graph. While distributed computational resources have become more accessible, developing distributed graph algorithms still remains challenging, especially to non-experts. In this work, we present GraphChi, a disk-based system for computing efficiently on graphs with billions of edges. By using a well-known method to break large graphs into small parts, and a novel parallel sliding windows method, GraphChi is able to execute several advanced data mining, graph mining, and machine learning algorithms on very large graphs, using just a single consumer-level computer. We further extend GraphChi to support graphs that evolve over time, and demonstrate that, on a single computer, GraphChi can process over one hundred thousand graph updates per second, while simultaneously performing computation. We show, through experiments and theoretical analysis, that GraphChi performs well on both SSDs and rotational hard drives. By repeating experiments reported for existing distributed systems, we show that, with only fraction of the resources, GraphChi can solve the same problems in very reasonable time. Our work makes large-scale graph computation available to anyone with a modern PC.}},
    address = {Berkeley, CA, USA},
    author = {Kyrola, Aapo and Blelloch, Guy and Guestrin, Carlos},
    booktitle = {Proceedings of the 10th USENIX Conference on Operating Systems Design and Implementation},
    citeulike-article-id = {13592237},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2387880.2387884},
    isbn = {978-1-931971-96-6},
    keywords = {graphs, hardware, parallel-programming},
    location = {Hollywood, CA, USA},
    pages = {31--46},
    posted-at = {2015-04-26 14:01:28},
    priority = {3},
    publisher = {USENIX Association},
    series = {OSDI'12},
    title = {{GraphChi: Large-scale Graph Computation on Just a PC}},
    url = {http://portal.acm.org/citation.cfm?id=2387880.2387884},
    year = {2012}
}

@article{Blelloch2009Parallel,
    abstract = {{Assuming that the multicore revolution plays out the way the microprocessor industry expects, it seems that within a decade most programming will involve parallelism at some level. One needs to ask how this affects the the way we teach computer science, or even how we have people think about computation. With regards to teaching there seem to be three basic choices: (1) we only train a small number of experts in parallel computation who develop a collection of libraries, and everyone else just uses them; (2) we leave our core curriculum pretty much as is, but add some advanced courses on parallelism or perhaps tack on a few lectures at the end of existing courses; or (3) we start teaching parallelism from the start and embed it throughout the curriculum with the idea of getting students to think about parallelism as the most natural form of computation and sequential computation as a special case. This talk will examine some of the implications of the third option. It will argue that thinking about parallelism, when treated in an appropriate way, might be as easy or easier that thinking sequentially. A key prerequisite, however, is to identify what the core ideas in parallelism are and how they might be layered and integrated with existing concepts. Another more difficult issue is how to cleanly integrate these ideas among courses. After all much of the success of sequential computation follows from the concept of a random access machine and its ability to serve as a simple, albeit imperfect, interface between programming languages, algorithm analysis, and hardware design. The talk will go through an initial list of some core ideas in parallelism, and an approach to integrating these ideas between parallel algorithms, programming languages, and, to some extent, hardware. This requires, however, moving away from the concept of a machine model as a interface for thinking about computation.}},
    address = {New York, NY, USA},
    author = {Blelloch, Guy E.},
    citeulike-article-id = {13591070},
    citeulike-linkout-0 = {http://www.cs.cmu.edu/~guyb/papers/PPoPP09.pdf},
    citeulike-linkout-1 = {http://portal.acm.org/citation.cfm?id=1504176.1504177},
    citeulike-linkout-2 = {http://dx.doi.org/10.1145/1594835.1504177},
    doi = {10.1145/1594835.1504177},
    issn = {0362-1340},
    journal = {SIGPLAN Not.},
    keywords = {functional-programming, parallel-programming, talk},
    month = feb,
    number = {4},
    pages = {1--2},
    posted-at = {2015-04-24 14:28:01},
    priority = {0},
    publisher = {ACM},
    title = {{Parallel Thinking}},
    url = {http://www.cs.cmu.edu/~guyb/papers/PPoPP09.pdf},
    volume = {44},
    year = {2009}
}

@inproceedings{Blelloch2010Functional,
    abstract = {{Functional programming presents several important advantages in the design, analysis and implementation of parallel algorithms: It discourages iteration and encourages decomposition. It supports persistence and hence easy speculation. It encourages higher-order aggregate operations. It is well suited for defining cost models tied to the programming language rather than the machine. Implementations can avoid false sharing. Implementations can use cheaper weak consistency models. And most importantly, it supports safe deterministic parallelism.In fact functional programming supports a level of abstraction in which parallel algorithms are often as easy to design and analyze as sequential algorithms. The recent widespread advent of parallel machines therefore presents a great opportunity for functional programming languages. However, any changes will require significant education at all levels and involvement of the functional programming community. In this talk I will discuss an approach to designing and analyzing parallel algorithms in a strict functional and fully deterministic setting. Key ideas include a cost model defined in term of analyzing work and span, the use of divide-and-conquer and contraction, the need for arrays (immutable) to achieve asymptotic efficiency, and the power of (deterministic) randomized algorithms. These are all ideas I believe can be taught at any level.}},
    address = {New York, NY, USA},
    author = {Blelloch, Guy E.},
    booktitle = {Proceedings of the 15th ACM SIGPLAN International Conference on Functional Programming},
    citeulike-article-id = {13591068},
    citeulike-linkout-0 = {http://www.cs.cmu.edu/~guyb/papers/ICFP10.pdf},
    citeulike-linkout-1 = {http://portal.acm.org/citation.cfm?id=1863543.1863579},
    citeulike-linkout-2 = {http://dx.doi.org/10.1145/1863543.1863579},
    doi = {10.1145/1863543.1863579},
    isbn = {978-1-60558-794-3},
    keywords = {algorithms, functional-programming, parallel-programming, talk},
    location = {Baltimore, Maryland, USA},
    pages = {247},
    posted-at = {2015-04-24 14:22:48},
    priority = {0},
    publisher = {ACM},
    series = {ICFP '10},
    title = {{Functional Parallel Algorithms}},
    url = {http://www.cs.cmu.edu/~guyb/papers/ICFP10.pdf},
    year = {2010}
}

@article{Lee2006Problem,
    abstract = {{For concurrent programming to become mainstream, we must discard threads as a programming model. Nondeterminism should be judiciously and carefully introduced where needed, and it should be explicit in programs.}},
    address = {Los Alamitos, CA, USA},
    author = {Lee, Edward},
    citeulike-article-id = {813196},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1137232.1137289},
    citeulike-linkout-1 = {http://doi.ieeecomputersociety.org/10.1109/MC.2006.180},
    citeulike-linkout-2 = {http://dx.doi.org/10.1109/mc.2006.180},
    citeulike-linkout-3 = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1631937},
    doi = {10.1109/mc.2006.180},
    institution = {Dept. of Electr. Eng. \& Comput. Sci., California Univ., Berkeley, CA, USA},
    issn = {0018-9162},
    journal = {Computer},
    keywords = {concurrency, multithreading, review},
    month = may,
    number = {5},
    pages = {33--42},
    posted-at = {2015-04-24 12:31:13},
    priority = {0},
    publisher = {IEEE},
    title = {{The problem with threads}},
    url = {http://dx.doi.org/10.1109/mc.2006.180},
    volume = {39},
    year = {2006}
}

@book{McGraw1983SISAL,
    author = {McGraw, J. and Skedzielewski, S. and Allan, S. and Grit, D. and Oldehoeft, R. and Glauert, J. and Dobes, I. and Hohensee, P.},
    citeulike-article-id = {13590794},
    posted-at = {2015-04-24 08:07:04},
    priority = {1},
    title = {{SISAL: streams and iteration in a single-assignment language. Language reference manual, Version 1. 1}},
    year = {1983}
}

@book{Sestoft2014Spreadsheet,
    abstract = {{Spreadsheets are used daily by millions of people for tasks that range from organizing a list of addresses to carrying out complex economic simulations. Spreadsheet programs are easy to learn and convenient to use because they have a clear visual model and a simple efficient underlying computational model. Yet although the basic spreadsheet model could be extended, improved, or otherwise experimented with in many ways, there is no coherently designed, reasonably efficient open source spreadsheet implementation that is a suitable platform for such experiments. This book fills the gap, teaching users how to experiment with and implement innovative spreadsheet functionality and introducing two software platforms for doing so. Along the way, it draws on and illustrates software technologies and computer science topics that range from object-oriented programming to compiler technology.

Spreadsheet Implementation Technology surveys a wide range of information about spreads eets drawn from user experience, the scientific literature, and patents. After summarizing the spreadsheet computation model and the most important challenges for efficient recalculation, the book describes Corecalc, a core implementation of essential spreadsheet functionality suitable for practical experiments, and Funcalc, an extension of Corecalc that allows users to define their own functions without extraneous programming languages or loss of efficiency. It also shows the advantages of automatic function specialization and offers a user's manual for Funcalc. The Corecalc and Funcalc software is downloadable free of charge.}},
    author = {Sestoft, Peter},
    citeulike-article-id = {13589783},
    citeulike-linkout-0 = {http://ieeexplore.ieee.org/xpl/bkabstractplus.jsp?bkn=6940404},
    citeulike-linkout-1 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20&amp;path=ASIN/0262526646},
    citeulike-linkout-10 = {http://www.librarything.com/isbn/0262526646},
    citeulike-linkout-2 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21&amp;path=ASIN/0262526646},
    citeulike-linkout-3 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21&amp;path=ASIN/0262526646},
    citeulike-linkout-4 = {http://www.amazon.jp/exec/obidos/ASIN/0262526646},
    citeulike-linkout-5 = {http://www.amazon.co.uk/exec/obidos/ASIN/0262526646/citeulike00-21},
    citeulike-linkout-6 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20&path=ASIN/0262526646},
    citeulike-linkout-7 = {http://www.worldcat.org/isbn/0262526646},
    citeulike-linkout-8 = {http://books.google.com/books?vid=ISBN0262526646},
    citeulike-linkout-9 = {http://www.amazon.com/gp/search?keywords=0262526646&index=books&linkCode=qs},
    day = {05},
    howpublished = {Paperback},
    isbn = {0262526646},
    keywords = {book, functional-programming, spreadsheets},
    month = sep,
    posted-at = {2015-04-23 14:24:23},
    priority = {0},
    publisher = {The MIT Press},
    title = {{Spreadsheet Implementation Technology: Basics and Extensions}},
    url = {http://ieeexplore.ieee.org/xpl/bkabstractplus.jsp?bkn=6940404},
    year = {2014}
}

@article{Blelloch1993Implementation,
    abstract = {{This paper gives an overview of the implementation of NESL, a portable nested data-parallel language. This language and its implementation are the first to fully support nested data structures as well as nested data-parallel function calls. These features allow the concise description of parallel algorithms on irregular data, such as sparse matrices and graphs. In addition, they maintain the advantages of data-parallel languages: a simple programming model and portability. The current NESL implementation is based on an intermediate language called VCODE and a library of vector routines called CVL. It runs on the Connection Machine CM-2, the Cray Y-MP C90, and serial machines. We compare initial benchmark results of NESL with those of machine-specific code on these machines for three algorithms: least-squares line-fitting, median finding, and a sparse-matrix vector product. These results show that NESL's performance is competitive with that of machine-specific codes for regular dense data, and is often superior for irregular data.}},
    address = {New York, NY, USA},
    author = {Blelloch, Guy E. and Hardwick, Jonathan C. and Chatterjee, Siddhartha and Sipelstein, Jay and Zagha, Marco},
    booktitle = {Proceedings of the fourth ACM SIGPLAN symposium on Principles and practice of parallel programming},
    citeulike-article-id = {9336501},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=155343},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/155332.155343},
    doi = {10.1145/155332.155343},
    isbn = {0-89791-589-5},
    issn = {0362-1340},
    journal = {SIGPLAN Not.},
    keywords = {array-programming, parallel-programming},
    location = {San Diego, California, United States},
    month = jul,
    number = {7},
    pages = {102--111},
    posted-at = {2015-04-14 13:24:23},
    priority = {3},
    publisher = {ACM},
    series = {PPOPP '93},
    title = {{Implementation of a Portable Nested Data-parallel Language}},
    url = {http://dx.doi.org/10.1145/155332.155343},
    volume = {28},
    year = {1993}
}

@inproceedings{Talbot2014Justintime,
    abstract = {{Dynamically typed vector languages are popular in data analytics and statistical computing. In these languages, vectors have both dynamic type and dynamic length, making static generation of efficient machine code difficult. In this paper, we describe a trace-based just-in-time compilation strategy that performs partial length specialization of dynamically typed vector code. This selective specialization is designed to avoid excessive compilation overhead while still enabling the generation of efficient machine code through length-based optimizations such as vector fusion, vector copy elimination, and the use of hardware SIMD units. We have implemented our approach in a virtual machine for a subset of R, a vector-based statistical computing language. In a variety of workloads, containing both scalar and vector code, we show near autovectorized C performance over a large range of vector sizes.}},
    address = {New York, NY, USA},
    author = {Talbot, Justin and DeVito, Zachary and Hanrahan, Pat},
    booktitle = {Proceedings of ACM SIGPLAN International Workshop on Libraries, Languages, and Compilers for Array Programming},
    citeulike-article-id = {13581767},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2627377},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2627373.2627377},
    doi = {10.1145/2627373.2627377},
    isbn = {978-1-4503-2937-8},
    keywords = {array-programming, performance},
    location = {Edinburgh, United Kingdom},
    posted-at = {2015-04-14 12:40:41},
    priority = {3},
    publisher = {ACM},
    series = {ARRAY'14},
    title = {{Just-in-time Length Specialization of Dynamic Vector Code}},
    url = {http://dx.doi.org/10.1145/2627373.2627377},
    year = {2014}
}

@inproceedings{Sengupta2007Scan,
    abstract = {{The scan primitives are powerful, general-purpose data-parallel primitives that are building blocks for a broad range of applications. We describe GPU implementations of these primitives, specifically an efficient formulation and implementation of segmented scan, on NVIDIA GPUs using the CUDA API.Using the scan primitives, we show novel GPU implementations of quicksort and sparse matrix-vector multiply, and analyze the performance of the scan primitives, several sort algorithms that use the scan primitives, and a graphical shallow-water fluid simulation using the scan framework for a tridiagonal matrix solver.}},
    author = {Sengupta, Shubhabrata and Harris, Mark and Zhang, Yao and Owens, John D.},
    booktitle = {GRAPHICS HARDWARE 2007},
    citeulike-article-id = {4920079},
    citeulike-linkout-0 = {http://graphics.idav.ucdavis.edu/publications/print_pub?pub_id=915},
    citeulike-linkout-1 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.131.3326},
    keywords = {gpu-programming, parallel-prefix-networks, parallel-programming, scan},
    pages = {97--106},
    posted-at = {2015-04-14 12:26:24},
    priority = {2},
    title = {{Scan Primitives for GPU Computing}},
    url = {http://graphics.idav.ucdavis.edu/publications/print_pub?pub_id=915},
    year = {2007}
}

@article{Blelloch1989Scans,
    abstract = {{A study of the effects of adding two scan primitives as unit-time primitives to PRAM (parallel random access machine) models is presented. It is shown that the primitives improve the asymptotic running time of many algorithms by an O(log n) factor, greatly simplifying the description of many algorithms, and are significantly easier to implement than memory references. It is argued that the algorithm designer should feel free to use these operations as if they were as cheap as a memory reference. The author describes five algorithms that clearly illustrate how the scan primitives can be used in algorithm design: a radix-sort algorithm, a quicksort algorithm, a minimum-spanning-tree algorithm, a line-drawing algorithm, and a merging algorithm. These all run on an EREW (exclusive read, exclusive write) PRAM with the addition of two scan primitives and are either simpler or more efficient than their pure PRAM counterparts. The scan primitives have been implemented in microcode on the Connection Machine system, are available in PARIS (the parallel instruction set of the machine).}},
    address = {Washington, DC, USA},
    author = {Blelloch, Guy E.},
    citeulike-article-id = {10450300},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=76113},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/12.42122},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=42122},
    doi = {10.1109/12.42122},
    institution = {Sch. of Comput. Sci., Carnegie Mellon Univ., Pittsburgh, PA, USA},
    issn = {0018-9340},
    journal = {Computers, IEEE Transactions on},
    keywords = {functional-programming, parallel-prefix-networks, parallel-programming},
    month = nov,
    number = {11},
    pages = {1526--1538},
    posted-at = {2015-04-14 10:54:52},
    priority = {4},
    publisher = {IEEE},
    title = {{Scans as primitive parallel operations}},
    url = {http://dx.doi.org/10.1109/12.42122},
    volume = {38},
    year = {1989}
}

@techreport{Blelloch1990Prefix,
    author = {Blelloch, G. E.},
    citeulike-article-id = {13581696},
    citeulike-linkout-0 = {http://repository.cmu.edu/compsci/2018/?utm_source=repository.cmu.edu%2Fcompsci%2F2018&#38;utm_medium=PDF&#38;utm_campaign=PDFCoverPages},
    institution = {School of Computer Science, Carnegie Mellon University},
    keywords = {array-programming, parallel-prefix-networks},
    note = {Also appears in Synthesis of Parallel Algorithms, Reif (ed.), Morgan Kaufmann, 1993.},
    number = {CMU-CS-90-190},
    posted-at = {2015-04-14 10:52:24},
    priority = {0},
    title = {{Prefix Sums and Their Applications}},
    url = {http://repository.cmu.edu/compsci/2018/?utm_source=repository.cmu.edu%2Fcompsci%2F2018&#38;utm_medium=PDF&#38;utm_campaign=PDFCoverPages},
    year = {1990}
}

@inproceedings{Garg2014Justintime,
    abstract = {{In dynamic array-based languages, the most computationally intensive parts of the program often involve either explicit loops or vector operations. These loops and vector operations can be better optimized if the compiler has accurate information about array shapes and loop-bounds. However, accurate shape information about loops and arrays may not be known until runtime. We present a method of performing shape inference in a just-in-time compiler by using information obtained at runtime. We have implemented our method in a compiler toolkit for array-based languages that is integrated into two different compilers: a prototype compiler for Python, and McVM, a virtual machine for MATLAB. We present results obtained from these two compiler integrations on a variety of benchmarks to evaluate the accuracy of shape inference of our method and the runtime overhead of our implementation.}},
    address = {New York, NY, USA},
    author = {Garg, Rahul and Hendren, Laurie},
    booktitle = {Proceedings of ACM SIGPLAN International Workshop on Libraries, Languages, and Compilers for Array Programming},
    citeulike-article-id = {13578668},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2627382},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2627373.2627382},
    doi = {10.1145/2627373.2627382},
    isbn = {978-1-4503-2937-8},
    keywords = {array-programming, parallel-programming, shape-inference},
    location = {Edinburgh, United Kingdom},
    posted-at = {2015-04-10 12:26:28},
    priority = {0},
    publisher = {ACM},
    series = {ARRAY'14},
    title = {{Just-in-time Shape Inference for Array-based Languages}},
    url = {http://dx.doi.org/10.1145/2627373.2627382},
    year = {2014}
}

@article{Sheeran2011Functional,
    abstract = {{A parallel prefix network of width n takes n inputs, a1, a2, . . ., an, and computes each yi = a1 ○ a2 ○ ⋅ ⋅ ⋅ ○ ai for 1 ≤ i ≤ n, for an associative operator ○. This is one of the fundamental problems in computer science, because it gives insight into how parallel computation can be used to solve an apparently sequential problem. As parallel programming becomes the dominant programming paradigm, parallel prefix or scan is proving to be a very important building block of parallel algorithms and applications. There are many different parallel prefix networks, with different properties such as number of operators, depth and allowed fanout from the operators. In this paper, ideas from functional programming are combined with search to enable a deep exploration of parallel prefix network design. Networks that improve on the best known previous results are generated. It is argued that precise modelling in a functional programming language, together with simple visualization of the networks, gives a new, more experimental, approach to parallel prefix network design, improving on the manual techniques typically employed in the literature. The programming idiom that marries search with higher order functions may well have wider application than the network generation described here.}},
    author = {Sheeran, Mary},
    citeulike-article-id = {13578654},
    citeulike-linkout-0 = {http://www.cse.chalmers.se/~ms/},
    citeulike-linkout-1 = {http://journals.cambridge.org/action/displayAbstract?fromPage=online&aid=8223113},
    citeulike-linkout-2 = {http://dx.doi.org/10.1017/s0956796810000304},
    comment = {Sheeran writes on her website: "I have since been informed by Igor Sergeev from Moscow State University that the minimum depth parallel prefix construction that I arrive at at the end of the paper is actually optimal. He has proved a lower bound (in a heroic proof that so far is only written down in Russian), and my construction matches the bound exactly."},
    doi = {10.1017/s0956796810000304},
    issn = {1469-7653},
    journal = {Journal of Functional Programming},
    keywords = {functional-programming, parallel-prefix-networks, parallel-programming},
    month = jan,
    pages = {59--114},
    posted-at = {2015-04-10 11:55:52},
    priority = {0},
    title = {{Functional and dynamic programming in the design of parallel prefix networks}},
    url = {http://www.cse.chalmers.se/~ms/},
    volume = {21},
    year = {2011}
}

@inproceedings{Kuper2013LVars,
    abstract = {{Programs written using a deterministic-by-construction model of parallel computation are guaranteed to always produce the same observable results, offering programmers freedom from subtle, hard-to-reproduce nondeterministic bugs that are the scourge of parallel software. We present LVars, a new model for deterministic-by-construction parallel programming that generalizes existing single-assignment models to allow multiple assignments that are monotonically increasing with respect to a user-specified lattice. LVars ensure determinism by allowing only monotonic writes and "threshold" reads that block until a lower bound is reached. We give a proof of determinism and a prototype implementation for a language with LVars and describe how to extend the LVars model to support a limited form of nondeterminism that admits failures but never wrong answers.}},
    address = {New York, NY, USA},
    author = {Kuper, Lindsey and Newton, Ryan R.},
    booktitle = {Proceedings of the 2Nd ACM SIGPLAN Workshop on Functional High-performance Computing},
    citeulike-article-id = {12714619},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2502326},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2502323.2502326},
    doi = {10.1145/2502323.2502326},
    isbn = {978-1-4503-2381-9},
    keywords = {determinism, haskell, lvars, parallel-programming},
    location = {Boston, Massachusetts, USA},
    pages = {71--84},
    posted-at = {2015-03-30 15:31:20},
    priority = {2},
    publisher = {ACM},
    series = {FHPC '13},
    title = {{LVars: Lattice-based Data Structures for Deterministic Parallelism}},
    url = {http://dx.doi.org/10.1145/2502323.2502326},
    year = {2013}
}

@inproceedings{Madriles2009Boosting,
    abstract = {{Industry has shifted towards multi-core designs as we have hit the memory and power walls. However, single thread performance remains of paramount importance since some applications have limited thread-level parallelism (TLP), and even a small part with limited TLP impose important constraints to the global performance, as explained by Amdahl's law. In this paper we propose a novel approach for leveraging multiple cores to improve single-thread performance in a multi-core design. The proposed technique features a set of novel hardware mechanisms that support the execution of threads generated at compile time. These threads result from a fine-grain speculative decomposition of the original application and they are executed under a modified multi-core system that includes: (1) mechanisms to support multiple versions; (2) mechanisms to detect violations among threads; (3) mechanisms to reconstruct the original sequential order; and (4) mechanisms to checkpoint the architectural state and recovery to handle misspeculations. The proposed scheme outperforms previous hardware-only schemes to implement the idea of combining cores for executing single-thread applications in a multi-core design by more than 10\% on average on Spec2006 for all configurations. Moreover, single-thread performance is improved by 41\% on average when the proposed scheme is used on a Tiny Core, and up to 2.6x for some selected applications.}},
    address = {New York, NY, USA},
    author = {Madriles, Carlos and L\'{o}pez, Pedro and Codina, Josep M. and Gibert, Enric and Latorre, Fernando and Martinez, Alejandro and Martinez, Ra\'{u}l and Gonzalez, Antonio},
    booktitle = {Proceedings of the 36th annual international symposium on Computer architecture},
    citeulike-article-id = {7208620},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1555813},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1555754.1555813},
    doi = {10.1145/1555754.1555813},
    isbn = {978-1-60558-526-0},
    keywords = {algorithms, multi-core, parallel-programming, performance},
    location = {Austin, TX, USA},
    pages = {474--483},
    posted-at = {2015-02-14 16:10:39},
    priority = {0},
    publisher = {ACM},
    series = {ISCA '09},
    title = {{Boosting single-thread performance in multi-core systems through fine-grain multi-threading}},
    url = {http://dx.doi.org/10.1145/1555754.1555813},
    year = {2009}
}

@article{Cantrill2008RealWorld,
    abstract = {{In this look at how concurrency affects practitioners in the
 real world, Cantrill and Bonwick argue that much of the anxiety
 over concurrency is unwarranted. Most developers who build typical
 MVC systems can leverage parallelism by combining pieces of already
 concurrent software such as database and operating systems (i.e.,
 concurrency through architecture), rather than by writing
 multithreaded code themselves. And for those who actually must deal
 with threads and locks, the authors include a helpful list of best
 practices to help minimize the pain.}},
    address = {New York, NY, USA},
    author = {Cantrill, Bryan and Bonwick, Jeff},
    citeulike-article-id = {5182601},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1454462},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1454456.1454462},
    doi = {10.1145/1454456.1454462},
    issn = {1542-7730},
    journal = {Queue},
    keywords = {concurrency, multithreading, parallel-programming, review},
    number = {5},
    pages = {16--25},
    posted-at = {2015-01-19 20:52:14},
    priority = {0},
    publisher = {ACM},
    title = {{Real-World Concurrency}},
    url = {http://dx.doi.org/10.1145/1454456.1454462},
    volume = {6},
    year = {2008}
}

@techreport{Milner1989Calculus,
    abstract = {{: We present the {\ss}-calculus, a calculus of communicating systems in
which one can naturally express processes which have changing structure. Not
only may the component agents of a system be arbitrarily linked, but a communication
between neighbours may carry information which changes that linkage.
The calculus is an extension of the process algebra CCS, following work by Engberg
and Nielsen who added mobility to CCS while preserving its algebraic
properties. The {\ss}-calculus gains simplicity by...}},
    author = {Milner, Robin and Parrow, Joachim and Walker, David},
    citeulike-article-id = {939084},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.36.865},
    keywords = {calculus, model-checking, parallel-programming, pi},
    number = {-86},
    posted-at = {2015-01-13 11:17:53},
    priority = {1},
    title = {A Calculus of Mobile Processes, Parts I and {II}},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.36.865},
    year = {1989}
}

@inproceedings{Chase2005Dynamic,
    abstract = {{The non-blocking work-stealing algorithm of Arora, Blumofe, and Plaxton (henceforth  ABP work-stealing ) is on its way to becoming the multiprocessor load balancing technology of choice in both industry and academia. This highly efficient scheme is based on a collection of array-based double-ended queues (deques) with low cost synchronization among local and stealing processes. Unfortunately, the algorithm's synchronization protocol is strongly based on the use of fixed size arrays, which are prone to overflows, especially in the multiprogrammed environments for which they are designed. We present a work-stealing deque that does not have the overflow problem.The only ABP-style work-stealing algorithm that eliminates the overflow problem is the list-based one presented by Hendler, Lev and Shavit. Their algorithm indeed deals with the overflow problem, but it is complicated, and introduces a trade-off between the space and time complexity, due to the extra work required to maintain the list.Our new algorithm presents a simple lock-free work-stealing deque, which stores the elements in a cyclic array that can grow when it overflows. The algorithm has no limit other than integer overflow (and the system's memory size) on the number of elements that may be on the deque, and the total memory required is linear in the number of elements in the deque.}},
    address = {New York, NY, USA},
    author = {Chase, David and Lev, Yossi},
    booktitle = {SPAA '05: Proceedings of the seventeenth annual ACM symposium on Parallelism in algorithms and architectures},
    citeulike-article-id = {4663310},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1073970.1073974},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1073970.1073974},
    doi = {10.1145/1073970.1073974},
    isbn = {1-58113-986-1},
    keywords = {deque, lock-free, parallel-programming, performance, workstealing},
    location = {Las Vegas, Nevada, USA},
    pages = {21--28},
    posted-at = {2015-01-08 09:50:04},
    priority = {3},
    publisher = {ACM},
    title = {{Dynamic circular work-stealing deque}},
    url = {http://dx.doi.org/10.1145/1073970.1073974},
    year = {2005}
}

@article{Drepper2007What,
    abstract = {{As CPU cores become both faster and more numerous, the limiting factor for most programs is now, and will be for some time, memory access. Hardware designers have come up with ever more sophisticated memory handling and acceleration techniques\^{a}such as CPU caches\^{a}but these cannot work optimally without some help from the programmer. Unfortunately, neither the structure nor the cost of using the memory subsystem of a computer or the caches on CPUs is well understood by most programmers. This paper explains the structure of memory subsystems in use on modern commodity hardware, illustrating why CPU caches were developed, how they work, and what programs should do to achieve optimal performance by utilizing them.}},
    author = {Drepper, Ulrich},
    citeulike-article-id = {8398331},
    citeulike-linkout-0 = {http://www.akkadia.org/drepper/cpumemory.pdf},
    citeulike-linkout-1 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.91.957},
    keywords = {hardware, linux, memory, unix},
    posted-at = {2014-11-24 08:04:45},
    priority = {4},
    title = {{What Every Programmer Should Know About Memory}},
    url = {http://www.akkadia.org/drepper/cpumemory.pdf},
    year = {2007}
}

@inproceedings{Grossman2007Transactional,
    abstract = {{This essay presents remarkable similarities between transactional memory and garbage collection. The connections are fascinating in their own right, and they let us better understand one technology by thinking about the corresponding issues for the other.}},
    address = {New York, NY, USA},
    author = {Grossman, Dan},
    booktitle = {Proceedings of the 22Nd Annual ACM SIGPLAN Conference on Object-oriented Programming Systems and Applications},
    citeulike-article-id = {1903871},
    citeulike-linkout-0 = {http://homes.cs.washington.edu/~djg/papers/analogy_oopsla07.pdf},
    citeulike-linkout-1 = {http://portal.acm.org/citation.cfm?id=1297027.1297080},
    citeulike-linkout-2 = {http://dx.doi.org/10.1145/1297027.1297080},
    doi = {10.1145/1297027.1297080},
    isbn = {978-1-59593-786-5},
    keywords = {gc, parallel-programming},
    location = {Montreal, Quebec, Canada},
    pages = {695--706},
    posted-at = {2014-11-24 08:02:10},
    priority = {2},
    publisher = {ACM},
    series = {OOPSLA '07},
    title = {{The Transactional Memory / Garbage Collection Analogy}},
    url = {http://homes.cs.washington.edu/~djg/papers/analogy_oopsla07.pdf},
    year = {2007}
}

@incollection{Kobayashi2003Type,
    abstract = {{Type systems for programming languages help reasoning about program behavior and early finding of bugs. Recent applications of type systems include analysis of various program behaviors such as side effects, resource usage, security properties, and concurrency. This paper is a tutorial of one of such applications: type systems for analyzing behavior of concurrent processes. We start with a simple type system and extend it step by step to obtain more expressive type systems to reason about deadlock-freedom, safe usage of locks, etc.}},
    author = {Kobayashi, Naoki},
    booktitle = {Formal Methods at the Crossroads. From Panacea to Foundational Support},
    citeulike-article-id = {13366995},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-540-40007-3_26},
    citeulike-linkout-1 = {http://link.springer.com/chapter/10.1007/978-3-540-40007-3_26},
    doi = {10.1007/978-3-540-40007-3_26},
    editor = {Aichernig, BernhardK and Maibaum, Tom},
    keywords = {concurrency-verification, parallel-programming, types},
    pages = {439--453},
    posted-at = {2014-09-18 16:36:50},
    priority = {1},
    publisher = {Springer Berlin Heidelberg},
    series = {Lecture Notes in Computer Science},
    title = {{Type Systems for Concurrent Programs}},
    url = {http://dx.doi.org/10.1007/978-3-540-40007-3_26},
    volume = {2757},
    year = {2003}
}

@article{Brady2010CorrectbyConstruction,
    author = {Brady, Edwin and Hammond, Kevin},
    citeulike-article-id = {13366755},
    citeulike-linkout-0 = {http://iospress.metapress.com/content/q3118847k1351421/},
    citeulike-linkout-1 = {http://dx.doi.org/10.3233/FI-2010-303},
    day = {01},
    doi = {10.3233/FI-2010-303},
    journal = {Fundamenta Informaticae},
    keywords = {concurrency-verification, parallel-programming, types},
    number = {2},
    pages = {145--176},
    posted-at = {2014-09-18 12:29:05},
    priority = {2},
    title = {{Correct-by-Construction Concurrency: Using Dependent Types to Verify Implementations of Effectful Resource Usage Protocols}},
    url = {http://iospress.metapress.com/content/q3118847k1351421/},
    volume = {102},
    year = {2010}
}

@article{Erdos1960On,
    author = {Erdos, P. and Renyi, A.},
    citeulike-article-id = {1666220},
    citeulike-linkout-0 = {http://www.renyi.hu/~p_erdos/1960-10.pdf},
    journal = {Publ. Math. Inst. Hung. Acad. Sci},
    keywords = {graphs, random, review},
    pages = {17--61},
    posted-at = {2014-05-19 10:19:50},
    priority = {1},
    title = {{On the evolution of random graphs}},
    url = {http://www.renyi.hu/~p_erdos/1960-10.pdf},
    volume = {5},
    year = {1960}
}

@article{Bollobas1984Evolution,
    abstract = {According to a fundamental result of Erd\"{o}s and R\'{e}nyi, the structure of a random graph \$G\_M\$ changes suddenly when \$M \sim n/2:\$ if \$M = \lfloor cn \rfloor\$ and \$c < \frac{1}{2}\$ then a.e. random graph of order \$n\$ and since \$M\$ is such that its largest component has \$O(\log n)\$ vertices, but for \$c > \frac{1}{2} a.e. \$G\_M\$ has a giant component: a component of order \$(1 - \alpha\_c + o(1))n\$ where \$\alpha\_c < 1\$. The aim of this paper is to examine in detail the structure of a random graph \$G\_M\$ when \$M\$ is close to \$n/2\$. Among others it is proved that if \$M = n/2 + s, s = o(n)\$ and \$s \geq (\log n)^{1/2}n^{2/3}\$ then the giant component has \$(4 + o(1))s\$ vertices. Furthermore, rather precise estimates are given for the order of the \$r\$th largest component for every fixed \$r\$.},
    author = {Bollobas, Bela},
    citeulike-article-id = {4596187},
    citeulike-linkout-0 = {http://dx.doi.org/10.2307/1999405},
    citeulike-linkout-1 = {http://www.jstor.org/stable/1999405},
    doi = {10.2307/1999405},
    issn = {00029947},
    journal = {Transactions of the American Mathematical Society},
    keywords = {graphs, random, review},
    month = nov,
    number = {1},
    pages = {257--274},
    posted-at = {2014-05-19 10:18:11},
    priority = {1},
    publisher = {American Mathematical Society},
    title = {{The Evolution of Random Graphs}},
    url = {http://dx.doi.org/10.2307/1999405},
    volume = {286},
    year = {1984}
}

@article{Hesselink2001Concurrent,
    author = {Hesselink, Wim H. and Meijster, Arnold and Bron, Coenraad},
    citeulike-article-id = {13156334},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/s0167-6423(01)00007-7},
    doi = {10.1016/s0167-6423(01)00007-7},
    issn = {01676423},
    journal = {Science of Computer Programming},
    keywords = {computer-vision, morphology, parallel-programming, segmentation, union-find},
    month = oct,
    number = {2},
    pages = {173--194},
    posted-at = {2014-05-01 13:43:47},
    priority = {0},
    title = {{Concurrent determination of connected components}},
    url = {http://dx.doi.org/10.1016/s0167-6423(01)00007-7},
    volume = {41},
    year = {2001}
}

@book{Roscoe1997Theory,
    abstract = {{From the Publisher:Since the introduction of Hoares' Communicating Sequential Processes notation, powerful new tools have transformed CSP into a practical way of describing industrial-sized problems. This book gives you the fundamental grasp of CSP concepts you'll need to take advantage of those tools.Part I provides a detailed foundation for working with CSP, using as little mathematics as possible. It introduces the ideas behind operational, denotational and algebraic models of CSP. Parts II and III go into greater detail about theory and practice. Topics include: parallel operators, hiding and renaming, piping and enslavement, buffers and communication, termination and sequencing, and semantic theory. Three detailed practical case studies are also presented.For anyone interested in modeling sequential processes.}},
    address = {Upper Saddle River, NJ, USA},
    author = {Roscoe, A. W. and Hoare, C. A. R. and Bird, Richard},
    citeulike-article-id = {1010001},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=550448},
    isbn = {0136744095},
    keywords = {concurrency-verification, csp, formal-methods, parallel-programming},
    posted-at = {2014-04-25 13:36:03},
    priority = {1},
    publisher = {Prentice Hall PTR},
    title = {{The Theory and Practice of Concurrency}},
    url = {http://portal.acm.org/citation.cfm?id=550448},
    year = {1997}
}

@article{Hoare1978Communicating,
    abstract = {{This paper suggests that input and output are basic primitives of programming and that parallel composition of communicating sequential processes is a fundamental program structuring method. When combined with a development of Dijkstra's guarded command, these concepts are surprisingly versatile. Their use is illustrated by sample solutions of a variety of a familiar programming exercises.}},
    address = {New York, NY, USA},
    author = {Hoare, C. A. R.},
    citeulike-article-id = {785872},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=359585},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/359576.359585},
    doi = {10.1145/359576.359585},
    issn = {0001-0782},
    journal = {Commun. ACM},
    keywords = {concurrency-verification, csp, formal-methods, parallel-programming},
    month = aug,
    number = {8},
    pages = {666--677},
    posted-at = {2014-04-25 13:32:18},
    priority = {2},
    publisher = {ACM},
    title = {{Communicating Sequential Processes}},
    url = {http://dx.doi.org/10.1145/359576.359585},
    volume = {21},
    year = {1978}
}

@misc{PerfWiki,
    citeulike-article-id = {13141391},
    citeulike-linkout-0 = {https://perf.wiki.kernel.org/index.php/Main_Page},
    howpublished = {https://perf.wiki.kernel.org/},
    keywords = {linux-kernel, website},
    note = {Accessed: 18.04.2014},
    posted-at = {2014-04-18 10:41:23},
    priority = {0},
    title = {{perf: Linux profiling with performance counters}},
    url = {https://perf.wiki.kernel.org/index.php/Main_Page}
}

@unpublished{Sestoft2013Microbenchmarks,
    address = {Rued Langgaards Vej , 2300 Copenhagen},
    author = {Sestoft, Peter},
    citeulike-article-id = {13140844},
    citeulike-linkout-0 = {https://www.itu.dk/people/sestoft/papers/benchmarking.pdf},
    howpublished = {https://www.itu.dk/people/sestoft/papers/benchmarking.pdf},
    keywords = {java, microbenchmarks, performance},
    month = sep,
    note = {Lecture Notes},
    organization = {IT University of Copenhagen},
    posted-at = {2014-04-17 14:48:04},
    priority = {0},
    title = {{Microbenchmarks in Java and C\#}},
    url = {https://www.itu.dk/people/sestoft/papers/benchmarking.pdf},
    year = {2013}
}

@incollection{Cok2011OpenJML,
    abstract = {{The Java Modeling Language is a widely used specification language for Java. However, the tool support has not kept pace with advances in the Java language. This paper describes OpenJML, an implementation of JML tools built by extending the OpenJDK Java tool set. OpenJDK has a readily extendible architecture, though its details could be revised to further facilitate extension. The result is a suite of JML tools for Java 7 that provides static analysis, specification documentation, and runtime checking, an API that is used for other tools, uses Eclipse as an IDE, and can be extended for further research. In addition, OpenJML can leverage the community effort devoted to OpenJDK.}},
    author = {Cok, DavidR},
    booktitle = {NASA Formal Methods},
    citeulike-article-id = {13139781},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-642-20398-5_35},
    citeulike-linkout-1 = {http://link.springer.com/chapter/10.1007/978-3-642-20398-5_35},
    doi = {10.1007/978-3-642-20398-5_35},
    editor = {Bobaru, Mihaela and Havelund, Klaus and Holzmann, GerardJ and Joshi, Rajeev},
    keywords = {formal-methods, jml, model-checking},
    pages = {472--479},
    posted-at = {2014-04-16 13:20:35},
    priority = {1},
    publisher = {Springer Berlin Heidelberg},
    series = {Lecture Notes in Computer Science},
    title = {{OpenJML: JML for Java 7 by Extending OpenJDK}},
    url = {http://dx.doi.org/10.1007/978-3-642-20398-5_35},
    volume = {6617},
    year = {2011}
}

@incollection{Khurshid2003Generalized,
    abstract = {{Modern software systems, which often are concurrent and manipulate complex data structures must be extremely reliable. We present a novel framework based on symbolic execution, for automated checking of such systems. We provide a two-fold generalization of traditional symbolic execution based approaches. First, we define a source to source translation to instrument a program, which enables standard model checkers to perform symbolic execution of the program. Second, we give a novel symbolic execution algorithm that handles dynamically allocated structures (e.g., lists and trees), method preconditions (e.g., acyclicity), data (e.g., integers and strings) and concurrency. The program instrumentation enables a model checker to automatically explore different program heap configurations and manipulate logical formulae on program data (using a decision procedure). We illustrate two applications of our framework: checking correctness of multi-threaded programs that take inputs from unbounded domains with complex structure and generation of non-isomorphic test inputs that satisfy a testing criterion. Our implementation for Java uses the Java PathFinder model checker.}},
    address = {Berlin, Heidelberg},
    author = {Khurshid, Sarfraz and P\u{A}s\u{A}reanu, CorinaS and Visser, Willem},
    booktitle = {Tools and Algorithms for the Construction and Analysis of Systems},
    chapter = {40},
    citeulike-article-id = {3037858},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/3-540-36577-x_40},
    citeulike-linkout-1 = {http://www.springerlink.com/content/pllk4effd3vrec7l},
    citeulike-linkout-2 = {http://link.springer.com/chapter/10.1007/3-540-36577-X_40},
    day = {28},
    doi = {10.1007/3-540-36577-x_40},
    editor = {Garavel, Hubert and Hatcliff, John},
    isbn = {978-3-540-00898-9},
    journal = {Tools and Algorithms for the Construction and Analysis of Systems},
    keywords = {formal-methods, jpf, model-checking, symbolic},
    month = feb,
    pages = {553--568},
    posted-at = {2014-04-16 11:52:07},
    priority = {1},
    publisher = {Springer Berlin Heidelberg},
    series = {Lecture Notes in Computer Science},
    title = {{Generalized Symbolic Execution for Model Checking and Testing}},
    url = {http://dx.doi.org/10.1007/3-540-36577-x_40},
    volume = {2619},
    year = {2003}
}

@article{Liskov1994Behavioral,
    abstract = {{The use of hierarchy is an important component of object-oriented design. Hierarchy allows the use of type families, in which higher level supertypes capture the behavior that all of their subtypes have in common. For this methodology to be effective, it is necessary to have a clear understanding of how subtypes and supertypes are related. This paper takes the position that the relationship should ensure that any property proved about supertype objects also holds for its subtype objects. It presents two ways of defining the subtype relation, each of which meets this criterion, and each of which is easy for programmers to use. The subtype relation is based on the specifications of the sub- and supertypes; the paper presents a way of specifying types that makes it convenient to define  the subtype relation. The paper also discusses the ramifications of this notion of subtyping on the design of type families.}},
    address = {New York, NY, USA},
    author = {Liskov, Barbara H. and Wing, Jeannette M.},
    citeulike-article-id = {332974},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=197383},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/197320.197383},
    doi = {10.1145/197320.197383},
    issn = {0164-0925},
    journal = {ACM Trans. Program. Lang. Syst.},
    keywords = {formal-methods, liskov-principle, types},
    month = nov,
    number = {6},
    pages = {1811--1841},
    posted-at = {2014-04-15 18:55:29},
    priority = {3},
    publisher = {ACM},
    title = {{A Behavioral Notion of Subtyping}},
    url = {http://dx.doi.org/10.1145/197320.197383},
    volume = {16},
    year = {1994}
}

@inproceedings{varabsint2014,
    author = {Midtgaard, Jan and Brabrand, Claus and Wasowski, Andrzej},
    booktitle = {MODULARITY},
    citeulike-article-id = {13138614},
    keywords = {lift, spl},
    posted-at = {2014-04-15 13:49:43},
    priority = {3},
    title = {{Systematic derivation of static analyses for software product lines}},
    year = {2014}
}

@inproceedings{Bodden2013SPLLIFT,
    abstract = {{A software product line (SPL) encodes a potentially large variety of software products as variants of some common code base. Up until now, re-using traditional static analyses for SPLs was virtually intractable, as it required programmers to generate and analyze all products individually. In this work, however, we show how an important class of existing inter-procedural static analyses can be transparently lifted to SPLs. Without requiring programmers to change a single line of code, our approach SPLLIFT automatically converts any analysis formulated for traditional programs within the popular IFDS framework for inter-procedural, finite, distributive, subset problems to an SPL-aware analysis formulated in the IDE framework, a well-known extension to IFDS. Using a full implementation based on Heros, Soot, CIDE and JavaBDD, we show that with SPLLIFT one can reuse IFDS-based analyses without changing a single line of code. Through experiments using three static analyses applied to four Java-based product lines, we were able to show that our approach produces correct results and outperforms the traditional approach by several orders of magnitude.}},
    address = {New York, NY, USA},
    author = {Bodden, Eric and Tol\^{e}do, T\'{a}rsis and Ribeiro, M\'{a}rcio and Brabrand, Claus and Borba, Paulo and Mezini, Mira},
    booktitle = {Proceedings of the 34th ACM SIGPLAN Conference on Programming Language Design and Implementation},
    citeulike-article-id = {13109014},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2499370.2491976},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2491956.2491976},
    doi = {10.1145/2491956.2491976},
    isbn = {978-1-4503-2014-6},
    keywords = {lift, spl, static-analysis},
    location = {Seattle, Washington, USA},
    pages = {355--364},
    posted-at = {2014-04-15 13:46:59},
    priority = {3},
    publisher = {ACM},
    series = {PLDI '13},
    title = {{SPLLIFT: Statically Analyzing Software Product Lines in Minutes Instead of Years}},
    url = {http://dx.doi.org/10.1145/2491956.2491976},
    year = {2013}
}

@article{Alistarh2013Are,
    author = {Alistarh, D. and Censor-Hillel, K. and Shavit, N.},
    citeulike-article-id = {13119083},
    journal = {ArXiv e-prints},
    keywords = {parallel-programming, performance},
    month = nov,
    posted-at = {2014-03-28 11:41:42},
    priority = {2},
    title = {{Are Lock-Free Concurrent Algorithms Practically Wait-Free?}},
    year = {2013}
}

@article{Visser2004Test,
    abstract = {{We show how model checking and symbolic execution can be used to generate test inputs to achieve structural coverage of code that manipulates complex data structures. We focus on obtaining branch-coverage during unit testing of some of the core methods of the red-black tree implementation in the Java TreeMap library, using the Java PathFinder model checker. Three different test generation techniques will be introduced and compared, namely, straight model checking of the code, model checking used in a black-box fashion to generate all inputs up to a fixed size, and lastly, model checking used during white-box test input generation. The main contribution of this work is to show how efficient white-box test input generation can be done for code manipulating complex data, taking into account complex method preconditions.}},
    address = {New York, NY, USA},
    author = {Visser, Willem and P\v{a}s\v{a}reanu, Corina S. and Khurshid, Sarfraz},
    citeulike-article-id = {80857},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1013886.1007526},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/1013886.1007526},
    doi = {10.1145/1013886.1007526},
    isbn = {1581138202},
    issn = {0163-5948},
    journal = {SIGSOFT Softw. Eng. Notes},
    keywords = {jpf, model-checking},
    month = jul,
    number = {4},
    pages = {97--107},
    posted-at = {2014-03-18 16:19:13},
    priority = {1},
    publisher = {ACM},
    title = {{Test Input Generation with Java PathFinder}},
    url = {http://dx.doi.org/10.1145/1013886.1007526},
    volume = {29},
    year = {2004}
}

@article{Visser2003Model,
    abstract = {{The majority of work carried out in the formal methods community throughout the last three decades has (for good reasons) been devoted to special languages designed to make it easier to experiment with mechanized formal methods such as theorem provers, proof checkers and model checkers. In this paper we will attempt to give convincing arguments for why we believe it is time for the formal methods community to shift some of its attention towards the analysis of programs written in modern programming languages. In keeping with this philosophy we have developed a verification and testing environment for Java, called Java PathFinder (JPF), which integrates model checking, program analysis and testing. Part of this work has consisted of building a new Java Virtual Machine that interprets Java bytecode. JPF uses state compression to handle big states, and partial order and symmetry reduction, slicing, abstraction, and runtime analysis techniques to reduce the state space. JPF has been applied to a real-time avionics operating system developed at Honeywell, illustrating an intricate error, and to a model of a spacecraft controller, illustrating the combination of abstraction, runtime analysis, and slicing with model checking.}},
    address = {Hingham, MA, USA},
    author = {Visser, Willem and Havelund, Klaus and Brat, Guillaume and Park, SeungJoon and Lerda, Flavio},
    booktitle = {Automated Software Engineering},
    citeulike-article-id = {1188784},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=641186},
    citeulike-linkout-1 = {http://dx.doi.org/10.1023/a:1022920129859},
    citeulike-linkout-2 = {http://link.springer.com/article/10.1023/A:1022920129859},
    day = {1},
    doi = {10.1023/a:1022920129859},
    issn = {0928-8910},
    journal = {Automated Software Engg.},
    keywords = {concurrency-verification, jpf, model-checking},
    month = apr,
    number = {2},
    pages = {203--232},
    posted-at = {2014-03-18 14:51:02},
    priority = {1},
    publisher = {Kluwer Academic Publishers},
    title = {{Model Checking Programs}},
    url = {http://dx.doi.org/10.1023/a:1022920129859},
    volume = {10},
    year = {2003}
}

@article{Edelstein2002Multithreaded,
    author = {Edelstein, O. and Farchi, E. and Nir, Y. and Ratsaby, G. and Ur, S.},
    citeulike-article-id = {13093451},
    citeulike-linkout-0 = {http://dx.doi.org/10.1147/sj.411.0111},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5386903},
    doi = {10.1147/sj.411.0111},
    institution = {IBM Research Division, Haifa Research Laboratory, MATAM, 31905, Israel},
    issn = {0018-8670},
    journal = {IBM Systems Journal},
    keywords = {concurrency-verification, parallel-programming},
    number = {1},
    pages = {111--125},
    posted-at = {2014-03-05 09:39:48},
    priority = {1},
    publisher = {IBM},
    title = {{Multithreaded Java program test generation}},
    url = {http://dx.doi.org/10.1147/sj.411.0111},
    volume = {41},
    year = {2002}
}

@inproceedings{Bolosky1993False,
    abstract = {{False sharing occurs when processors in a shared-memory parallel system make references to different data objects within the same coherence block (cache line or page), thereby inducing \&quot;unnecessary\&quot; coherence operations. False sharing is widely believed to be a serious problem for parallel program performance, but a precise definition and quantification of the problem has proven to be elusive. We explain why. In the process, we present a variety of possible definitions for false sharing, and...}},
    author = {Bolosky, William J. and Scott, Michael L.},
    booktitle = {Proceedings of the USENIX SEDMS IV Conference},
    citeulike-article-id = {2792244},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.17.3255},
    keywords = {parallel-programming, performance},
    posted-at = {2014-02-19 11:03:23},
    priority = {3},
    title = {{False Sharing and its Effect on Shared Memory Performance}},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.17.3255},
    year = {1993}
}

@article{Shavit1997Software,
    abstract = {{As we learn from the literature, flexibility in choosing synchronization operations greatly simplifies the task of designing highly concurrent programs. Unfortunately, existing hardware is inflexible and is at best on the level of a Load–Linked/Store–Conditional operation on a single word. Building on the hardware based transactional synchronization methodology of Herlihy and Moss, we offer software transactional memory (STM), a novel software method for supporting flexible transactional programming of synchronization operations. STM is non-blocking, and can be implemented on existing machines using only a Load–Linked/Store–Conditional operation. We use STM to provide a general highly concurrent method for translating sequential object implementations to non-blocking ones based on implementing a k-word compare\&swap STM-transaction. Empirical evidence collected on simulated multiprocessor architectures shows that our method always outperforms the non-blocking translation methods in the style of Barnes, and outperforms Herlihy's translation method for sufficiently large numbers of processors. The key to the efficiency of our software-transactional approach is that unlike Barnes style methods, it is not based on a costly  ” recursive helping” policy.}},
    author = {Shavit, Nir and Touitou, Dan},
    booktitle = {Distributed Computing},
    citeulike-article-id = {2056039},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/s004460050028},
    citeulike-linkout-1 = {http://link.springer.com/article/10.1007/s004460050028},
    day = {22},
    doi = {10.1007/s004460050028},
    journal = {Distributed Computing},
    keywords = {parallel-programming, stm},
    month = feb,
    number = {2},
    pages = {99--116},
    posted-at = {2014-02-11 12:12:26},
    priority = {2},
    publisher = {Springer-Verlag},
    title = {{Software transactional memory}},
    url = {http://dx.doi.org/10.1007/s004460050028},
    volume = {10},
    year = {1997}
}

@article{Erdos1959Random,
    author = {Erd\"{o}s, P. and R\'{e}nyi, A.},
    citeulike-article-id = {1282814},
    citeulike-linkout-0 = {http://www.renyi.hu/~p_erdos/1959-11.pdf},
    journal = {Publicationes Mathematicae},
    keywords = {graphs, random},
    pages = {290--297},
    posted-at = {2014-02-02 14:59:25},
    priority = {0},
    title = {{On Random Graphs, I}},
    url = {http://www.renyi.hu/~p_erdos/1959-11.pdf},
    volume = {6},
    year = {1959}
}

@article{Sutter2005Free,
    author = {Sutter, Herb},
    citeulike-article-id = {12941114},
    citeulike-linkout-0 = {http://www.gotw.ca/publications/concurrency-ddj.htm},
    howpublished = {http://www.gotw.ca/publications/concurrency-ddj.htm},
    journal = {Dr. Dobb's Journal},
    keywords = {parallel-programming, review},
    month = mar,
    number = {3},
    posted-at = {2014-01-29 15:01:02},
    priority = {0},
    title = {{The free lunch is over: a fundamental turn toward concurrency in software.}},
    url = {http://www.gotw.ca/publications/concurrency-ddj.htm},
    volume = {30},
    year = {2005}
}

@misc{MultiverseWebsite,
    citeulike-article-id = {12941067},
    citeulike-linkout-0 = {http://multiverse.codehaus.org},
    howpublished = {http://multiverse.codehaus.org},
    keywords = {parallel-programming, stm, website},
    note = {Accessed: 29.01.2014},
    posted-at = {2014-01-29 14:07:48},
    priority = {0},
    title = {{Software Transactional Memory for Java \& the JVM}},
    url = {http://multiverse.codehaus.org}
}

@phdthesis{Nethercote2004Dynamic,
    abstract = {{This dissertation describes Valgrind in some detail (some of these details are now out-of-date) as well as Cachegrind, Annelid and Redux; it also covers some underlying theory about dynamic binary analysis in general and what all these tools have in common. Please cite it if you are writing about Cachegrind, or the dynamic binary analysis theory work. If you are writing about Valgrind in general, please cite the PLDI2007 paper above in preference. If you are writing about Annelid, please cite the SPACE2004 paper in preference. If you are writing about Redux, please cite the ENTCS paper in preference.}},
    author = {Nethercote, Nicholas},
    citeulike-article-id = {12940265},
    citeulike-linkout-0 = {http://valgrind.org/docs/phd2004.pdf},
    keywords = {cachegrind, instrumentation, performance},
    month = nov,
    posted-at = {2014-01-28 15:23:53},
    priority = {1},
    school = {University of Cambridge},
    title = {{Dynamic Binary Analysis and Instrumentation}},
    url = {http://valgrind.org/docs/phd2004.pdf},
    year = {2004}
}

@book{Herlihy2008Art,
    abstract = {{Multiprocessor programming, also known as multicore programming, requires new principles, algorithms, and programming tools. This book provides a comprehensive presentation of the principles and tools available for programming multiprocessor machines. It will be of immediate use to programmers working with the new architectures.}},
    author = {Herlihy, Maurice and Shavit, Nir},
    citeulike-article-id = {10675355},
    citeulike-linkout-0 = {http://www.worldcat.org/isbn/9780123705914},
    citeulike-linkout-1 = {http://books.google.com/books?vid=ISBN9780123705914},
    citeulike-linkout-2 = {http://www.amazon.com/gp/search?keywords=9780123705914&index=books&linkCode=qs},
    citeulike-linkout-3 = {http://www.librarything.com/isbn/9780123705914},
    citeulike-linkout-4 = {http://www.worldcat.org/oclc/776069297},
    isbn = {9780123705914},
    keywords = {book, parallel-programming},
    posted-at = {2014-01-07 12:54:55},
    priority = {3},
    publisher = {Elsevier/Morgan Kaufmann},
    title = {{The art of multiprocessor programming}},
    url = {http://www.worldcat.org/isbn/9780123705914},
    year = {2008}
}

@book{Goetz2006Java,
    author = {Goetz, Brian and Peierls, Tim and Bloch, Joshua and Bowbeer, Joseph and Holmes, David and Lea, Doug},
    citeulike-article-id = {1030084},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20&amp;path=ASIN/0321349601},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21&amp;path=ASIN/0321349601},
    citeulike-linkout-10 = {http://www.worldcat.org/oclc/846089284},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21&amp;path=ASIN/0321349601},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0321349601},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0321349601/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20&path=ASIN/0321349601},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0321349601},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0321349601},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0321349601&index=books&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0321349601},
    day = {19},
    edition = {1},
    howpublished = {Paperback},
    isbn = {0321349601},
    keywords = {book, parallel-programming},
    month = may,
    posted-at = {2013-12-16 22:08:02},
    priority = {0},
    publisher = {Addison-Wesley Professional},
    title = {{Java Concurrency in Practice}},
    url = {http://www.worldcat.org/isbn/0321349601},
    year = {2006}
}

@mastersthesis{Berman2010Multicore,
    abstract = {{A crucial question facing today's multicore programmers is which programming methodology to use for coordination and data structure design: fine grained locking, lock-free or wait-free synchronization, or perhaps transactional memory. One aspect of this question that has received little attention is the tradeoff between performance and flexibility. In other words, given a data structure implemented using methodology X, delivering a given level of scalability, how costly is it, in terms of both  performance and ease of programming, to use
methodology X to add new features to this existing algorithm.

This work studies the flexibility question in the context of the union-find
problem, a problem that is a unique fit for our quest in that it has a known efficient wait-free concurrent solution for implementing the union and find methods, but only a complex sequential solution if one wishes to allow delete methods.

Based on union find, we are able to make interesting observations about the
relative benefits of using locks, non-blocking algorithms, and state-of-the-art software transactional memory systems. Moreover, based on our new understandings, we present highly efficient and flexible algorithms for the union-find and union-find-delete problems that we believe are of independent interest.}},
    address = {Schreiber Building, Tel Aviv University, P.O.B. 39040, Ramat Aviv, Tel Aviv 69978},
    author = {Berman, Igor},
    citeulike-article-id = {12810835},
    citeulike-linkout-0 = {http://mcg.cs.tau.ac.il/papers/igor-berman-msc.pdf},
    keywords = {algorithms, parallel-programming, union-find},
    month = jul,
    posted-at = {2013-12-03 10:16:57},
    priority = {0},
    school = {Tel-Aviv University, School of Computer Science},
    title = {{Multicore Programming in the Face of Metamorphosis: Union-Find as an Example}},
    url = {http://mcg.cs.tau.ac.il/papers/igor-berman-msc.pdf},
    year = {2010}
}

@book{Tarjan1983Data,
    author = {Tarjan, Robert E.},
    citeulike-article-id = {12799896},
    citeulike-linkout-0 = {http://www.worldcat.org/isbn/9780898711875},
    citeulike-linkout-1 = {http://books.google.com/books?vid=ISBN9780898711875},
    citeulike-linkout-2 = {http://www.amazon.com/gp/search?keywords=9780898711875&index=books&linkCode=qs},
    citeulike-linkout-3 = {http://www.librarything.com/isbn/9780898711875},
    citeulike-linkout-4 = {http://www.worldcat.org/oclc/848042077},
    isbn = {9780898711875},
    keywords = {algorithms, book, union-find},
    posted-at = {2013-11-25 10:50:22},
    priority = {2},
    publisher = {Society For Industrial And Applied Mathematics},
    title = {{Data structures and network algorithms}},
    url = {http://www.worldcat.org/isbn/9780898711875},
    year = {1983}
}

@inproceedings{Manne2010Scalable,
    abstract = {{The Union-Find algorithm is used for maintaining a number of non-overlapping sets from a finite universe of elements. The algorithm has applications in a number of areas including the computation of spanning trees, sparse linear algebra, and in image processing. Although the algorithm is inherently sequential there has been some previous efforts at constructing parallel implementations. These have mainly focused on shared memory computers. In this paper we present the first scalable parallel implementation of the Union-Find algorithm suitable for distributed memory computers. Our new parallel algorithm is based on an observation of how the Find part of the sequential algorithm can be executed more efficiently. We show the efficiency of our implementation through a series of tests to compute spanning forests of very large graphs.}},
    address = {Berlin, Heidelberg},
    author = {Manne, Fredrik and Md},
    booktitle = {Proceedings of the 8th International Conference on Parallel Processing and Applied Mathematics: Part I},
    citeulike-article-id = {12793006},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1882815},
    isbn = {3-642-14389-X, 978-3-642-14389-2},
    keywords = {algorithms, parallel-programming, union-find},
    location = {Wroclaw, Poland},
    pages = {186--195},
    posted-at = {2013-11-18 18:08:04},
    priority = {3},
    publisher = {Springer-Verlag},
    series = {PPAM'09},
    title = {{A Scalable Parallel Union-find Algorithm for Distributed Memory Computers}},
    url = {http://portal.acm.org/citation.cfm?id=1882815},
    year = {2010}
}

@inproceedings{Gabow1983Lineartime,
    abstract = {{This paper presents a linear-time algorithm for the special case of the disjoint set union problem in which the structure of the unions (defined by a  ” union tree”) is known in advance. The algorithm executes an intermixed sequence of m union and find operations on n elements in 0(m+n) time and 0(n) space. This is a slight but theoretically significant improvement over the fastest known algorithm for the general problem, which runs in 0(m\&agr;(m+n, n)+n) time and 0(n) space, where \&agr; is a functional inverse of Ackermann's function. Used as a subroutine, the algorithm gives similar improvements in the efficiency of algorithms for solving a number of other problems, including two-processor scheduling, the off-line min problem, matching on convex graphs, finding nearest common ancestors off-line, testing a flow graph for reducibility, and finding two disjoint directed spanning trees. The algorithm obtains its efficiency by combining a fast algorithm for the general problem with table look-up on small sets, and requires a random access machine for its implementation. The algorithm extends to the case in which single-node additions to the union tree are allowed. The extended algorithm is useful in finding maximum cardinality matchings on nonbipartite graphs.}},
    address = {New York, NY, USA},
    author = {Gabow, Harold N. and Tarjan, Robert E.},
    booktitle = {Proceedings of the Fifteenth Annual ACM Symposium on Theory of Computing},
    citeulike-article-id = {3358358},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=808753},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/800061.808753},
    doi = {10.1145/800061.808753},
    isbn = {0-89791-099-0},
    keywords = {algorithms, union-find},
    pages = {246--251},
    posted-at = {2013-11-18 18:06:34},
    priority = {2},
    publisher = {ACM},
    series = {STOC '83},
    title = {{A Linear-time Algorithm for a Special Case of Disjoint Set Union}},
    url = {http://dx.doi.org/10.1145/800061.808753},
    year = {1983}
}

@inproceedings{Fruhwirth2005Parallelizing,
    abstract = {{Constraint Handling Rules is a logical concurrent committed-choice rule-based language. Recently it was shown that the classical union-find algorithm can be implemented in CHR with optimal time complexity. Here we investigate if a parallel implementation of this algorithm is also possible in CHR. The problem is hard for several reasons: - Up to now, no parallel computation model for CHR was defined. - Tarjan's optimal union-find is known to be hard to parallelize. - The parallel code should be as close as possible to the sequential one. It turns out that confluence analysis of the sequential implementation gives almost all the information needed to parallelize the union-find algorithm under a rather general parallel computation model for CHR.}},
    address = {Berlin, Heidelberg},
    author = {Fr\"{u}hwirth, Thom},
    booktitle = {Proceedings of the 21st International Conference on Logic Programming},
    citeulike-article-id = {12793001},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2079636},
    citeulike-linkout-1 = {http://dx.doi.org/10.1007/11562931_11},
    doi = {10.1007/11562931_11},
    isbn = {3-540-29208-X, 978-3-540-29208-1},
    keywords = {algorithms, parallel-programming, union-find},
    location = {Sitges, Spain},
    pages = {113--127},
    posted-at = {2013-11-18 18:03:56},
    priority = {3},
    publisher = {Springer-Verlag},
    series = {ICLP'05},
    title = {{Parallelizing Union-find in Constraint Handling Rules Using Confluence Analysis}},
    url = {http://dx.doi.org/10.1007/11562931_11},
    year = {2005}
}

@book{Guenther1990Modern,
    abstract = {{The most up-to-date treatment available on modern optics. Covers classical topics and surveys the state of the art in applications including laser optics, fiber optics and medical imaging. The rigorous physical approach makes this text/reference suitable for courses in optics, physics and electrical engineering.}},
    author = {Guenther, Robert D.},
    citeulike-article-id = {1847556},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20&amp;path=ASIN/0471605387},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21&amp;path=ASIN/0471605387},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21&amp;path=ASIN/0471605387},
    citeulike-linkout-3 = {http://www.amazon.co.uk/exec/obidos/ASIN/0471605387/citeulike00-21},
    citeulike-linkout-4 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20&path=ASIN/0471605387},
    citeulike-linkout-5 = {http://www.worldcat.org/isbn/0471605387},
    citeulike-linkout-6 = {http://books.google.com/books?vid=ISBN0471605387},
    citeulike-linkout-7 = {http://www.amazon.com/gp/search?keywords=0471605387&index=books&linkCode=qs},
    citeulike-linkout-8 = {http://www.librarything.com/isbn/0471605387},
    citeulike-linkout-9 = {http://www.worldcat.org/oclc/20133975},
    day = {16},
    howpublished = {Paperback},
    isbn = {0471605387},
    month = jan,
    posted-at = {2013-11-17 16:07:11},
    priority = {1},
    publisher = {Wiley},
    title = {{Modern optics}},
    url = {http://www.worldcat.org/isbn/0471605387},
    year = {1990}
}

@inproceedings{Groves2008Verifying,
    abstract = {{Lock-free algorithms have been developed to avoid various problems associated with using locks to control access to shared data structures. These algorithms are typically more intricate than lock-based algorithms, as they allow more complex interactions between processes, and many published algorithms have turned out to contain errors. There is thus a pressing need for practical techniques for verifying lock-free algorithms and programs that use them. In this paper we show how Michael and Scott's well known lock-free queue algorithm can be verified using a trace reduction method, based on Lipton's reduction method. Michael and Scott's queue is an interesting case study because, although the basic idea is easy to understand, the actual algorithm is quite subtle, and it demonstrates several way in which the basic reduction method needs to be extended.}},
    address = {Darlinghurst, Australia, Australia},
    author = {Groves, Lindsay},
    booktitle = {Proceedings of the Fourteenth Symposium on Computing: The Australasian Theory - Volume 77},
    citeulike-article-id = {12787822},
    citeulike-linkout-0 = {http://crpit.com/abstracts/CRPITV77Groves.html},
    citeulike-linkout-1 = {http://portal.acm.org/citation.cfm?id=1379385},
    isbn = {978-1-920682-58-3},
    keywords = {algorithms, concurrency-verification, parallel-programming},
    location = {Wollongong, NSW, Australia},
    pages = {133--142},
    posted-at = {2013-11-13 21:12:26},
    priority = {3},
    publisher = {Australian Computer Society, Inc.},
    series = {CATS '08},
    title = {{Verifying Michael and Scott's Lock-free Queue Algorithm Using Trace Reduction}},
    url = {http://crpit.com/abstracts/CRPITV77Groves.html},
    year = {2008}
}

@techreport{Vafeiadis2008Modular,
    abstract = {{Traditionally, concurrent data structures are protected by a single mutual exclusion lock so that only one thread may access the data structure at any time. This coarse-grained approach makes it relatively easy to reason about correctness, but it severely limits parallelism. More advanced algorithms instead perform synchronisation at a finer grain. They employ sophisticated synchronisation schemes (both blocking and non-blocking) and are usually written in low-level languages such as C. This dissertation addresses the formal verification of such algorithms. It proposes techniques that are modular (and hence scalable), easy for programmers to use, and yet powerful enough to verify complex algorithms. In doing so, it makes two theoretical and two practical contributions to reasoning about fine-grained concurrency. First, building on rely/guarantee reasoning and separation logic, it develops a new logic, RGSep, that subsumes these two logics and enables simple, modular proofs of finegrained concurrent algorithms that use complex dynamically allocated data structures and may explicitly deallocate memory. RGSep allows for ownership-based reasoning and ownership}},
    author = {Vafeiadis, Viktor},
    citeulike-article-id = {12787818},
    citeulike-linkout-0 = {http://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-726.html},
    citeulike-linkout-1 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.145.9530},
    institution = {University of Cambridge, Computer Laboratory},
    keywords = {concurrency-verification, parallel-programming},
    month = jul,
    posted-at = {2013-11-13 21:09:22},
    priority = {3},
    title = {{Modular fine-grained concurrency verification}},
    url = {http://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-726.html},
    year = {2008}
}

@article{Kogan2012Methodology,
    abstract = {{Lock-freedom is a progress guarantee that ensures overall program progress. Wait-freedom is a stronger progress guarantee that ensures the progress of each thread in the program. While many practical lock-free algorithms exist, wait-free algorithms are typically inefficient and hardly used in practice. In this paper, we propose a methodology called fast-path-slow-path for creating efficient wait-free algorithms. The idea is to execute the efficient lock-free version most of the time and revert to the wait-free version only when things go wrong. The generality and effectiveness of this methodology is demonstrated by two examples. In this paper, we apply this idea to a recent construction of a wait-free queue, bringing the wait-free implementation to perform in practice as efficient as the lock-free implementation. In another work, the fast-path-slow-path methodology has been used for (dramatically) improving the performance of a wait-free linked-list.}},
    address = {New York, NY, USA},
    author = {Kogan, Alex and Petrank, Erez},
    citeulike-article-id = {12739472},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=2145816.2145835},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/2370036.2145835},
    doi = {10.1145/2370036.2145835},
    issn = {0362-1340},
    journal = {SIGPLAN Not.},
    keywords = {parallel-programming},
    month = feb,
    number = {8},
    pages = {141--150},
    posted-at = {2013-11-12 08:35:15},
    priority = {3},
    publisher = {ACM},
    title = {{A Methodology for Creating Fast Wait-free Data Structures}},
    url = {http://dx.doi.org/10.1145/2370036.2145835},
    volume = {47},
    year = {2012}
}

@article{Wilkinson2008Concurrent,
    author = {Wilkinson, M. H. F. and Gao, Hui and Hesselink, W. H. and Jonker, J. E. and Meijster, A.},
    citeulike-article-id = {12754964},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/tpami.2007.70836},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4407727},
    doi = {10.1109/tpami.2007.70836},
    institution = {Inst. for Math. \& Comput. Sci., Univ. of Groningen, Groningen},
    issn = {0162-8828},
    journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
    keywords = {morphology, parallel-programming, performance},
    month = oct,
    number = {10},
    pages = {1800--1813},
    posted-at = {2013-11-05 09:12:45},
    priority = {0},
    publisher = {IEEE},
    title = {{Concurrent Computation of Attribute Filters on Shared Memory Parallel Machines}},
    url = {http://dx.doi.org/10.1109/tpami.2007.70836},
    volume = {30},
    year = {2008}
}

@article{Loncaric1998Survey,
    abstract = {{This paper provides a review of shape analysis methods. Shape analysis methods play an important role in systems for object recognition, matching, registration, and analysis. Research in shape analysis has been motivated, in part, by studies of human visual form perception systems. Several theories of visual form perception are briefly mentioned. Shape analysis methods are classified into several groups. Classification is determined according to the use of shape boundary or interior, and according to the type of result. An overview of the most representative methods is presented.}},
    author = {Loncaric, Sven},
    citeulike-article-id = {3151892},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/s0031-2023(97)00122-2},
    citeulike-linkout-1 = {http://www.sciencedirect.com/science/article/B6V14-44898T8-1/2/581c3ea67bf7fc023dff96b5b9edac24},
    day = {01},
    doi = {10.1016/s0031-2023(97)00122-2},
    issn = {00313203},
    journal = {Pattern Recognition},
    keywords = {computer-vision, shape-analysis},
    month = aug,
    number = {8},
    pages = {983--1001},
    posted-at = {2013-11-04 16:34:47},
    priority = {1},
    title = {{A survey of shape analysis techniques}},
    url = {http://dx.doi.org/10.1016/s0031-2023(97)00122-2},
    volume = {31},
    year = {1998}
}

@incollection{Veltkamp2001State,
    abstract = {{Large image databases are used in an extraordinary number of multimedia applications in fields such as entertainment, business, art, engineering, and science. Retrieving images by their content, as opposed to external features, has become an important operation. A fundamental ingredient for content-based image retrieval is the technique used for comparing images. There are two general methods for image comparison: intensity based (color and texture) and geometry based (shape). A recent user survey about cognition aspects of image retrieval shows that users are more interested in retrieval by shape than by color and texture [62]. However, retrieval by shape is still considered one of the most difficult aspects of content-based search. Indeed, systems such as IBM's Query By Image Content, QBIC [57], perhaps one of the most advanced image retrieval systems to date, is relatively successful in retrieving by color and texture, but performs poorly when searching on shape. A similar behavior is exhibited in the new Alta Vista photo finder [10].}},
    author = {Veltkamp, RemcoC and Hagedoorn, Michiel},
    booktitle = {Principles of Visual Information Retrieval},
    citeulike-article-id = {12751743},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-1-4471-3702-3_4},
    citeulike-linkout-1 = {http://link.springer.com/chapter/10.1007/978-1-4471-3702-3_4},
    doi = {10.1007/978-1-4471-3702-3_4},
    editor = {Lew, MichaelS},
    keywords = {computer-vision, shape-analysis},
    pages = {87--119},
    posted-at = {2013-11-04 16:33:34},
    priority = {1},
    publisher = {Springer London},
    series = {Advances in Pattern Recognition},
    title = {{State of the Art in Shape Matching}},
    url = {http://dx.doi.org/10.1007/978-1-4471-3702-3_4},
    year = {2001}
}

@article{Charpiat2005Approximations,
    abstract = {{This paper proposes a framework for dealing with several problems related
              to the analysis of shapes. Two related such problems are the definition of the
              relevant set of shapes and that of defining a metric on it. Following a recent research
              monograph by Delfour and Zol\'{e}sio [11], we consider the characteristic functions
              of the subsets of R2 and their distance functions. The L2 norm of the difference of
              characteristic functions, the L∞ and the W1,2 norms of the difference of distance
              functions define interesting topologies, in particular the well-known Hausdorff distance.
              Because of practical considerations arising from the fact that we deal with image shapes defined on finite grids of pixels, we restrict our attention to subsets of
              ℝ2 of positive reach in the sense of Federer [16], with smooth boundaries of bounded
              curvature. For this particular set of shapes we show that the three previous topologies
              are equivalent. The next problem we consider is that of warping a shape onto another
              by infinitesimal gradient descent, minimizing the corresponding distance. Because
              the distance function involves an inf, it is not differentiable with respect to the shape.
              We propose a family of smooth approximations of the distance function which are
              continuous with respect to the Hausdorff topology, and hence with respect to the
              other two topologies. We compute the corresponding G\^{a}teaux derivatives. They define deformation flows that can be used to warp a shape onto another by solving an
              initial value problem.We show several examples of this warping and prove properties
              of our approximations that relate to the existence of local minima. We then use this
              tool to produce computational definitions of the empirical mean and covariance of
              a set of shape examples. They yield an analog of the notion of principal modes of
              variation. We illustrate them on a variety of examples.}},
    author = {Charpiat, Guillaume and Faugeras, Olivier and Keriven, Renaud},
    booktitle = {Foundations of Computational Mathematics},
    citeulike-article-id = {12751739},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/s10208-003-0094-x},
    citeulike-linkout-1 = {http://link.springer.com/article/10.1007/s10208-003-0094-x},
    doi = {10.1007/s10208-003-0094-x},
    keywords = {computer-vision, shape-analysis},
    number = {1},
    pages = {1--58},
    posted-at = {2013-11-04 16:33:09},
    priority = {1},
    publisher = {Springer-Verlag},
    title = {{Approximations of Shape Metrics and Application to Shape Warping and Empirical Shape Statistics}},
    url = {http://dx.doi.org/10.1007/s10208-003-0094-x},
    volume = {5},
    year = {2005}
}

@article{Beucher2007Numerical,
    abstract = {{Binary morphological transformations based on the residues (ultimate erosion, skeleton by openings, etc.) and their associated functions which are based on the analysis of the residue evolution in every point of the image are extended to functions. In this approach, the associated function indicates the value of the residue index for which the evolution is the most important. The approach also has the advantage of supplying effective tools for shape analysis and of allowing the definition of new residual transforms together with their associated functions. Two of these numerical residues will be introduced, called, respectively, ultimate opening and quasi-distance and, through some applications, the interest and efficiency of these operators will be illustrated. Finally, this residual approach will be extended to more complex operators.}},
    address = {Newton, MA, USA},
    author = {Beucher, Serge},
    citeulike-article-id = {12751009},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1224926},
    citeulike-linkout-1 = {http://dx.doi.org/10.1016/j.imavis.2006.07.020},
    doi = {10.1016/j.imavis.2006.07.020},
    issn = {0262-8856},
    journal = {Image Vision Comput.},
    keywords = {computer-vision, morphology, segmentation},
    month = apr,
    number = {4},
    pages = {405--415},
    posted-at = {2013-11-04 13:09:38},
    priority = {1},
    publisher = {Butterworth-Heinemann},
    title = {{Numerical residues}},
    url = {http://dx.doi.org/10.1016/j.imavis.2006.07.020},
    volume = {25},
    year = {2007}
}

@article{Wermser1984Segmentation,
    author = {Wermser, D. and Haussmann, G. and Liedtke, C. E.},
    citeulike-article-id = {12745777},
    citeulike-linkout-0 = {http://www.sciencedirect.com/science/article/pii/0734189X84901002},
    citeulike-linkout-1 = {http://dx.doi.org/10.1016/0734-189x(84)90100-2},
    doi = {10.1016/0734-189x(84)90100-2},
    issn = {0734189X},
    journal = {Computer Vision, Graphics, and Image Processing},
    keywords = {computer-vision, rbc-segmentation, segmentation},
    month = feb,
    number = {2},
    pages = {151--168},
    posted-at = {2013-11-03 08:39:39},
    priority = {1},
    title = {{Segmentation of blood smears by hierarchical thresholding}},
    url = {http://www.sciencedirect.com/science/article/pii/0734189X84901002},
    volume = {25},
    year = {1984}
}

@inproceedings{Ritter2007Segmentation,
    abstract = {{We present an unsupervised blood cell segmentation algorithm for images taken from peripheral blood smear slides. Unlike prior algorithms the method is fast; fully automated; finds all objects---cells, cell groups and cell fragments---that do not intersect the image border; identifies the points interior to each object; finds an accurate one pixel wide border for each object; separates objects that just touch; and has been shown to work with a wide selection of red blood cell morphologies. The full algorithm was tested on two sets of images. In the first set of 47 images, 97.3\% of the 2962 image objects were correctly segmented. The second test set---51 images from a different source---contained 5417 objects for which the success rate was 99.0\%. The time taken for processing a 2272x1704 image ranged from 4.86 to 11.02 seconds on a Pentium 4, 2.4 GHz machine, depending on the number of objects in the image.}},
    address = {Darlinghurst, Australia, Australia},
    author = {Ritter, Nicola and Cooper, James},
    booktitle = {Proceedings of the thirtieth Australasian conference on Computer science - Volume 62},
    citeulike-article-id = {12745775},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=1273768},
    isbn = {1-920-68243-0},
    keywords = {computer-vision, rbc-segmentation, segmentation},
    location = {Ballarat, Victoria, Australia},
    pages = {161--169},
    posted-at = {2013-11-03 08:38:58},
    priority = {1},
    publisher = {Australian Computer Society, Inc.},
    series = {ACSC '07},
    title = {{Segmentation and border identification of cells in images of peripheral blood smear slides}},
    url = {http://portal.acm.org/citation.cfm?id=1273768},
    year = {2007}
}

@inproceedings{Bergen2008Segmentation,
    author = {Bergen, T. and Steckhan, D. and Wittenberg, T. and Zerfass, Thorsten},
    booktitle = {Engineering in Medicine and Biology Society, 2008. EMBS 2008. 30th Annual International Conference of the IEEE},
    citeulike-article-id = {12745771},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/iembs.2008.4649853},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4649853},
    doi = {10.1109/iembs.2008.4649853},
    institution = {Image Processing and Medical Engineering Department, Fraunhofer-Institute for Integrated Circuits IIS, 91058 Erlangen, Germany},
    isbn = {978-1-4244-1814-5},
    issn = {1557-170X},
    keywords = {computer-vision, rbc-segmentation, segmentation},
    month = aug,
    pages = {3075--3078},
    posted-at = {2013-11-03 08:38:13},
    priority = {1},
    publisher = {IEEE},
    title = {{Segmentation of leukocytes and erythrocytes in blood smear images}},
    url = {http://dx.doi.org/10.1109/iembs.2008.4649853},
    year = {2008}
}

@article{DiRuberto2002Analysis,
    author = {Di Ruberto, Cecilia and Dempster, Andrew and Khan, Shahid and Jarra, Bill},
    citeulike-article-id = {12739778},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/s0262-8856(01)00092-0},
    doi = {10.1016/s0262-8856(01)00092-0},
    issn = {02628856},
    journal = {Image and Vision Computing},
    keywords = {computer-vision, morphology, segmentation},
    month = feb,
    number = {2},
    pages = {133--146},
    posted-at = {2013-10-30 11:26:46},
    priority = {0},
    title = {{Analysis of infected blood cell images using morphological operators}},
    url = {http://dx.doi.org/10.1016/s0262-8856(01)00092-0},
    volume = {20},
    year = {2002}
}

@inproceedings{Chawla2002SMOTE,
    abstract = {{An approach to the construction of classifiers from imbalanced datasets is described. A dataset is imbalanced if the classification categories are not approximately equally represented. Often real-world data sets are predominately composed of ``normal'' examples with only a small percentage of ``abnormal'' or ``interesting'' examples. It is also the case that the cost of misclassifying an abnormal (interesting) example as a normal example is often much higher than the cost of the reverse error. Under-sampling of the majority (normal) class has been proposed as a good means of increasing the sensitivity of a classifier to the minority class. This paper shows that a combination of our method of over-sampling the minority (abnormal) class and under-sampling the majority (normal) class can achieve better classifier performance (in ROC space) than only under-sampling the majority class. This paper also shows that a combination of our method of over-sampling the minority class and under-sampling the majority class can achieve better classifier performance (in ROC space) than varying the loss ratios in Ripper or class priors in Naive Bayes. Our method of over-sampling the minority class involves creating synthetic minority class examples. Experiments are performed using C4.5, Ripper and a Naive Bayes classifier. The method is evaluated using the area under the Receiver Operating Characteristic curve (AUC) and the ROC convex hull strategy.}},
    author = {Chawla, Nitesh V. and Bowyer, Kevin W. and Hall, Lawrence O. and Kegelmeyer, W. Philip},
    booktitle = {Journal of Artificial Intelligence Research},
    citeulike-article-id = {3681497},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.18.5547},
    journal = {Journal of Artificial Intelligence Research},
    keywords = {classification, machine-learning},
    pages = {321--357},
    posted-at = {2013-10-29 17:15:45},
    priority = {1},
    title = {{SMOTE: Synthetic Minority Over-sampling Technique}},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.18.5547},
    volume = {16},
    year = {2002}
}

@inproceedings{Urbach2002ShapeOnly,
    abstract = {{Abstract Multiscale methods which provide a decomposition of an image based on scale have many uses in image analysis. One class of such methods from mathematical morphology is based on size distributions or granulometries. In this paper a different type of image decomposition based on shape but not scale is proposed. Called a shape granulometry or shape distribution, it is built from a family of morphological thinnings, rather than openings as in the case of size distributions. An implementation based on scale invariant attribute thinnings is presented, and an example of an application is shown. Keywords: Multi-scale analysis, connected filters, granulometries, attribute thinnings. 1.}},
    author = {Urbach, E. R. and Wilkinson, M. H. F.},
    booktitle = {Proceedings of the VIth International Symposium - ISMM 2002},
    citeulike-article-id = {12727274},
    citeulike-linkout-0 = {http://iwi.eldoc.ub.rug.nl/FILES/root/2002/ProcISMMUrbach/2002ProcISMMUrbach.pdf},
    citeulike-linkout-1 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.74.2991},
    editor = {Talbot, Hugues and Beare, Richard},
    isbn = {064306804X},
    keywords = {computer-vision, granulometry, morphology, segmentation},
    month = apr,
    posted-at = {2013-10-18 15:18:22},
    priority = {1},
    publisher = {CSIRO Publishing},
    title = {{Shape-Only Granulometries and Grey-Scale Shape Filters}},
    url = {http://iwi.eldoc.ub.rug.nl/FILES/root/2002/ProcISMMUrbach/2002ProcISMMUrbach.pdf},
    volume = {6},
    year = {2002}
}

@article{Urbach2007Connected,
    abstract = {{In this paper, we describe a multiscale and multishape morphological method for pattern-based analysis and classification of gray-scale images using connected operators. Compared with existing methods, which use structuring elements, our method has three advantages. First, in our method, the time needed for computing pattern spectra does not depend on the number of scales or shapes used, i.e., the computation time is independent of the dimensions of the pattern spectrum. Second, size and strict shape attributes can be computed, which we use for the construction of joint 2D shape-size pattern spectra. Third, our method is significantly less sensitive to noise and is rotation-invariant. Although rotation invariance can also be approximated by methods using structuring elements at different angles, this tends to be computationally intensive. The classification performance of these methods is discussed using four image sets: Brodatz, COIL-20, COIL-100, and diatoms. The new method obtains better or equal classification performance to the best competitor with a 5 to 9-fold speed gain}},
    address = {Los Alamitos, CA, USA},
    author = {Urbach, E. R. and Roerdink, J. B. T. M. and Wilkinson, M. H. F.},
    citeulike-article-id = {9340083},
    citeulike-linkout-0 = {http://doi.ieeecomputersociety.org/10.1109/TPAMI.2007.28},
    citeulike-linkout-1 = {http://dx.doi.org/10.1109/tpami.2007.28},
    citeulike-linkout-2 = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4042702},
    doi = {10.1109/tpami.2007.28},
    institution = {Inst. for Math. \& Comput. Sci., Groningen Univ.},
    issn = {0162-8828},
    journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
    keywords = {granulometry, morphology, segmentation},
    month = feb,
    number = {2},
    pages = {272--285},
    posted-at = {2013-10-18 12:23:41},
    priority = {0},
    publisher = {IEEE},
    title = {{Connected Shape-Size Pattern Spectra for Rotation and Scale-Invariant Classification of Gray-Scale Images}},
    url = {http://dx.doi.org/10.1109/tpami.2007.28},
    volume = {29},
    year = {2007}
}

@article{Hernandez2011Shape,
    abstract = {{The ultimate opening (UO) is a powerful segmentation operator recently introduced by Beucher [1]. It automatically selects the most contrasted regions of an image. However, in the presence of nested structures (e.g. text in a signboard or windows in a contrasted facade), interesting structures may be masked by the containing region. In this paper we focus on ultimate attribute openings and we propose a method that improves the results by favoring regions with a predefined shape via a similarity function. An efficient implementation using a max-tree representation of the image is proposed. The method is validated in the framework of three applications: facade analysis, scene-text detection and cell segmentation. Experimental results show that the proposed method yields better segmentation results than UO. Shape ultimate attribute opening provides good segmentation results. The method handles difficult situations: low contrast, multi-scale, perspective effects and different fonts. Text segmentation examples are shown. \^{a}º Ultimate Attribute Opening (UAO) is a powerful multi-scale segmentation operator. \^{a}º Our method combines UAO with shape information, favoring regions of a predefined shape. \^{a}º Much better results are obtained, at the expense of a marginal increase in the computation time. \^{a}º The approach has been validated in three applications (facade, text and cell segmentation).}},
    author = {Hern\'{a}ndez, Jorge and Marcotegui, Beatriz},
    citeulike-article-id = {9418869},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.imavis.2011.05.001},
    doi = {10.1016/j.imavis.2011.05.001},
    issn = {02628856},
    journal = {Image and Vision Computing},
    keywords = {computer-vision, morphology, segmentation},
    month = jul,
    number = {8},
    pages = {533--545},
    posted-at = {2013-10-07 15:32:07},
    priority = {0},
    title = {{Shape ultimate attribute opening}},
    url = {http://dx.doi.org/10.1016/j.imavis.2011.05.001},
    volume = {29},
    year = {2011}
}

@incollection{Hernandez2009Ultimate,
    abstract = {{In this paper, a method for morphological segmentation using shape information is presented. This method is based on a morphological operator named ultimate attribute opening (UAO). Our approach considers shape information to favor the detection of specific shapes. The method is validated in the framework of two applications: fa\c{c}ade analysis and scene-text detection. The experimental results show that our approach is more robust than the standard UAO.}},
    author = {Hern\'{a}ndez, Jorge and Marcotegui, Beatriz},
    booktitle = {Mathematical Morphology and Its Application to Signal and Image Processing},
    citeulike-article-id = {12700571},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-642-03613-2_19},
    citeulike-linkout-1 = {http://link.springer.com/chapter/10.1007/978-3-642-03613-2_19},
    doi = {10.1007/978-3-642-03613-2_19},
    editor = {Wilkinson, MichaelH and Roerdink, JosB},
    keywords = {algorithms, computer-vision, morphology, segmentation},
    pages = {205--214},
    posted-at = {2013-10-07 15:11:12},
    priority = {0},
    publisher = {Springer Berlin Heidelberg},
    series = {Lecture Notes in Computer Science},
    title = {{Ultimate Attribute Opening Segmentation with Shape Information}},
    url = {http://dx.doi.org/10.1007/978-3-642-03613-2_19},
    volume = {5720},
    year = {2009}
}

@inproceedings{Wilkinson2000Fast,
    abstract = {{Morphological attribute openings and closings and related operators are generalizations of the area opening and closing, and allow filtering of images based on a wide variety of shape or size based criteria. A fast union-find algorithm for the computation of these operators is presented in this paper. The new algorithm has a worst case time complexity of O(N log N) where N is the image size, as opposed to O(N log N) for the existing algorithm. Memory requirements are O(N) for both algorithms.}},
    author = {Wilkinson, Michael H. F. and Roerdink, Jos B. T. M.},
    booktitle = {In Proceedings of the ISMM2000},
    citeulike-article-id = {12681694},
    citeulike-linkout-0 = {http://www.cs.rug.nl/~michael/ismm2000.pdf},
    citeulike-linkout-1 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.16.2632},
    keywords = {algorithms, granulometry, morphology, performance},
    pages = {311--320},
    posted-at = {2013-10-02 13:19:51},
    priority = {0},
    title = {{Fast Morphological Attribute Operations Using Tarjan's Union-Find Algorithm}},
    url = {http://www.cs.rug.nl/~michael/ismm2000.pdf},
    year = {2000}
}

@article{Kirbas2004Review,
    abstract = {{Vessel segmentation algorithms are the critical components of circulatory blood vessel analysis systems. We present a survey of vessel extraction techniques and algorithms. We put the various vessel extraction approaches and techniques in perspective by means of a classi-fication of the existing research. While we have mainly targeted the extraction of blood ves-sels, neurosvascular structure in particular, we have also reviewed some of the segmentation methods for the tubular objects that show similar characteristics to vessels. We have divided vessel segmentation algorithms and techniques into six main categories: (1) pattern recog-nition techniques, (2) model-based approaches, (3) tracking-based approaches, (4) artificial intelligence-based approaches, (5) neural network-based approaches, and (6) miscellaneous tube-like object detection approaches. Some of these categories are further divided into sub-categories. We have also created tables to compare the papers in each category against such criteria as dimensionality, input type, pre-processing, user interaction, and result type. Keywords: Vessel extraction, medical imaging, X-ray angiography (XRA), magnetic resonance angiography (MRA) 1}},
    author = {Kirbas, Cemil and Quek, Francis K. H.},
    citeulike-article-id = {3376872},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.11.9182},
    journal = {ACM Computing Surveys},
    keywords = {blood\_vessels, classification, computer-vision, review, segmentation},
    pages = {81--121},
    posted-at = {2013-09-26 22:36:31},
    priority = {3},
    title = {{A review of vessel extraction techniques and algorithms}},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.11.9182},
    volume = {36},
    year = {2004}
}

@book{Jensen2001Ripples,
    author = {Jensen, A. and Cour-Harbo, Anders L.},
    citeulike-article-id = {12656849},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20&amp;path=ASIN/B000U5M49A},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21&amp;path=ASIN/B000U5M49A},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21&amp;path=ASIN/B000U5M49A},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/B000U5M49A},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/B000U5M49A/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20&path=ASIN/B000U5M49A},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/9783642567025},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN9783642567025},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=9783642567025&index=books&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/9783642567025},
    day = {06},
    edition = {2001},
    howpublished = {Kindle Edition},
    keywords = {algorithms, computer-vision},
    month = jun,
    posted-at = {2013-09-26 21:57:59},
    priority = {1},
    publisher = {Springer},
    title = {{Ripples in Mathematics: The Discrete Wavelet Transform}},
    url = {http://www.worldcat.org/isbn/9783642567025},
    year = {2001}
}

@techreport{Rivest1992MD5,
    abstract = {{This document describes the MD5 message-digest algorithm. The
algorithm takes as input a message of arbitrary length and produces as
output a 128-bit "fingerprint" or "message digest" of the input. This
memo provides information for the Internet community. It does not
specify an Internet standard.}},
    address = {Fremont, CA, USA},
    author = {Rivest, R.},
    citeulike-article-id = {10293331},
    citeulike-linkout-0 = {http://www.rfc-editor.org/rfc/rfc1321.txt},
    citeulike-linkout-1 = {http://tools.ietf.org/html/rfc1321},
    citeulike-linkout-2 = {http://tools.ietf.org/rfc/rfc1321.txt},
    howpublished = {Internet Requests for Comment},
    institution = {RFC Editor},
    issn = {2070-1721},
    keywords = {algorithms, hashing},
    month = apr,
    number = {1321},
    posted-at = {2013-09-25 15:35:14},
    priority = {1},
    publisher = {RFC Editor},
    title = {{The MD5 Message-Digest Algorithm}},
    url = {http://www.rfc-editor.org/rfc/rfc1321.txt},
    year = {1992}
}

@article{Mavandadi2012Distributed,
    abstract = {{In this work we investigate whether the innate visual recognition and learning capabilities of untrained humans can be used in conducting reliable microscopic analysis of biomedical samples toward diagnosis. For this purpose, we designed entertaining digital games that are interfaced with artificial learning and processing back-ends to demonstrate that in the case of binary medical diagnostics decisions (e.g., infected vs. uninfected), with the use of crowd-sourced games it is possible to approach the accuracy of medical experts in making such diagnoses. Specifically, using non-expert gamers we report diagnosis of malaria infected red blood cells with an accuracy that is within 1.25\% of the diagnostics decisions made by a trained medical professional.}},
    author = {Mavandadi, Sam and Dimitrov, Stoyan and Feng, Steve and Yu, Frank and Sikora, Uzair and Yaglidere, Oguzhan and Padmanabhan, Swati and Nielsen, Karin and Ozcan, Aydogan},
    citeulike-article-id = {10751725},
    citeulike-linkout-0 = {http://dx.doi.org/10.1371/journal.pone.0037245},
    day = {11},
    doi = {10.1371/journal.pone.0037245},
    journal = {PLoS ONE},
    keywords = {malaria},
    month = may,
    number = {5},
    pages = {e37245+},
    posted-at = {2013-09-25 15:14:38},
    priority = {3},
    publisher = {Public Library of Science},
    title = {{Distributed Medical Image Analysis and Diagnosis through Crowd-Sourced Games: A Malaria Case Study}},
    url = {http://dx.doi.org/10.1371/journal.pone.0037245},
    volume = {7},
    year = {2012}
}

@article{Coskun2014Computational,
    abstract = {{ Consumer electronics creates new opportunities for imaging and sensing technologies. We review emerging computational imaging and sensing platforms for global health. Computational imagers and sensors are in general field-portable and cost-effective. In this review, we summarize some of the recent work in emerging computational imaging, sensing and diagnostics techniques, along with some of the complementary non-computational modalities that can potentially transform the delivery of health care globally. As computational resources are becoming more and more powerful, while also getting cheaper and more widely available, traditional imaging, sensing and diagnostic tools will continue to experience a revolution through simplification of their designs, making them compact, light-weight, cost-effective, and yet quite powerful in terms of their performance when compared to their bench-top counterparts. }},
    author = {Coskun, Ahmet F. and Ozcan, Aydogan},
    citeulike-article-id = {12630056},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.copbio.2013.08.008},
    doi = {10.1016/j.copbio.2013.08.008},
    issn = {09581669},
    journal = {Current Opinion in Biotechnology},
    keywords = {review, tele-medicine},
    month = feb,
    pages = {8--16},
    posted-at = {2013-09-17 12:27:02},
    priority = {1},
    title = {{Computational imaging, sensing and diagnostics for global health applications}},
    url = {http://dx.doi.org/10.1016/j.copbio.2013.08.008},
    volume = {25},
    year = {2014}
}

@article{Breen1996Attribute,
    abstract = {{In this paper we establish an attribute-based approach to openings and closings and provide an efficient algorithm for their implementation on gray-scale images. Attribute openings are similar to openings by reconstruction since they are connected component transformations. However, attribute openings are more general because they can describe generalized shape features and openings that have no shape-bias. This work is then extended to gray-scale granuolmetries and to include gray-scale thinnings, which are nonincreasing filters. The use of nonincreasing gray-scale thinnings is seen as an important generalization because it allows the use of nonincreasing shape descriptors such as compactness and eccentricity to be applied to filter gray-scale images. Applications are then given to illustrate the performance of the filters proposed.}},
    author = {Breen, Edmond J. and Jones, Ronald},
    citeulike-article-id = {12628362},
    citeulike-linkout-0 = {http://www.sciencedirect.com/science/article/pii/S1077314296900661#},
    citeulike-linkout-1 = {http://dx.doi.org/10.1006/cviu.1996.0066},
    doi = {10.1006/cviu.1996.0066},
    issn = {10773142},
    journal = {Computer Vision and Image Understanding},
    keywords = {granulometry, morphology},
    month = nov,
    number = {3},
    pages = {377--389},
    posted-at = {2013-09-16 15:17:09},
    priority = {0},
    title = {{Attribute Openings, Thinnings, and Granulometries}},
    url = {http://www.sciencedirect.com/science/article/pii/S1077314296900661#},
    volume = {64},
    year = {1996}
}

@incollection{DiRuberto2001Morphological,
    abstract = {{This work describes a system for detecting and classifying malaria parasites in images of Giemsa stained blood slides in order to evaluate the parasitaemia of the blood. The first aim of our system is to detect the parasites by means of an automatic thresholding based on a morphological approach. Then we propose a morphological method to cell image segmentation based on grey scale granulometries and openings with disk-shaped elements, flat and hemispherical, that is more accurate than the classical watershed-based algorithm. The last step of the system is classifying the parasites by morphological skeleton.}},
    author = {Di Ruberto, Cecilia and Dempster, Andrew and Khan, Shahid and Jarra, Bill},
    booktitle = {Visual Form 2001},
    citeulike-article-id = {12627814},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/3-540-45129-3_68},
    citeulike-linkout-1 = {http://link.springer.com/chapter/10.1007/3-540-45129-3_68},
    doi = {10.1007/3-540-45129-3_68},
    editor = {Arcelli, Carlo and Cordella, LuigiP and Baja, GabriellaSanniti},
    keywords = {granulometry, malaria, morphology, segmentation},
    pages = {739--748},
    posted-at = {2013-09-16 09:12:08},
    priority = {1},
    publisher = {Springer Berlin Heidelberg},
    series = {Lecture Notes in Computer Science},
    title = {{Morphological Image Processing for Evaluating Malaria Disease}},
    url = {http://dx.doi.org/10.1007/3-540-45129-3_68},
    volume = {2059},
    year = {2001}
}

@article{Stoer1997Simple,
    abstract = {{We present an algorithm for finding the minimum cut of an undirected edge-weighted graph. It is simple in every respect. It has a short and compact description, is easy to implement, and has a surprisingly simple proof of correctness. Its runtime matches that of the fastest algorithm known. The runtime analysis is straightforward. In contrast to nearly all approaches so far, the algorithm uses no flow techniques. Roughly speaking, the algorithm consists of about | V | nearly identical phases each of which is a  maximum adjacency search .}},
    address = {New York, NY, USA},
    author = {Stoer, Mechthild and Wagner, Frank},
    citeulike-article-id = {941105},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=263872},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/263867.263872},
    doi = {10.1145/263867.263872},
    issn = {0004-5411},
    journal = {J. ACM},
    keywords = {graph-cuts, segmentation},
    month = jul,
    number = {4},
    pages = {585--591},
    posted-at = {2013-09-15 17:38:39},
    priority = {1},
    publisher = {ACM},
    title = {{A simple min-cut algorithm}},
    url = {http://dx.doi.org/10.1145/263867.263872},
    volume = {44},
    year = {1997}
}

@inproceedings{Anggraini2011Automated,
    author = {Anggraini, D. and Nugroho, A. S. and Pratama, C. and Rozi, I. E. and Iskandar, A. A. and Hartono, R. N.},
    booktitle = {Electrical Engineering and Informatics (ICEEI), 2011 International Conference on},
    citeulike-article-id = {12616060},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/iceei.2011.6021762},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6021762},
    doi = {10.1109/iceei.2011.6021762},
    institution = {Swiss German Univesity, Tangerang, Indonesia},
    isbn = {978-1-4577-0753-7},
    issn = {2155-6822},
    keywords = {classification, computer-vision, malaria},
    month = jul,
    pages = {1--6},
    posted-at = {2013-09-11 22:04:06},
    priority = {1},
    publisher = {IEEE},
    title = {{Automated status identification of microscopic images obtained from malaria thin blood smears}},
    url = {http://dx.doi.org/10.1109/iceei.2011.6021762},
    year = {2011}
}

@inproceedings{Anderson1994Waitfree,
    abstract = {{We are interested in designing efficient data structures for a shared memory multiprocessor. In this paper we focus on the Union-Find data structure. We consider a fully asynchronous model of computation where arbitrary delays are possible. Thus we require our solutions to the data structure problem have the wait-free property, meaning that each thread continues to make progress on its operations, independent of the speeds of the other threads. In this model efficiency is best measured in terms of the total number of instructions used to perform a sequence of data structure operations, the work performed by the processors. We give a wait-free implementation of an efficient algorithm for Union-Find. In addition we show that the worst case performance of the algorithm can be improved by simulating a synchronized algorithm, or by simulating a larger machine if the data structure requests support sufficient parallelism. Our solutions apply to a much more general adversary model than has be...}},
    author = {Anderson, Richard J. and Woll, Heather},
    booktitle = {In Proc. 23rd ACM Symposium on Theory of Computing},
    citeulike-article-id = {8423759},
    citeulike-linkout-0 = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.56.8354},
    keywords = {algorithms, parallel-programming},
    pages = {370--380},
    posted-at = {2013-09-06 20:56:10},
    priority = {0},
    title = {{Wait-free Parallel Algorithms for the Union-Find Problem}},
    url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.56.8354},
    year = {1994}
}

@article{Meijster2002Comparison,
    author = {Meijster, A. and Wilkinson, M. H. F.},
    citeulike-article-id = {12602537},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/34.993556},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=993556},
    doi = {10.1109/34.993556},
    institution = {Centre for High Performance Comput. \& Visualization, Groningen Univ., Netherlands},
    issn = {0162-8828},
    journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
    keywords = {algorithms, granulometry, morphology, performance},
    month = apr,
    number = {4},
    pages = {484--494},
    posted-at = {2013-08-30 19:52:50},
    priority = {0},
    publisher = {IEEE},
    title = {{A comparison of algorithms for connected set openings and closings}},
    url = {http://dx.doi.org/10.1109/34.993556},
    volume = {24},
    year = {2002}
}

@inproceedings{Tek2006Colour,
    author = {Tek, F. B. and Dempster, A. G. and Kale, I.},
    booktitle = {Signal Processing and Communications Applications, 2006 IEEE 14th},
    citeulike-article-id = {12601322},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/siu.2006.1659768},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1659768},
    doi = {10.1109/siu.2006.1659768},
    institution = {Appl. DSP \& VLSI Res. Group, Univ. of Westminster, London},
    isbn = {1-4244-0238-7},
    keywords = {image-enhancement, malaria},
    month = apr,
    pages = {1--4},
    posted-at = {2013-08-29 19:07:18},
    priority = {1},
    publisher = {IEEE},
    title = {{A Colour Normalization Method for Giemsa-Stained Blood Cell Images}},
    url = {http://dx.doi.org/10.1109/siu.2006.1659768},
    year = {2006}
}

@inproceedings{Meijster2001Fast,
    author = {Meijster, A. and Wilkinson, M. H. F.},
    booktitle = {Image Processing, 2001. Proceedings. 2001 International Conference on},
    citeulike-article-id = {12601318},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/icip.2001.958207},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=958207},
    doi = {10.1109/icip.2001.958207},
    institution = {Centre for High Performance Comput., Groningen Univ., Netherlands},
    isbn = {0-7803-6725-1},
    keywords = {algorithms, granulometry, morphology},
    pages = {668--671 vol.3},
    posted-at = {2013-08-29 18:57:34},
    priority = {0},
    publisher = {IEEE},
    title = {{Fast computation of morphological area pattern spectra}},
    url = {http://dx.doi.org/10.1109/icip.2001.958207},
    volume = {3},
    year = {2001}
}

@article{Vincent1993Morphological,
    abstract = {{Two different formal definitions of gray-scale reconstruction are presented. The use of gray-scale reconstruction in various image processing applications discussed to illustrate the usefulness of this transformation for image filtering and segmentation tasks. The standard parallel and sequential approaches to reconstruction are reviewed. It is shown that their common drawback is their inefficiency on conventional computers. To improve this situation, an algorithm that is based on the notion of regional maxima and makes use of breadth-first image scannings implemented using a queue of pixels is introduced. Its combination with the sequential technique results in a hybrid gray-scale reconstruction algorithm which is an order of magnitude faster than any previously known algorithm}},
    author = {Vincent, Luc},
    citeulike-article-id = {4168569},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/83.217222},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=217222},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/18296207},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=18296207},
    day = {06},
    doi = {10.1109/83.217222},
    institution = {Div. of Appl. Sci., Harvard Univ., Cambridge, MA, USA},
    issn = {1057-7149},
    journal = {Image Processing, IEEE Transactions on},
    keywords = {algorithms, morphology, segmentation},
    month = apr,
    number = {2},
    pages = {176--201},
    pmid = {18296207},
    posted-at = {2013-08-21 10:24:28},
    priority = {0},
    publisher = {IEEE},
    title = {{Morphological grayscale reconstruction in image analysis: applications and efficient algorithms}},
    url = {http://dx.doi.org/10.1109/83.217222},
    volume = {2},
    year = {1993}
}

@article{Vincent1991Watersheds,
    abstract = {{A fast and flexible algorithm for computing watersheds in digital gray-scale images is introduced. A review of watersheds and related motion is first presented, and the major methods to determine watersheds are discussed. The algorithm is based on an immersion process analogy, in which the flooding of the water in the picture is efficiently simulated using of queue of pixel. It is described in detail provided in a pseudo C language. The accuracy of this algorithm is proven to be superior to that of the existing implementations, and it is shown that its adaptation to any kind of digital grid and its generalization to}},
    address = {Los Alamitos, CA, USA},
    author = {Vincent, L. and Soille, P.},
    citeulike-article-id = {557456},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=116707},
    citeulike-linkout-1 = {http://doi.ieeecomputersociety.org/10.1109/34.87344},
    citeulike-linkout-2 = {http://dx.doi.org/10.1109/34.87344},
    citeulike-linkout-3 = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=87344},
    doi = {10.1109/34.87344},
    institution = {Center for Math. Morphology, Ecole des Mines de Paris, Fontainebleau, France},
    issn = {0162-8828},
    journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
    keywords = {algorithms, segmentation},
    month = jun,
    number = {6},
    pages = {583--598},
    posted-at = {2013-08-17 17:52:33},
    priority = {1},
    publisher = {IEEE},
    title = {{Watersheds in digital spaces: an efficient algorithm based on immersion simulations}},
    url = {http://dx.doi.org/10.1109/34.87344},
    volume = {13},
    year = {1991}
}

@article{Otsu1979Threshold,
    author = {Otsu, Nobuyuki},
    booktitle = {Systems, Man and Cybernetics, IEEE Transactions on},
    citeulike-article-id = {2917492},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/tsmc.1979.4310076},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4310076},
    doi = {10.1109/tsmc.1979.4310076},
    issn = {0018-9472},
    journal = {IEEE Transactions on Systems, Man, and Cybernetics},
    keywords = {segmentation},
    month = jan,
    number = {1},
    pages = {62--66},
    posted-at = {2013-08-17 17:45:42},
    priority = {1},
    publisher = {IEEE},
    title = {{A Threshold Selection Method from Gray-Level Histograms}},
    url = {http://dx.doi.org/10.1109/tsmc.1979.4310076},
    volume = {9},
    year = {1979}
}

@inproceedings{Makkapati2009Segmentation,
    abstract = {{Detection of malaria parasites in stained blood smears is critical for treatment of the disease. Automation of this process will help in reducing the time taken for diagnosis and the chance for human errors. However, the variability and artifacts in microscope images of blood samples pose significant challenges for accurate detection. A scheme based on HSV color space that segments Red Blood Cells and parasites by detecting dominant hue range and by calculating optimal saturation thresholds is presented in this paper. Methods that are less computation-intensive than existing approaches are proposed to remove artifacts. The scheme is evaluated using images taken from Leishman-stained blood smears. Sensitivity and specificity of the scheme are found to be 83\% and 98\% respectively.}},
    author = {Makkapati, V. V. and Rao, R. M.},
    booktitle = {Acoustics, Speech and Signal Processing, 2009. ICASSP 2009. IEEE International Conference on},
    citeulike-article-id = {12569066},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/icassp.2009.4959845},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4959845},
    doi = {10.1109/icassp.2009.4959845},
    institution = {Philips Res. Asia - Bangalore, Philips Electron. India Ltd., Bangalore},
    isbn = {978-1-4244-2353-8},
    issn = {1520-6149},
    keywords = {malaria, segmentation},
    month = apr,
    pages = {1361--1364},
    posted-at = {2013-08-15 17:19:51},
    priority = {0},
    publisher = {IEEE},
    title = {{Segmentation of malaria parasites in peripheral blood smear images}},
    url = {http://dx.doi.org/10.1109/icassp.2009.4959845},
    year = {2009}
}

@article{Tao2007Color,
    abstract = {{In this correspondence, we develop a novel approach that provides effective and robust segmentation of color images. By incorporating the advantages of the mean shift (MS) segmentation and the normalized cut (Ncut) partitioning methods, the proposed method requires low computational complexity and is therefore very feasible for real-time image segmentation processing. It preprocesses an image by using the MS algorithm to form segmented regions that preserve the desirable discontinuity characteristics of the image. The segmented regions are then represented by using the graph structures, and the Ncut method is applied to perform globally optimized clustering. Because the number of the segmented regions is much smaller than that of the image pixels, the proposed method allows a low-dimensional image clustering with significant reduction of the complexity compared to conventional graph-partitioning methods that are directly applied to the image pixels. In addition, the image clustering using the segmented regions, instead of the image pixels, also reduces the sensitivity to noise and results in enhanced image segmentation performance. Furthermore, to avoid some inappropriate partitioning when considering every region as only one graph node, we develop an improved segmentation strategy using multiple child nodes for each region. The superiority of the proposed method is examined and demonstrated through a large number of experiments using color natural scene images.}},
    author = {Tao, Wenbing and Jin, Hai and Zhang, Yimin},
    citeulike-article-id = {11077749},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/tsmcb.2007.902249},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4305291},
    doi = {10.1109/tsmcb.2007.902249},
    institution = {Huazhong Univ. of Sci. \& Technol., Wuhan},
    issn = {1083-4419},
    journal = {Systems, Man, and Cybernetics, Part B: Cybernetics, IEEE Transactions on},
    keywords = {graph-cuts, segmentation},
    month = oct,
    number = {5},
    pages = {1382--1389},
    posted-at = {2013-08-15 17:13:44},
    priority = {0},
    publisher = {IEEE},
    title = {{Color Image Segmentation Based on Mean Shift and Normalized Cuts}},
    url = {http://dx.doi.org/10.1109/tsmcb.2007.902249},
    volume = {37},
    year = {2007}
}

@article{Grau2004Improved,
    abstract = {{The watershed transform has interesting properties that make it useful for many different image segmentation applications: it is simple and intuitive, can be parallelized, and always produces a complete division of the image. However, when applied to medical image analysis, it has important drawbacks (oversegmentation, sensitivity to noise, poor detection of thin or low signal to noise ratio structures). We present an improvement to the watershed transform that enables the introduction of prior information in its calculation. We propose to introduce this information via the use of a previous probability calculation. Furthermore, we introduce a method to combine the watershed transform and atlas registration, through the use of markers. We have applied our new algorithm to two challenging applications: knee cartilage and gray matter/white matter segmentation in MR images. Numerical validation of the results is provided, demonstrating the strength of the algorithm for medical image segmentation.}},
    author = {Grau, V. and Mewes, A. U. J. and Alcaniz, M. and Kikinis, R. and Warfield, S. K.},
    booktitle = {Medical Imaging, IEEE Transactions on},
    citeulike-article-id = {3377075},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/tmi.2004.824224},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1281998},
    day = {05},
    doi = {10.1109/tmi.2004.824224},
    institution = {Brigham \& Women''s Hosp. \& Harvard Med. Sch., Boston, MA, USA},
    issn = {0278-0062},
    journal = {IEEE Transactions on Medical Imaging},
    keywords = {segmentation, watershed},
    month = apr,
    number = {4},
    pages = {447--458},
    posted-at = {2013-08-15 08:48:51},
    priority = {1},
    publisher = {IEEE},
    title = {{Improved watershed transform for medical image segmentation using prior information}},
    url = {http://dx.doi.org/10.1109/tmi.2004.824224},
    volume = {23},
    year = {2004}
}

@inproceedings{WaltherFranks2012Animation,
    author = {Walther-Franks, Benjamin and Biermann, Florian and Steenbergen, Nikolaas and Malaka, Rainer},
    booktitle = {International Conference on Entertainment Computing (ICEC)},
    citeulike-article-id = {10899055},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-642-33542-6_55},
    doi = {10.1007/978-3-642-33542-6_55},
    keywords = {animation, hci, performance},
    posted-at = {2013-08-13 17:48:26},
    priority = {0},
    publisher = {Springer},
    title = {{The Animation Loop Station: Near Real-time Animation Production}},
    url = {http://dx.doi.org/10.1007/978-3-642-33542-6_55},
    year = {2012}
}

@inproceedings{Barenbrock2010Perform,
    abstract = {{Interaktive digitale Medien sind in Musik- Tanz- und Theaterauffüh- rungen eher die Ausnahme. Doch können erst Systeme, welche in Echt- zeit gesteuert werden können, die Improvisations- und Interaktions- freiheit der Akteure vollends unterstützen. Wir präsentieren Elemente, welche wir für eine Musik- und Tanz- sowie eine Theaterproduktion entwickelt haben, und schildern Motivation, Gestaltung, und tech- nische Umsetzung.}},
    author = {Barenbrock, Anna and Biermann, Florian and Bogdanowa, Nadja and Celikel, Timur and Grosche, Daniel and Heckers, Pascal and Hollstein, Hendrik and H\"{o}pken, Rebecca and Krummel, Julia and Lange, Kolja and Ozong, Kavaye O. and da Rocha, Michael S. and Sliwon, Jana and Steenbergen, Nikolaas and Winkler, Anna P. and Walther-Franks, Benjamin and Friederichs-B\"{u}ttner, Gesa and Malaka, Rainer},
    booktitle = {Kultur und Informatik: Interaktive Systeme},
    citeulike-article-id = {7432866},
    citeulike-linkout-0 = {https://shop.strato.de/epages/Store8.sf/?ObjectPath=/Shops/61236266/Products/978-3-940317-72-8},
    editor = {Sieck, J\"{u}rgen},
    isbn = {978-3-940317-72-8},
    keywords = {hci, performance},
    location = {Berlin},
    month = may,
    pages = {243--251},
    posted-at = {2013-08-13 17:46:57},
    priority = {0},
    publisher = {Verlag Werner H\"{u}lsbusch},
    title = {{Perform! - Interaktive digitale Medien f\"{u}r Musik-, Tanz- und Theaterauff\"{u}hrungen}},
    url = {https://shop.strato.de/epages/Store8.sf/?ObjectPath=/Shops/61236266/Products/978-3-940317-72-8},
    year = {2010}
}

@book{Shneiderman2010Designing,
    author = {Shneiderman, Ben},
    citeulike-article-id = {4545192},
    citeulike-linkout-0 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21&amp;path=ASIN/0321601483},
    citeulike-linkout-1 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21&amp;path=ASIN/0321601483},
    citeulike-linkout-2 = {http://www.amazon.jp/exec/obidos/ASIN/0321601483},
    citeulike-linkout-3 = {http://www.amazon.co.uk/exec/obidos/ASIN/0321601483/citeulike00-21},
    citeulike-linkout-4 = {http://www.worldcat.org/isbn/0321601483},
    citeulike-linkout-5 = {http://books.google.com/books?vid=ISBN0321601483},
    citeulike-linkout-6 = {http://www.amazon.com/gp/search?keywords=0321601483&index=books&linkCode=qs},
    citeulike-linkout-7 = {http://www.librarything.com/isbn/0321601483},
    citeulike-linkout-8 = {http://www.worldcat.org/oclc/244066651},
    day = {16},
    edition = {5},
    howpublished = {Paperback},
    isbn = {9780321601483},
    keywords = {hci, review},
    month = apr,
    posted-at = {2013-08-13 17:39:41},
    priority = {1},
    publisher = {Addison-Wesley},
    title = {{Designing the user interface : strategies for effective human-computer interaction}},
    url = {http://www.worldcat.org/isbn/0321601483},
    year = {2010}
}

@book{Kleinberg2006Algorithm,
    abstract = {{Algorithm Design introduces algorithms by looking at the real-world problems that motivate them. The book teaches a range of design and analysis techniques for problems that arise in computing applications. The text encourages an understanding of the algorithm design process and an appreciation of the role of algorithms in the broader field of computer science.}},
    author = {Kleinberg, Jon and Tardos, \'{E}va},
    citeulike-article-id = {578377},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20&amp;path=ASIN/0321295358},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21&amp;path=ASIN/0321295358},
    citeulike-linkout-10 = {http://www.worldcat.org/oclc/845840753},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21&amp;path=ASIN/0321295358},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0321295358},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0321295358/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20&path=ASIN/0321295358},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0321295358},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0321295358},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0321295358&index=books&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0321295358},
    day = {26},
    edition = {United States ed},
    howpublished = {Hardcover},
    isbn = {0321295358},
    keywords = {algorithms, review},
    month = mar,
    posted-at = {2013-08-13 17:36:14},
    priority = {0},
    publisher = {Pearson, Addison-Wesley},
    title = {{Algorithm Design}},
    url = {http://www.worldcat.org/isbn/0321295358},
    year = {2006}
}

@inproceedings{Michael1996Simple,
    abstract = {{An abstract is not available.}},
    address = {New York, NY, USA},
    author = {Michael, Maged M. and Scott, Michael L.},
    booktitle = {Proceedings of the fifteenth annual ACM symposium on Principles of distributed computing},
    citeulike-article-id = {4448},
    citeulike-linkout-0 = {http://portal.acm.org/citation.cfm?id=248106},
    citeulike-linkout-1 = {http://dx.doi.org/10.1145/248052.248106},
    doi = {10.1145/248052.248106},
    isbn = {0-89791-800-2},
    keywords = {parallel-programming},
    location = {Philadelphia, Pennsylvania, USA},
    pages = {267--275},
    posted-at = {2013-08-13 17:35:34},
    priority = {0},
    publisher = {ACM},
    series = {PODC '96},
    title = {{Simple, fast, and practical non-blocking and blocking concurrent queue algorithms}},
    url = {http://dx.doi.org/10.1145/248052.248106},
    year = {1996}
}

@phdthesis{Tek2007Computerised,
    author = {Tek, F. Boray},
    citeulike-article-id = {12556228},
    citeulike-linkout-0 = {http://vision.cs.man.ac.uk/theses/theses/tek2007a.pdf},
    keywords = {computer-vision, malaria},
    month = sep,
    posted-at = {2013-08-13 17:34:38},
    priority = {0},
    school = {University of Westminster},
    title = {{Computerised Diagnosis of Malaria}},
    url = {http://vision.cs.man.ac.uk/theses/theses/tek2007a.pdf},
    year = {2007}
}

@article{Smith2011CellPhoneBased,
    abstract = {{In this paper we report the development of two attachments to a commercial cell phone that transform the phone's integrated lens and image sensor into a 350× microscope and visible-light spectrometer. The microscope is capable of transmission and polarized microscopy modes and is shown to have 1.5 micron resolution and a usable field-of-view of 150×150 with no image processing, and approximately 350×350 when post-processing is applied. The spectrometer has a 300 nm bandwidth with a limiting spectral resolution of close to 5 nm. We show applications of the devices to medically relevant problems. In the case of the microscope, we image both stained and unstained blood-smears showing the ability to acquire images of similar quality to commercial microscope platforms, thus allowing diagnosis of clinical pathologies. With the spectrometer we demonstrate acquisition of a white-light transmission spectrum through diffuse tissue as well as the acquisition of a fluorescence spectrum. We also envision the devices to have immediate relevance in the educational field.}},
    author = {Smith, Zachary J. and Chu, Kaiqin and Espenson, Alyssa R. and Rahimzadeh, Mehdi and Gryshuk, Amy and Molinaro, Marco and Dwyre, Denis M. and Lane, Stephen and Matthews, Dennis and Wachsmann-Hogiu, Sebastian},
    citeulike-article-id = {9429570},
    citeulike-linkout-0 = {http://dx.doi.org/10.1371/journal.pone.0017150},
    citeulike-linkout-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3047559/},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/21399693},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=21399693},
    day = {2},
    doi = {10.1371/journal.pone.0017150},
    issn = {1932-6203},
    journal = {PLoS ONE},
    keywords = {tele-medicine},
    month = mar,
    number = {3},
    pages = {e17150+},
    pmcid = {PMC3047559},
    pmid = {21399693},
    posted-at = {2013-08-13 17:30:58},
    priority = {3},
    publisher = {Public Library of Science},
    title = {{Cell-Phone-Based Platform for Biomedical Device Development and Education Applications}},
    url = {http://dx.doi.org/10.1371/journal.pone.0017150},
    volume = {6},
    year = {2011}
}

@book{Bradski2008Learning,
    abstract = {{Learning OpenCV puts you in the middle of the rapidly expanding field of computer vision. Written by the creators of the free open source OpenCV library, this book introduces you to computer vision and demonstrates how you can quickly build applications that enable computers to "see" and make decisions based on that data. Computer vision is everywhere-in security systems, manufacturing inspection systems, medical image analysis, Unmanned Aerial Vehicles, and more. It stitches Google maps and Google Earth together, checks the pixels on LCD screens, and makes sure the stitches in your shirt are sewn properly. OpenCV provides an easy-to-use computer vision framework and a comprehensive library with more than 500 functions that can run vision code in real time.}},
    author = {Bradski, Gary R.},
    citeulike-article-id = {12556221},
    citeulike-linkout-0 = {http://www.worldcat.org/isbn/9780596516130},
    citeulike-linkout-1 = {http://books.google.com/books?vid=ISBN9780596516130},
    citeulike-linkout-2 = {http://www.amazon.com/gp/search?keywords=9780596516130&index=books&linkCode=qs},
    citeulike-linkout-3 = {http://www.librarything.com/isbn/9780596516130},
    citeulike-linkout-4 = {http://www.worldcat.org/oclc/214307253},
    isbn = {9780596516130},
    keywords = {review},
    posted-at = {2013-08-13 17:29:54},
    priority = {1},
    publisher = {O'Reilly},
    title = {{Learning OpenCV : computer vision with the OpenCV library}},
    url = {http://www.worldcat.org/isbn/9780596516130},
    year = {2008}
}

@article{Zoueu2008Optical,
    author = {Zoueu, Jeremie T. and Loum, Georges L. and Haba, T. Cisse and Brydegaard, Mikkel and Menan, Herve},
    citeulike-article-id = {12556204},
    citeulike-linkout-0 = {http://dx.doi.org/10.3923/jas.2008.2711.2717},
    day = {1},
    doi = {10.3923/jas.2008.2711.2717},
    issn = {18125654},
    journal = {Journal of Applied Sciences},
    keywords = {malaria},
    month = dec,
    number = {15},
    pages = {2711--2717},
    posted-at = {2013-08-13 17:22:32},
    priority = {0},
    title = {{Optical Microscope Based on Multispectral Imaging Applied to Plasmodium Diagnosis}},
    url = {http://dx.doi.org/10.3923/jas.2008.2711.2717},
    volume = {8},
    year = {2008}
}

@article{Breslauer2009Mobile,
    abstract = {{Light microscopy provides a simple, cost-effective, and vital method for the diagnosis and screening of hematologic and infectious diseases. In many regions of the world, however, the required equipment is either unavailable or insufficiently portable, and operators may not possess adequate training to make full use of the images obtained. Counterintuitively, these same regions are often well served by mobile phone networks, suggesting the possibility of leveraging portable, camera-enabled mobile phones for diagnostic imaging and telemedicine. Toward this end we have built a mobile phone-mounted light microscope and demonstrated its potential for clinical use by imaging P. falciparum-infected and sickle red blood cells in brightfield and M. tuberculosis-infected sputum samples in fluorescence with LED excitation. In all cases resolution exceeded that necessary to detect blood cell and microorganism morphology, and with the tuberculosis samples we took further advantage of the digitized images to demonstrate automated bacillus counting via image analysis software. We expect such a telemedicine system for global healthcare via mobile phone – offering inexpensive brightfield and fluorescence microscopy integrated with automated image analysis – to provide an important tool for disease diagnosis and screening, particularly in the developing world and rural areas where laboratory facilities are scarce but mobile phone infrastructure is extensive.}},
    author = {Breslauer, David N. and Maamari, Robi N. and Switz, Neil A. and Lam, Wilbur A. and Fletcher, Daniel A.},
    citeulike-article-id = {5222194},
    citeulike-linkout-0 = {http://dx.doi.org/10.1371/journal.pone.0006320},
    day = {22},
    doi = {10.1371/journal.pone.0006320},
    journal = {PLoS ONE},
    keywords = {tele-medicine},
    month = jul,
    number = {7},
    pages = {e6320+},
    posted-at = {2013-08-13 17:21:49},
    priority = {1},
    publisher = {Public Library of Science},
    title = {{Mobile Phone Based Clinical Microscopy for Global Health Applications}},
    url = {http://dx.doi.org/10.1371/journal.pone.0006320},
    volume = {4},
    year = {2009}
}

@book{Han2011Data,
    author = {Han, Jiawei and Kamber, Micheline and Pei, Jian},
    citeulike-article-id = {9598766},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20&amp;path=ASIN/0123814790},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21&amp;path=ASIN/0123814790},
    citeulike-linkout-10 = {http://www.worldcat.org/oclc/818321921},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21&amp;path=ASIN/0123814790},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/0123814790},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/0123814790/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20&path=ASIN/0123814790},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/0123814790},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN0123814790},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=0123814790&index=books&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/0123814790},
    day = {06},
    edition = {3},
    howpublished = {Hardcover},
    isbn = {0123814790},
    keywords = {classification},
    month = jul,
    posted-at = {2013-08-13 17:20:57},
    priority = {0},
    publisher = {Morgan Kaufmann},
    title = {{Data Mining: Concepts and Techniques, Third Edition (The Morgan Kaufmann Series in Data Management Systems)}},
    url = {http://www.worldcat.org/isbn/0123814790},
    year = {2011}
}

@electronic{Chaudhuri2001Superresolution,
    abstract = {{Annotation}},
    author = {Chaudhuri, Subhasis},
    citeulike-article-id = {12556199},
    citeulike-linkout-0 = {http://www.worldcat.org/isbn/9780792374718},
    citeulike-linkout-1 = {http://books.google.com/books?vid=ISBN9780792374718},
    citeulike-linkout-2 = {http://www.amazon.com/gp/search?keywords=9780792374718&index=books&linkCode=qs},
    citeulike-linkout-3 = {http://www.librarything.com/isbn/9780792374718},
    citeulike-linkout-4 = {http://www.worldcat.org/oclc/559624067},
    isbn = {9780792374718},
    keywords = {image-enhancement},
    posted-at = {2013-08-13 17:20:09},
    priority = {1},
    publisher = {Kluwer Academic Publishers},
    title = {{Super-resolution imaging}},
    url = {http://www.worldcat.org/isbn/9780792374718},
    year = {2001}
}

@inproceedings{Glasner2009Superresolution,
    abstract = {{Methods for super-resolution can be broadly classified into two families of methods: (i) The classical multi-image super-resolution (combining images obtained at subpixel misalignments), and (ii) Example-Based super-resolution (learning correspondence between low and high resolution image patches from a database). In this paper we propose a unified framework for combining these two families of methods. We further show how this combined approach can be applied to obtain super resolution from as little as a single image (with no database or prior examples). Our approach is based on the observation that patches in a natural image tend to redundantly recur many times inside the image, both within the same scale, as well as across different scales. Recurrence of patches within the same image scale (at subpixel misalignments) gives rise to the classical super-resolution, whereas recurrence of patches across different scales of the same image gives rise to example-based super-resolution. Our approach attempts to recover at each pixel its best possible resolution increase based on its patch redundancy within and across scales.}},
    author = {Glasner, D. and Bagon, S. and Irani, M.},
    booktitle = {Computer Vision, 2009 IEEE 12th International Conference on},
    citeulike-article-id = {10434814},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/iccv.2009.5459271},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5459271},
    doi = {10.1109/iccv.2009.5459271},
    institution = {Dept. of Comput. Sci. \& Appl. Math., Weizmann Inst. of Sci., Rehovot, Israel},
    isbn = {978-1-4244-4420-5},
    issn = {1550-5499},
    keywords = {image-enhancement},
    location = {Kyoto},
    month = sep,
    pages = {349--356},
    posted-at = {2013-08-13 17:19:29},
    priority = {1},
    publisher = {IEEE},
    title = {{Super-resolution from a single image}},
    url = {http://dx.doi.org/10.1109/iccv.2009.5459271},
    year = {2009}
}

@book{WorldHealthOrganization1991Basic,
    address = {20 Avenue Appia, 1211 Geneva 27},
    author = {{World Health Organization}},
    citeulike-article-id = {12556189},
    citeulike-linkout-0 = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20&amp;path=ASIN/9241544309},
    citeulike-linkout-1 = {http://www.amazon.de/exec/obidos/redirect?tag=citeulike01-21&amp;path=ASIN/9241544309},
    citeulike-linkout-2 = {http://www.amazon.fr/exec/obidos/redirect?tag=citeulike06-21&amp;path=ASIN/9241544309},
    citeulike-linkout-3 = {http://www.amazon.jp/exec/obidos/ASIN/9241544309},
    citeulike-linkout-4 = {http://www.amazon.co.uk/exec/obidos/ASIN/9241544309/citeulike00-21},
    citeulike-linkout-5 = {http://www.amazon.com/exec/obidos/redirect?tag=citeulike07-20&path=ASIN/9241544309},
    citeulike-linkout-6 = {http://www.worldcat.org/isbn/9241544309},
    citeulike-linkout-7 = {http://books.google.com/books?vid=ISBN9241544309},
    citeulike-linkout-8 = {http://www.amazon.com/gp/search?keywords=9241544309&index=books&linkCode=qs},
    citeulike-linkout-9 = {http://www.librarything.com/isbn/9241544309},
    edition = {Second},
    howpublished = {Spiral-bound},
    isbn = {9241544309},
    keywords = {malaria},
    location = {Switzerland},
    posted-at = {2013-08-13 17:17:42},
    priority = {1},
    publisher = {World Health Organization},
    title = {{Basic Malaria Microscopy: Part 1 Learner's guide}},
    url = {http://www.worldcat.org/isbn/9241544309},
    year = {1991}
}

@article{Trampuz2003Clinical,
    abstract = {{Malaria represents a medical emergency because it may rapidly progress to complications and death without prompt and appropriate treatment. Severe malaria is almost exclusively caused by Plasmodium falciparum. The incidence of imported malaria is increasing and the case fatality rate remains high despite progress in intensive care and antimalarial treatment. Clinical deterioration usually appears 3-7 days after onset of fever. Complications involve the nervous, respiratory, renal, and/or hematopoietic systems. Metabolic acidosis and hypoglycemia are common systemic complications. Intravenous quinine and quinidine are the most widely used drugs in the initial treatment of severe falciparum malaria, whereas artemisinin derivatives are currently recommended for quinine-resistant cases. As soon as the patient is clinically stable and able to swallow, oral treatment should be given. The intravascular volume should be maintained at the lowest level sufficient for adequate systemic perfusion to prevent development of acute respiratory distress syndrome. Renal replacement therapy should be initiated early. Exchange blood transfusion has been suggested for the treatment of patients with severe malaria and high parasitemia. For early diagnosis, it is paramount to consider malaria in every febrile patient with a history of travel in an area endemic for malaria.}},
    author = {Trampuz, Andrej and Jereb, Matjaz and Muzlovic, Igor and Prabhu, Rajesh},
    citeulike-article-id = {3986869},
    citeulike-linkout-0 = {http://dx.doi.org/10.1186/cc2183},
    citeulike-linkout-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC270697/},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/12930555},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=12930555},
    doi = {10.1186/cc2183},
    issn = {1364-8535},
    journal = {Critical Care},
    keywords = {malaria, review},
    month = aug,
    number = {4},
    pages = {315--323},
    pmcid = {PMC270697},
    pmid = {12930555},
    posted-at = {2013-08-13 17:10:20},
    priority = {1},
    title = {{Clinical review: Severe malaria}},
    url = {http://dx.doi.org/10.1186/cc2183},
    volume = {7},
    year = {2003}
}

@article{Ross2006Automated,
    abstract = {{Malaria is a serious global health problem, and rapid, accurate diagnosis is required to control the disease. An image processing algorithm to automate the diagnosis of malaria on thin blood smears is developed. The image classification system is designed to positively identify malaria parasites present in thin blood smears, and differentiate the species of malaria. Images are acquired using a charge-coupled device camera connected to a light microscope. Morphological and novel threshold selection techniques are used to identify erythrocytes (red blood cells) and possible parasites present on microscopic slides. Image features based on colour, texture and the geometry of the cells and parasites are generated, as well as features that make use of a priori knowledge of the classification problem and mimic features used by human technicians. A two-stage tree classifier using backpropogation feedforward neural networks distinguishes between true and false positives, and then diagnoses the species (Plasmodium falciparum, P. vivax, P. ovale or P. malariae) of the infection. Malaria samples obtained from the Department of Clinical Microbiology and Infectious Diseases at the University of the Witwatersrand Medical School are used for training and testing of the system. Infected erythrocytes are positively identified with a sensitivity of 85\% and a positive predictive value (PPV) of 81\%, which makes the method highly sensitive at diagnosing a complete sample provided many views are analysed. Species were correctly determined for 11 out of 15 samples.}},
    author = {Ross, Nicholas E. and Pritchard, Charles J. and Rubin, David M. and Dus\'{e}, Adriano G.},
    booktitle = {Medical and Biological Engineering and Computing},
    citeulike-article-id = {12556169},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/s11517-006-0044-2},
    citeulike-linkout-1 = {http://link.springer.com/article/10.1007/s11517-006-0044-2},
    doi = {10.1007/s11517-006-0044-2},
    keywords = {malaria},
    number = {5},
    pages = {427--436},
    posted-at = {2013-08-13 17:09:23},
    priority = {0},
    publisher = {Springer-Verlag},
    title = {{Automated image processing method for the diagnosis and classification of malaria on thin blood smears}},
    url = {http://dx.doi.org/10.1007/s11517-006-0044-2},
    volume = {44},
    year = {2006}
}

@article{Makler1998Review,
    abstract = {{Malaria is a global health problem, responsible for nearly 3 million deaths each year, and on the increase worldwide. Improvements in malaria diagnostics should facilitate the identification of individuals infected with the malarial parasites and the treatment of such cases with appropriate drugs. Both traditional and contemporary methods for malaria diagnosis are the subjects of the present review. Traditional diagnosis, based on the examination of Giemsa-stained thick and thin blood smears under a microscope, is inappropriate for many areas because there are insufficient microscopes and/or trained microscopists to read and interpret the slides. Such traditional methods are discussed in the context of parasite quantification. Newer, more advanced malaria diagnostics are now available and the relative merits of methods based on fluorescent microscopy or the detection of nucleic acid (including PCR) are described, including comparisons of costs. Fluorescent microscopy and nucleic-acid techniques both require skills and equipment which are not universally available in many malaria-endemic countries. Recently introduced diagnostic tests based on immuno-assays solve this problem since they are easy to run and interpret, and do not require complex equipment or technical support. They are also rapid ( 10 min/test), cost-effective and at least as sensitive as traditional microscopy.}},
    author = {Makler, M. T. and Palmer, C. J. and Ager, A. L.},
    citeulike-article-id = {12556167},
    citeulike-linkout-0 = {http://www.ingentaconnect.com/content/routledg/catm/1998/00000092/00000004/art00006},
    issn = {0003-4983},
    journal = {Annals of Tropical Medicine and Parasitology},
    keywords = {malaria, review},
    month = jun,
    pages = {419--433},
    posted-at = {2013-08-13 17:07:33},
    priority = {1},
    publisher = {Routledge, part of the Taylor \& Francis Group},
    title = {{A review of practical techniques for the diagnosis of malaria}},
    url = {http://www.ingentaconnect.com/content/routledg/catm/1998/00000092/00000004/art00006},
    year = {1998}
}

@article{Maragos1989Pattern,
    author = {Maragos, P.},
    citeulike-article-id = {12556157},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/34.192465},
    doi = {10.1109/34.192465},
    issn = {01628828},
    journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
    keywords = {granulometry, morphology},
    month = jul,
    number = {7},
    pages = {701--716},
    posted-at = {2013-08-13 17:03:51},
    priority = {1},
    title = {{Pattern spectrum and multiscale shape representation}},
    url = {http://dx.doi.org/10.1109/34.192465},
    volume = {11},
    year = {1989}
}

@incollection{Vincent1994Morphological,
    abstract = {{The filter that removes from a binary image the components with area smaller than a parameter λ is called area opening. Together with its dual, the area closing, it is first extended to grey-scale images. It is then proved to be equivalent to a maximum of morphological openings with all the connected structuring elements of area greater than or equal to λ. The study of the relationships between these filters and image extrema leads to a very efficient area opening/closing algorithm. Grey-scale area openings and closings can be seen as transformations with a structuring element which locally adapts its shape to the image structures, and therefore have very nice filtering capabilities. Their effect is compared to that of more standard morphological filters. Some applications in image segmentation and hierarchical decomposition are also briefly described.}},
    author = {Vincent, Luc},
    booktitle = {Shape in Picture},
    citeulike-article-id = {12556147},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-3-662-03039-4_13},
    citeulike-linkout-1 = {http://link.springer.com/chapter/10.1007/978-3-662-03039-4_13},
    doi = {10.1007/978-3-662-03039-4_13},
    editor = {Ying-Lie and Toet, Alexander and Foster, David and Heijmans, HenkJ and Meer, Peter},
    keywords = {morphology},
    pages = {197--208},
    posted-at = {2013-08-13 16:59:58},
    priority = {0},
    publisher = {Springer Berlin Heidelberg},
    series = {NATO ASI Series},
    title = {{Morphological Area Openings and Closings for Grey-scale Images}},
    url = {http://dx.doi.org/10.1007/978-3-662-03039-4_13},
    volume = {126},
    year = {1994}
}

@book{Szeliski2011Computer,
    address = {London},
    author = {Szeliski, Richard},
    citeulike-article-id = {10710867},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/978-1-84882-935-0},
    citeulike-linkout-1 = {http://www.springerlink.com/content/978-1-84882-934-3},
    doi = {10.1007/978-1-84882-935-0},
    isbn = {978-1-84882-934-3},
    keywords = {book, review},
    posted-at = {2013-08-13 16:58:44},
    priority = {1},
    publisher = {Springer London},
    title = {{Computer Vision}},
    url = {http://dx.doi.org/10.1007/978-1-84882-935-0},
    year = {2011}
}

@article{MohanaRao2001Areagranulometry,
    author = {Mohana Rao, K. N. R. and Dempster, A. G.},
    citeulike-article-id = {12556142},
    citeulike-linkout-0 = {http://dx.doi.org/10.1049/el:20010635},
    doi = {10.1049/el:20010635},
    issn = {00135194},
    journal = {Electronics Letters},
    keywords = {granulometry, morphology},
    number = {15},
    pages = {950+},
    posted-at = {2013-08-13 16:57:52},
    priority = {0},
    title = {{Area-granulometry: an improved estimator of size distribution of image objects}},
    url = {http://dx.doi.org/10.1049/el:20010635},
    volume = {37},
    year = {2001}
}

@article{Serra1992Overview,
    abstract = {{This paper consists of a tutorial overview of morphological filtering, a theory introduced in 1988 in the context of mathematical morphology. Its first section is devoted to the presentation of the lattice framework. Emphasis is put on the lattices of numerical functions in digital and continuous spaces. The basic filters, namely the openings and the closings, are then described and their various versions are listed. In the third section morphological filters are defined as increasing idempotent operators, and their laws of composition are proved. The last sections are concerned with two special classes of filters and their derivations: first, the alternating sequential filters allow us to bring into play families of operators depending on a positive scale parameter. Finally, the center and the toggle mappings modify the function under study by comparing it, at each point, with a few reference transforms.}},
    author = {Serra, Jean and Vincent, Luc},
    booktitle = {Circuits, Systems and Signal Processing},
    citeulike-article-id = {3377121},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/bf01189221},
    citeulike-linkout-1 = {http://link.springer.com/article/10.1007/BF01189221},
    day = {1},
    doi = {10.1007/bf01189221},
    journal = {Circuits, Systems, and Signal Processing},
    keywords = {morphology, review},
    month = mar,
    number = {1},
    pages = {47--108},
    posted-at = {2013-08-13 16:57:00},
    priority = {0},
    publisher = {Birkh\"{a}user-Verlag},
    title = {{An overview of morphological filtering}},
    url = {http://dx.doi.org/10.1007/bf01189221},
    volume = {11},
    year = {1992}
}

@inproceedings{DiRuberto2000Segmentation,
    author = {Di Ruberto, Cecilia and Dempster, Andrew and Khan, S. and Jarra, B.},
    booktitle = {Proceedings 15th International Conference on Pattern Recognition. ICPR-2000},
    citeulike-article-id = {12556130},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/icpr.2000.903568},
    doi = {10.1109/icpr.2000.903568},
    isbn = {0-7695-0750-6},
    keywords = {morphology, segmentation},
    location = {Barcelona, Spain},
    pages = {397--400},
    posted-at = {2013-08-13 16:54:42},
    priority = {0},
    publisher = {IEEE Comput. Soc},
    title = {{Segmentation of blood images using morphological operators}},
    url = {http://dx.doi.org/10.1109/icpr.2000.903568},
    year = {2000}
}

@article{Tek2009Computer,
    abstract = {{This paper reviews computer vision and image analysis studies aiming at automated diagnosis or screening of malaria infection in microscope images of thin blood film smears. Existing works interpret the diagnosis problem differently or propose partial solutions to the problem. A critique of these works is furnished. In addition, a general pattern recognition framework to perform diagnosis, which includes image acquisition, pre-processing, segmentation, and pattern classification components, is described. The open problems are addressed and a perspective of the future work for realization of automated microscopy diagnosis of malaria is provided.}},
    author = {Tek, F. Boray and Dempster, Andrew and Kale, Izzet},
    citeulike-article-id = {12556125},
    citeulike-linkout-0 = {http://dx.doi.org/10.1186/1475-2875-8-153},
    citeulike-linkout-1 = {http://view.ncbi.nlm.nih.gov/pubmed/19594927},
    citeulike-linkout-2 = {http://www.hubmed.org/display.cgi?uids=19594927},
    doi = {10.1186/1475-2875-8-153},
    issn = {1475-2875},
    journal = {Malaria Journal},
    keywords = {malaria, review},
    number = {1},
    pages = {153+},
    pmid = {19594927},
    posted-at = {2013-08-13 16:51:36},
    priority = {0},
    title = {{Computer vision for microscopy diagnosis of malaria}},
    url = {http://dx.doi.org/10.1186/1475-2875-8-153},
    volume = {8},
    year = {2009}
}

@article{Tek2010Parasite,
    abstract = {{This paper investigates automated detection and identification of malaria parasites in images of Giemsa-stained thin blood film specimens. The Giemsa stain highlights not only the malaria parasites but also the white blood cells, platelets, and artefacts. We propose a complete framework to extract these stained structures, determine whether they are parasites, and identify the infecting species and life-cycle stages. We investigate species and life-cycle-stage identification as multi-class classification problems in which we compare three different classification schemes and empirically show that the detection, species, and life-cycle-stage tasks can be performed in a joint classification as well as an extension to binary detection. The proposed binary parasite detector can operate at 0.1\%0.1\% parasitemia without any false detections and with less than 10 false detections at levels as low as 0.01\%0.01\%.}},
    author = {Tek, F. Boray and Dempster, Andrew G. and Kale, \.{I}zzet},
    citeulike-article-id = {5665411},
    citeulike-linkout-0 = {http://dx.doi.org/10.1016/j.cviu.2009.08.003},
    day = {24},
    doi = {10.1016/j.cviu.2009.08.003},
    issn = {10773142},
    journal = {Computer Vision and Image Understanding},
    keywords = {malaria},
    month = jan,
    number = {1},
    pages = {21--32},
    posted-at = {2013-08-13 16:51:03},
    priority = {0},
    title = {{Parasite detection and identification for automated thin blood film malaria diagnosis}},
    url = {http://dx.doi.org/10.1016/j.cviu.2009.08.003},
    volume = {114},
    year = {2010}
}

@inproceedings{Halim2006Estimating,
    author = {Halim, S. and Bretschneider, T. and Li, Y. and Preiser, P. R. and Kuss, C.},
    booktitle = {Control, Automation, Robotics and Vision, 2006. ICARCV \&\#039;06. 9th International Conference on},
    citeulike-article-id = {12556119},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/icarcv.2006.345381},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4150204},
    doi = {10.1109/icarcv.2006.345381},
    institution = {Sch. of Comput. Eng., Nanyang Technol. Univ., Singapore},
    isbn = {1-4244-0341-3},
    keywords = {malaria},
    month = dec,
    pages = {1--6},
    posted-at = {2013-08-13 16:50:00},
    priority = {1},
    publisher = {IEEE},
    title = {{Estimating Malaria Parasitaemia from Blood Smear Images}},
    url = {http://dx.doi.org/10.1109/icarcv.2006.345381},
    year = {2006}
}

@inproceedings{Mandal2010Segmentation,
    author = {Mandal, S. and Kumar, A. and Chatterjee, J. and Manjunatha, M. and Ray, A. K.},
    booktitle = {India Conference (INDICON), 2010 Annual IEEE},
    citeulike-article-id = {12556009},
    citeulike-linkout-0 = {http://dx.doi.org/10.1109/indcon.2010.5712739},
    citeulike-linkout-1 = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=5712739},
    doi = {10.1109/indcon.2010.5712739},
    institution = {Sch. of Med. Sci. \& Technol., Indian Inst. of Technol., Kharagpur, India},
    isbn = {978-1-4244-9072-1},
    keywords = {graph-cuts, malaria},
    month = dec,
    pages = {1--4},
    posted-at = {2013-08-13 16:49:23},
    priority = {1},
    publisher = {IEEE},
    title = {{Segmentation of blood smear images using normalized cuts for detection of malarial parasites}},
    url = {http://dx.doi.org/10.1109/indcon.2010.5712739},
    year = {2010}
}

@article{Moon2013Image,
    abstract = {{With more than 40\% of the world's population at risk, 200–300 million infections each year, and an estimated 1.2 million deaths annually, malaria remains one of the most important public health problems of mankind today. With the propensity of malaria parasites to rapidly develop resistance to newly developed therapies, and the recent failures of artemisinin-based drugs in Southeast Asia, there is an urgent need for new antimalarial compounds with novel mechanisms of action to be developed against multidrug resistant malaria. We present here a novel image analysis algorithm for the quantitative detection and classification of Plasmodium lifecycle stages in culture as well as discriminating between viable and dead parasites in drug-treated samples. This new algorithm reliably estimates the number of red blood cells (isolated or clustered) per fluorescence image field, and accurately identifies parasitized erythrocytes on the basis of high intensity DAPI-stained parasite nuclei spots and Mitotracker-stained mitochondrial in viable parasites. We validated the performance of the algorithm by manual counting of the infected and non-infected red blood cells in multiple image fields, and the quantitative analyses of the different parasite stages (early rings, rings, trophozoites, schizonts) at various time-point post-merozoite invasion, in tightly synchronized cultures. Additionally, the developed algorithm provided parasitological effective concentration 50 (EC50) values for both chloroquine and artemisinin, that were similar to known growth inhibitory EC50 values for these compounds as determined using conventional SYBR Green I and lactate dehydrogenase-based assays.}},
    author = {Moon, Seunghyun and Lee, Sukjun and Kim, Heechang and Freitas-Junior, Lucio H. and Kang, Myungjoo and Ayong, Lawrence and Hansen, Michael A. E.},
    citeulike-article-id = {12555629},
    citeulike-linkout-0 = {http://dx.doi.org/10.1371/journal.pone.0061812},
    day = {23},
    doi = {10.1371/journal.pone.0061812},
    journal = {PLoS ONE},
    keywords = {malaria},
    month = apr,
    number = {4},
    pages = {e61812+},
    posted-at = {2013-08-13 16:41:01},
    priority = {0},
    publisher = {Public Library of Science},
    title = {{An Image Analysis Algorithm for Malaria Parasite Stage Classification and Viability Quantification}},
    url = {http://dx.doi.org/10.1371/journal.pone.0061812},
    volume = {8},
    year = {2013}
}

